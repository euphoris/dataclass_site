자 다시 이어서 해보도록 할까요?

자 이번 시간에 할 거는 공기어 네트워크 입니다.

공기어 네트워크는 뭐냐 일단 공기라는 말은 이게 우리말 한자우니까 사실 우리의 말이라 해야 될지 모르겠지만 어쨌든 한자가 되게 어려운데 공은 함께 이런 뜻이에요

공동차 할 때 공자고 그 다음에 기는 일어난다

이런 얘기 입니다.

함께 일어난다

이런 뜻이죠

영어로는 코어커러스 그래서 두 단어가 같이 나타나면은 공기어 라고 해요

그런데 예를 들면 뭐 뭐가 있을까요

아까 우리 문장을 보면은 예를 들면은 뭐 플레이스가 있다

그러면은 뭐 조용한 장소 이런 거는 말이 되지만 조용한 음식 이런 거는 뭐 조용한 음식도 있을 수 있죠

소디가 먹을 때 안 나는 근데 이제 뭐 조용한 서비스 이런 것도 조금 이상하고 그래서 뭐 예를 들면 딜리셔스 맛있는 음식 이런 거는 되지만 맛있는 서비스 이런 건 좀 이상하단 말이에요

어떤 단어가 단어가 함께 쓸 수 있는 경우도 있고 좀 잘 안 쓰이는 경우도 있는데 그런 관계를 이제 공기어 관계라고 합니다.

그래서 같은 한 맥락 안에서 함께 나타나면 함께 공 나타날 기에서 공기어 라고 해요

그 다음에 네트워크라는 거는 두 단어가 이렇게 같이 나타나는 관계고 예랑 예랑도 같이 나타나는 관계고 예랑 예랑도 같이 나타나는 관계다

또 얘는 예랑 같이 나타나고 얘는 이렇게 나타나고 이런 식으로 이제 네트워크를 그릴 수가 있겠죠

그럼 이 네트워크에서 단어가 어떤 점의 역할을 하고 그 다음에 단어와 단어가 함께 일어나는 관계를 우리가 선으로 그릴 수 있는데 이런 구조를 네트워크라고 합니다

그래서 이제 이런 공기어 네트워크를 우리가 또 분석을 할 수가 있겠죠

그래서 그런 분석을 공기어 네트워크 분석이다

이렇게 얘기합니다

그래서 데이터는 똑같이 엘프로 할 거예요

그래서 이거는 뭐 다시 안 하셔도 되겠죠

이거는 건너 뛰시면 됩니다

패스 그 다음에 이제 문서 단어 행렬을 만들 건데 약간 다르게 만들 거예요

어떻게 만드냐면 일단 여기 스타버즈는 똑같이 하시면 되고요

그 다음에 이제 우리가 맥스 피체스로 하셔도 되는데 우리가 앞에서 맥스 피체스로 했죠

이거를 조금 다르게 할 겁니다

뭘로 할 거냐면 민 DF로 할 거예요

민 DF는 뭐냐면 민은 최소란 뜻이고요 DF는 다큐먼트 프리콘시라는 뜻인데 한마디로 몇 개의 문서에 등장했느냐

이런 뜻입니다

그래서 민 DF는 0.01 하면 최소 1% 이상의 문서에서 출연한 단어만 포함하겠다

이런 얘기예요

왜 최대 단어수 대신에 이런 식으로 접근하냐면 어떤 단어는 특정 문서에만 너무 많이 나오는 경우가 있거든요

근데 지금 우리가 분석을 뭘로 할 거냐면 공기어 네트워크로 분석을 할 거니까 너무 소수의 문서에 많이 나온 단어는 별로 필요가 없어요

왜냐하면 같이 나타나는 다른 단어랑 함께 나타나는 걸 봐야 되는데 그러면 지원자 많이 나온 건 소요 없죠

여러 문서에 골고루 나와야 다른 단어랑 어떻게 나타난지를 알 수가 있습니다

그 다음에 이제 바이널이는 true 이렇게 되는데 바이널이는 0 아니면 1이라는 뜻입니다

그래서 이거는 외해주냐 하면 우리가 어떤 문서에 나타나면 1 안 나타나면 0 이렇게 둘로 할 거라서 그렇습니다

그래서 여기서는 어떤 단어가 절대적으로 얼마나 나타나는지가 중요한 게 아니고 다른 단어랑 같이 나타나는지 아닌지가 중요하기 때문에 단어에 구체적인 빈도보다는 단어가 나타났으면 1 안 나타났으면 0 이렇게 단순하게 만들어 줄 거예요

그래서 슬라이드 우리가 사실 인포트 같은 것도 이미 다 되어 있기 때문에 또 하실 필요 없고 여기 134쪽에 밑에 두 줄 이거 두 줄만 해주시면 됩니다

나머지는 다 이미 했던 거라서 또 하실 필요는 없어요

이렇게 두 줄만 해주시면 됩니다

다 해보셨나요

그러면은 이제 좀 복잡한 걸 해야 되는데 인접 행렬이라는 걸 만들 겁니다

인접 행렬은 뭐냐면 두 개가 이제 인접해 있다 이거죠

말 그대로 어떤 단어가 있고 이 단어와 단어가 서로 같이 나타났는지 이거를 행렬로 나타날 겁니다

인접 행렬을 어떻게 만들 수 있냐면

사실 되게 간단한데 약간의 수학이 들어가요

그래서 우리가 이제 지금 어떤 단어가 특정 문서에 나타나면 문서가 있고 단어가 있죠

문서가 있고 단어가 있으면 어떤 문서에 단어가 ABC 세 가지가 있는데 B하고 C가 나타났으면 11 이렇게 쓰고요 그다음에 이제 문서 2에 A하고 B가 나타났으면 11 C는 없으면 0 이렇게 쓰게 됩니다

그럼 이거를 뒤에 점T 라고 돼 있는데 이거는 전치 행렬이라고 해서 이거를 뒤집어서 표시를 하는 거예요

어떻게 표시하냐면 단어 ABC가 있고 문서 1 문서 2가 있겠죠

똑같이 쓰면 됩니다

문서 1에는 A가 안 나오고 B가 나오고 C가 나오고 문서 2에는 A하고 B가 나오고 C는 안 나오고 그러면 이거를 골뱅이 표시를 써주면 이 골뱅이 표시는 뭐냐면 행렬의 곱샘을 하라는 거예요

행렬의 곱샘은 이렇게 행 방향하고 이렇게 열 방향을 꼽해주는 겁니다

그러면은 자 꼽해 봅시다 손으로 한번 어떻게 되는지

그럼 일단 이제 단어 A의 경우에 0 1이고 이렇게 0 1이니까 0 9 파기 0 7 파기 1 하면 더하게 하면 1이 되겠죠

그래서 이렇게 되고요 그다음에 A하고 B하고 곱하면 0 9 파기 1 7 파기 1 그래서 1이 되겠죠

A하고 C하고 하면 0 9 파기 1 7 파기 0이니까 A하고 C는 0이 됩니다

그다음에 이제 단어 B의 경우에는 7 파기 1 7 파기 1이니까 여기는 2가 되고요 그다음에 C하고 해보면 7 파기 1 7 파기 0이니까 1이 되겠죠

그다음에 단어 C의 경우에는 7 파기 0 7 파기 0이니까 1이 됩니다

여기는 왜 계산 아니냐면 어차피 대칭이기 때문에 여기도 1 여기도 0 여기도 1 이렇게 돼요

그래서 행렬의 곱샘을 하면 결국 얻어지는 행렬은 뭐냐면 A하고 B가 얼마나 자주 같이 나왔는가 한 번 같이 나왔다

이거죠

그다음에 이렇게 대각선 원소가 있는데 이 대각선 원소는 뭘 나타내냐면 단어의 총 빈도가 됩니다

단어의 총 빈도가 되고 그다음에 여기 이제 삼각형 부분 이 삼각형 부분은 두 단어에 함께 나타난 공기빈도가 됩니다

밑에도 어차피 대칭이기 때문에 좌우 대칭이기 때문에 똑같은 얘기가 돼요

이렇게 행렬의 곱샘을 하면 인접 행렬 두 단어가 얼마나 같이 쓰였느냐를 나타내는 행렬이 됩니다

그리고 해보면 코오커는 dtm.

t 골뱅이 dtm 이렇게 하고 그다음에 adj는 코오커.

a 이.

a는 압축을 풀어라

이런 뜻이에요

그래서 adj.

shape 해보시면 82행 82열 이렇게 되고 왜 82행 82열이냐면 최소 1% 이상의 문서에서 등장한 단어들이라서 그렇습니다

82개의 단어들이 함께 나타난 경우를 나타냅니다

그래서 숫자를 보시려면 adj라고 써보시면 되겠죠

adj 써보면 24,11,12 이렇게 나갔는데 이거는 단어의 전체 빈도고 여기 1 이렇게 있죠

그럼 이게 첫 번째 단어랑 두 번째 세 번째 세 번째 단어랑 같이 나온 경우가 한 번 있다

이런 경우입니다

그래서 요거 또 해보시면 되겠습니다

약간 수확이 들어가서 어려울 수도 있는데 뭐 수확적인 건 중요하지 않고 약간 요 행렬이 뭘 나타내냐

이거를 이해하시면 될 것 같아요

잘 하셨나요

그 다음에 이제 우리가 두 단어가 함께 쓰인 빈도가 높으면 그러면 두 단어는 뭐가 관련이 있느냐 라고 하면 꼭 그렇다고 할 수는 없습니다

왜냐하면 애초에 그 빈도가 높은 단어는 원래 그냥 빈도가 높으니까 예를 들면은 우리나라 말 중에 한국 사람들은 말할 때 항상 아니 이 말로 시작하죠

그래서 아니 이러면서 이렇게 말을 시작하는데 이 단어는 그러면 특정 단어랑 관련이 있느냐

하면 별로 관련 없는데 아까처럼 인접 행렬을 나타내면 굉장히 빈도가 높게 나올 겁니다

왜냐하면 애초에 아니라는 말을 자주 하기 때문에 다른 단어랑 같이 쓰이는 경우가 많아요

그래서 우리가 이제 상대적으로 얼마나 같이 쓰였는지를 계산을 해야 되는데 이제 요 P A라고 쓴 거는 A의 확률입니다

A의 확률 A라는 단어가 쓰일 확률이 어떻게 되느냐

이거고 P B는 B의 확률이죠

그래서 B라는 단어가 얼마 자주 쓰이느냐

그러면 만약에 N가 두 개가 독립이면 P A 곱하기 P B만큼이 두 단어가 동시에 쓰일 확률이죠

이거는 이제 동시에 쓰일 확률입니다 확률의 정의상 두 개가 독립이면 두 개의 확률을 곱하면 두 개가 동시에 일어날 확률이라고 같아요

그러면 이게 독립인 경우에는 1이 되는데 만약에 독립이 아니라면 이 비율이 1이 아니게 됩니다

그래서 만약에 요 값이 1보다 매우 크다

그러면은 두 개는 굉장히 긴밀하게 관련되어 있는 거고 만약에 이게 1에 가깝다

그러면 두 단어는 독립적인 독립적이라는 거는 서로 별로 관련이 없는데 그냥 A도 많이 나오고 B도 많이 나오니까 A랑 B가 같이 나오는 경우도 많아지면 그냥 전체 개수는 늘어나겠죠

만약에 이게 1보다 매우 작다 그러면 반대 역관계가 있습니다

하나가 나오면 다른 하나는 안 나오는 그런 역관계에 있는 거고 우리는 이제 뭔가 관련이 있는 단어를 찾고 싶으니까 요 두 개의 비율이 1보다 매우 큰 어떤 단어를 찾아야겠죠

그래서 이런 식으로 이제 계산하는 거를 분야에 따라서 이름이 다른데 데이터 마이닝이라는 분야가 있어요

데이터 마이닝 분야는 어떤 거 하냐면 여러분 뭐 그런 얘기 한번 들어보셨을 거예요

맥주랑 기저기를 패키지로 파니까 패키지로 파니까 잘 팔리더라

왜 잘 팔린지 알아보니까 이제 미국에서 얘기인데 어 이제 애기아빠들이 장보로 왔다가 이제 엄마는 애기 보고 아빠는 이제 장보로 나왔는데 미국은 나라가 크니까 마트 한번 가려면 차 끌고 막 몇십 키로를 가야 된단 말이에요

시골동네 이런 데 그럼 한번 나오면 다시 돌아갈 때 또 한참 가야 되니까 이제 나온 김에 자기 먹을 맥주도 원래 이제 엄마 그 와이프한테 등짝 한대 막고 집에서 애 안 볼 거면 기적이라서 사와

그래서 이제 마트까지 갔다가 두덜 두덩 갔다가 어 맥주도 있네

그럼 이제 맥주도 사가야지

뭐 이런 애기아빠들이 좀 있는데 그래서 맥주랑 기저기를 패키지로 파니까 잘 팔리더라

뭐 이런 식의 얘기를 아마 들어보신 분들이 있을 거예요

사실 이 얘기는 되게 오래된 얘기입니다

90년대 얘기인데 사실 이제 이런 식으로 뭔가 패키지를 그 발견하는 게 쉽지 않아요

그러니까 90년대에 나온 어떤 사례를 아직도 30년째 울거 먹고 있는 건데 뭐 어쨌든 이런 거 찾아내는 이런 어떤 특정한 데이터에 어떤 패턴을 찾아내는 걸 데이터 마이닝이라고 해요

그래서 데이터 마이닝 분야에서는 이런 거를 향상도라고 부릅니다

여기도 이제 마찬가지 문제가 있죠

예를 들면 맥주랑 기저기가 같이 많이 팔리는 이유는 원래 맥주도 많이 팔리고 기저기도 많이 팔려서인가 아니면 두 개가 뭔가 관련이 있어서인가

그럼 이걸 이렇게 계산할 수 있습니다

그쵸 뭐 예를 들면 우리가 이제 마트 가면 맨날 사는 게 뭐야 라면도 사람만 다르지만 마트 가면은 보통 라면 많이 사고 그다음에 채소 많이 사잖아요

그럼 라면하고 채소는 함께 팔리는 경우가 많은데 두 개가 뭐 관련이 있어서 그런 경우도 있고 아니면 그냥 단순히 라면도 많이 팔리고 채소도 많이 팔리니까 같은 장바구니 안에 라면이랑 채소가 같이 들어있는 경우도 많겠죠

그래서 그거를 이제 제대로 계산하려면 이렇게 비율로 계산해야 됩니다

그래서 데이터 마이닝에서는 이걸 보통 향상도라고 하고요 그다음에 이제 정보 이론이라는 분야가 있는데 거기서는 요거를 점상호 정보 라고 불러요

포인트 뮤추얼 인포메이션 여기서는 엄밀히 말하면 요 앞이 로그가 붙어야 됩니다

로그랑 마이너스가 붙는데 어차피 기본적으로는 로그를 붙여도 결국 똑같은 숫자이 똑같기 때문에 로그 붙이면 이제 이게 0보다 커야겠죠

근데 뭐 그게 중요한 건 아니고 하여간 사실상 똑같은 연산이다

그래서 두 개 각각의 어떤 확률을 곱한 거하고 같이 나타난 확률을 비교를 해 가지고 두 개가 얼마나 관련 있는지를 계산하는게 요 점상호 정보 또는 향상도의 수치가 의미하는 겁니다

그래서 요거를 이제 계산을 해야 되는데 일단 문서 단어가 얼마나 나왔냐

그러면 여기 아까 보시면 24,11,12 이게 이제 이 단어가 얼마나 나왔냐

이거거든요

이 단어가 어떤 단어지도 잠깐 보면 cv.

getfeaturenames 하면 단어를 볼 수 있겠죠

제일 첫 번째 단어가 amazing이고 그 다음에 etmospia인데 대각선이 나타나는 건 뭐냐면 24가 amazing이 24개의 문서에 나왔다

이겁니다

24번 나온 건 아니고 한 문서에 두 번, 세 번 나올 수도 있는데 우리가 다 1로 카운트했기 때문에 문서 수는 24개입니다

그래서 np.

diag라는 함수에다 넣으면 이 방향을 대각선 방향이라고 하는데 대각선 방향에 있는 값들만 뽑아줘요

24,11,12 이렇게 이게 뭐냐면은 그 각 단어가 문서들의 얼마나 나왔냐

이런 겁니다

어떤 단어는 121번 나오고 어떤 단어는 11번 나왔는데 그러면 121번 나온 단어는 지금 문서가 1000개가 있는데 1000개 중에 121번 나왔으니까 어떤 다른 단어랑 우연히 같이 나올 확률이 10%가 넘는 거죠

1000개의 문서 중에 121개의 문서에 나왔으니까 일단 이 단어는 12%의 문서에 나왔잖아요

그럼 받고 말하면 어떤 단어든지 간에 이 단어랑 같이 나올 확률이 12%는 되는 셈입니다

그러면 12% 이상 같이 나와야 그 단어는 이 단어랑 뭔가 관련이 있다 이런 식으로 얘기를 할 수 있겠죠

그래서 이거를 n이라는 변수에다가 넣어주고요 그 다음에 이제 우리가 전체 문서 수는 dtm.

shave을 해보면 이 앞에 있는 1000이 전체 문서 수거든요

그래서 그거를 total이라는 변수에 넣어줄 거예요

total, comma, 밑줄은 이렇게 하면 1000은 여기 total에 들어가고 82는 밑줄에 들어갑니다

변수 이름을 밑줄으로 써준 이유는 보통 다음번에 안 쓸 변수는 밑줄이라고 해요

그래서 82는 밑줄에 들어가는데 보통 파이사운 이거는 문법은 아니고 관습인데 82는 우리가 필요가 없으니까 그냥 변수 이름을 잘 눈에 띄지 않는 밑줄로 지정을 해준 겁니다

그 다음에 계산이 이렇게 되는데 계산이 좀 복잡하죠

이거는 일단 계산을 해놓고 그 다음에 설명을 드리도록 하겠습니다

이 식 자체는 아까 우리가 앞에서 봤던 이 식하고 똑같은 식이에요

왜 그렇게 되느냐

이거는 일단 돌려놓고 설명을 드리도록 하겠습니다

그래서 슬라이드 137쪽에 있는 코드들을 한번 실행을 해보시면 되겠습니다

잘 따라오고 계신가요

그래서 여기 보시면 이제 우리가 수식으로 나타내려면 이제 어떻게 나타내려냐면 이거 앞에 요거를 계산해야겠죠

요거를 계산해야 되는데 우리가 이제 이거 A가 나타날 확률은 어떻게 되냐면 M분의 토탈 하면 됩니다

B가 나타날 확률도 M분의 토탈 하면 되거든요

두 개가 같이 나타나는 경우는 ADJ분의 토탈을 하면 돼요

그럼 요거를 이제 정리를 해주면 요렇게 이렇게 재해지고 그 다음에 토탈이 위로 올라가죠

그래서 여기 보시면 토탈하고 ADJ를 곱하고 MP.

outer n by n 이렇게 되는데 왜 그러냐면 ADJ의 형식을 보시면 ADJ가 요렇게 생겼거든요

그럼 요거랑 똑같은 모양으로 만들어줘야 되는데 MP.

outer 하면 n by n 하면 우리가 지금 n이 24,11,12,19 이렇게 나가죠

그거랑 이쪽으로도 24,11,12,19 이렇게 곱해줍니다

그래서 여기 이제 576이 들어가는데 왜 576이냐면 24 곱하기 24라서 그래요 576이 되죠

그 다음에 여기는 264인데 왜 264냐면 n을 보면 11번이잖아요

그러면 24 곱하기 11해서 264가 됩니다

그래서 요거를 토탈의 재곱으로 나누면 이렇게 확률이 나오는데 요 확률이 뭐냐면 이제 일종의 기대가 되는 확률이에요

여기에는 0.00264의 확률이 기대가 되고 여기는 0.00288의 확률이 기대가 되는데 실제로 우리가 관찰한 확률은 뭐냐면 ADJ를 토탈로 나눈 겁니다

그러면 여기는 0.024가 기대가 되고 여기는 0이 기대가 되고 여기는 0.0201이 기대가 되고 요런식이 된 거죠

그래서 이게 분모고 이게 분자인데 요거를 이렇게 나눈 거죠

그래서 여기 토탈이 위에 있는 분모가 없어지고 여기 재곱이 없어지고 그 다음에 나누기가 있으니까 요게 위로 올라가고 그래서 아까 말했던 요 형태가 되는 겁니다

이것도 계산은 복잡한데 요 점은 한간 두 개가 독립적으로 나온 경우에 대비해서 실제로 관찰된 경우는 얼마나 되느냐 계산은 복잡하지만 요거가 어떻게 되느냐

계산을 해본 거고 그래서 리프트를 계산을 했고요 그러면 우리가 리프트가 큰 거만 남기고 작은 거는 그래프 그릴 때 빼고 그려야 되는데 빼고 그릴 건데 어떻게 할 거냐면 리프트 값을 보면 리프트 보면 리프트가 41, 3 이렇게 나온 데가 있어요

그리고 대각선 쪽은 무시하시고 3.47 이렇게 나온 거는 리프트가 크게 나온 거죠

100 이렇게 리프트가 작은 데도 있거든요

리프트가 1에 가까운 쪽은 사실 나오긴 나왔지만 별로 많이 나온 쪽은 아닙니다

그래서 우리의 이제 어떤 기준을 정해서 잘라버릴 건데 뭐냐면 향상도가 2 이상인 경우만 남기고 나머지는 다 0으로 바꿀 거예요 리프트가 1.5 이렇게 나왔다

그럼 1.5 정도는 뭐 쳐다보면 나올 수 있는 거죠

왜냐면 독립이어도 1은 나오니까 그래서 한 2 정도 이상인 거는 남기고 나머지는 다 0으로 바꾸겠다

이렇게 해주면 해주고요

그럼 지금 M 보시면 일단 101 이렇게 바뀌었는데 여기 1으로 나온 경우는 향상도가 2 이상인 경우입니다

그다음에 여기 대각선 부분은 필요가 없거든요

왜냐하면 서로 다른 단어가 같이 나오는 비율을 알고 싶은 건데 여기는 자기 자신하고 같이 나오는 경우라서 뭐 우리의 지금 공기여의 관심은 아니에요

그래서 이거를 필 다이어거나 이렇게 하면 대각선은 0으로 채워라

이런 뜻입니다

그러니까 여기 대각선 방향은 0으로 채워라

이런 뜻입니다

여기까지 실행하시고 M 쳐보면 지금 대각선이 이제 0으로 바뀌어 있죠

그리고 여기에 1 이렇게 되는데 이거는 첫 번째랑 세 번째는 좀 같이 나온 경우가 많다

이런 자기네 비율에 비해서 원래 비율에 비해서 좀 많이 나온 편이다

이런 얘기가 됩니다

그래서 138조까지 해보시면 되겠습니다

자 그러면은 이거를 이제 네트워크 형태로 한번 바꿔보도록 하겠습니다

그래서 네트워크 X라고 해가지고 파이선에서 네트워크 분석을 위한 라이브러리가 있거든요

그래서 이거를 우리의 인접 행렬을 네트워크로 변환을 해줍니다

그 다음에 이 네트워크 NX.

re라벨 노즈 이렇게 하면은 그 네트워크에다 이름을 붙일 수가 있거든요

그래서 노즈 이름을 단어로 바꾸고 그 다음에 이제 이렇게 하시면 여기 네이버라는 이름이 나오는데 네이버는 이웃이라는 뜻이죠

그래서 스테이크라는 단어의 네이버 이웃이 뭐냐 여기서 이웃은 스테이크라는 단어랑 같이 쓰인 적이 있는 단어가 뭐냐

이런 뜻입니다

그러면은 이제 보시면은 스테이크하고 같이 쓰인 단어는 어메이징이라든지 베스트라든지 치킨이라든지 플레이버 후레시 그레이트 뭐 이런 단어 월스트 이런 단어들이 아 스테이크랑 같이 쓰이는구나

이런 거를 알 수 있어요

다른 단어도 넣어보면 뭐 예를 들면 서비스 서비스랑 같이 쓰이는 단어는 뭐 엑셀런트 판타스틱 뭐 프렌들리 뭐 이런 단어구나 테러블 슬로우 이런 단어 서버 그리고 플레이스랑 같이 쓰이는 단어는 뭐냐 플레이스 오썸 뭐 노 러브 뭐 레코멘드 쓰시 싱크 뭐 이런 단어다

그래서 어떤 단어가 어떤 단어랑 같이 쓰이는지

이런 거를 우리가 살펴볼 수가 있습니다

그래서 여기에 슬라이드 140조까지고요 여기까지 한번 해보시고 잘 안 되시거나 질문 있으시면 말씀해주세요

잘 되시나요

그 다음에 이거를 좀 그림으로 그려서 보면 더 좋겠죠

그 전에 일단 중심성 계산부터 해보도록 하겠습니다

그 중심성은 뭐냐면 어떤 네트워크에서 그 노트의 중요도를 나타낸 지표인데 뭐 예를 들면 우리가 어떤 사람이 있을 때 그 사람이 얼마나 중요한 사람이냐

우리 회사에서 중요한 사람이냐

그러면 그거를 여러 가지로 표현할 수 있는데 한 가지는 네트워크 상에서 얼마나 큰 위치에 중요한 위치에 있느냐 이걸 가지고 나타낼 수 있어요

그래서 여러 가지 지표가 있는데 일단 연결 중심성 이거는 사실 되게 간단합니다

연결된 단어 수가 많으면 중요한 단어 그러니까 자기랑 연결된 단어가 많으면 중요한 단어가 별로 없다 그러면 안 중요한 거야

사람으로 치면 친구가 많은 사람이 중요한 사람이고 친구가 별로 없는 사람은 안 중요한 사람입니다

그래서 이게 Degree Centrality라는 함수로 개선할 수 있는데요 그래서 DC로 이렇게 해보시면은 단어별로 이 숫자가 나옵니다

그래서 amazing, ethmosphere, awesome 뭐 이렇게 나오죠

그래서 이거를 정렬을 해서 보려면 pd.

dataframe하고 dc.

items 한 다음에 그냥 이렇게 하면은 아이고 아이고 이렇게 하면은 이제 여기 행번호가 안 붙거든요

열 번호가 안 붙거든요

그래서 여기 143쪽에 보시면은 여기 코드가 있는데 Columns 이렇게 하면은 열 이름을 붙여주죠

이거를 뭐 dcf 이렇게 하고 dcf.

sort values centrality 순으로 정렬하고 싶으시면 centrality라고 써주시면 됩니다

그 다음에 ascending은 pulse 이렇게 써주시면은 centrality가 높은 거에서 낮은 거 순으로 정렬을 해줘요

centrality가 제일 높은 단어가 vegas고 그 다음에 real time going 이렇게 되죠

vegas라는 단어가 다른 단어랑 함께 쓰인 경우가 많아요

아마 이 맛집 리뷰를 las vegas 맛집 리뷰를 썼을 수도 있을 것 같다는 생각이 드네요

그래서 이런 식으로 우리가 이제 centrality가 높은 단어를 볼 수가 있습니다

여기까지 잘 해보셨나요

그 다음에 이제 연결 중심성은 사람으로 치면 친구가 얼마나 많냐

이 얘기인데 매개 중심성이라는 것도 있습니다

매개 중심성은 예를 들면 우리가 이제 그 사람이 친구가 많은 건 아닌데 여기에 어떤 사람이 있고 그 다음에 여기에 어떤 사람이 있을 때 A에서 A하고 B하고 만나려고 한다

그러면 이렇게 아는 사람 소개소개로 만날 수 있겠죠

근데 C라는 사람을 거치면 이제 B라는 사람을 만날 수 있어요

내가 A가 다른 사람을 또 만나고 싶어요

D라는 사람을 만나고 싶은데 또 소개소개하다 보니까 중간에 C를 또 거치네

어 신기하다

그 다음에 또 E라는 사람을 만나고 싶은데 또 이렇게 가다 보니까 또 C를 거쳐요

그래서 아니 뭘 만나도 C랑 거치는구만

그럼 C가 중요한 사람인 거죠

그래서 C 자체가 꼭 많은 사람을 알 필요는 없습니다

많은 사람을 알 수도 있지만 이렇게 되면 C가 아는 사람은 별로 없잖아요

C가 아는 사람은 이렇게 3명밖에 없지만 결국 C를 거치지 않으면 다른 사람하고 만날 방법이 없는 거죠

만약에 이런 식으로 된다

그러면 C가 스스로 아는 사람은 많지 않아도 중요한 단어가 되게 됩니다

그래서 매개 중심성은 단어하고 단어의 최단 경로를 찾아요

그래서 예를 들면 A에서 D까지 가려면 어떻게 가야 제일 빨리 갈 수 있냐

그걸 찾은 다음에 그 최단 경로에 포함되는 카운트를 세가지고 가장 많은 최단 경로에 포함되면 매개 중심성이 높아집니다

만약에 본인이 아는 단어가 많아도 어떤 네트워크 전체 구조가 있는데 여기 네트워크의 어떤 구석에서 서로 아는 단어가 되게 많아요

서로 연결된 단어가 되게 많아요

그러면 이런 경우는 매개 중심성이 떨어집니다

왜냐하면 다른 단어들의 어떤 최단 경로에는 얘는 영향을 안 주기 때문에 구석에서 자기들끼리 아는 사람 되게 많으면 예를 들면 친구는 되게 많은데 되게 작은 협소한 커뮤니티 안에서 친구가 많아요

그러면 사실 그 사람의 영향력이라는 건 별로 없는 거죠

본인 친구가 많지 않아도 이 사람을 거치면 누구든지 알 수 있다

이러면 되게 중요한 사람이 된 거죠

예를 들면 우리나라 기차역 중에 대전이 되게 중요한데 왜냐하면 서울에서 부산을 갈 때도 대전을 거치고 부산에서 광주를 갈 때도 대전을 거쳐서 K-Tex 타고 가는 게 더 빠를 수 있거든요

그러니까 대전 자체가 연결된 도시는 별로 없을 수 있는데 하여간 어딜 가든 대전을 거치는 게 유리한 경우가 많으면 대전이 매개 중심성이 높은 도시다

이렇게 얘기할 수 있겠죠

그래서 매개 중심성은 비트윗리스를 이용해서 계산을 합니다

그래서 계산 방법은 똑같아요

그래서 bc는 nx.

betweenness centrality 그래서 이렇게 계산하시면 되고요 그 다음에 행렬로, 여기 표로 바꾸시려면 똑같은 코드에다가 여기 bc를 bc로 바꾸시면 되겠죠

그 다음에 이제 소트를 해보면 이렇게 됩니다

그래서 아까는 베가스가 1등이었는데 리얼리가 1등으로 바뀌었어요

그래서 베가스가 연결된 단어만지만 베가스를 거쳐서 가는 것보다 리얼리를 거쳐서 가는 게 더 최단 경로인 경우가 많다

이렇게 되는 거죠

기본적으로는 순위가 그렇게 차이가 많이 나진 않는데 왜냐하면 어차피 일반적인 네트워크 구조에서는 하여간 친구가 많은 쪽이 연결된 단어가 많은 쪽이 네트워크 중심에 있는 경우도 많아서 그렇습니다

그래서 어쨌든 이렇게 구해볼 수가 있고요

자 그러면 또 다른 중심성을 알아보도록 하겠습니다

그 다음에 이제 근접중심성이라는 것도 있는데 근접중심성은 비트윈리스랑 조금 비슷한데 약간 달라요

뭐냐면 그 집으로 치면 교통이 편한 동네 이런 느낌입니다

그래서 이 단어에서 다른 단어까지 가려면 직접 연결돼 있으면 한 다리 건너서 가면 되고 간접적으로 연결돼 있으면 두 다리 건너서 가면 되고 또 간접적으로 연결돼 있으면 세 다리 건너서 가면 되는데 그 몇 다리나 건너면 다른 단어까지 갈 수 있느냐 평균 거리를 말해요

그래서 거리가 평균적으로 짧으면 근접중심성이 높습니다

그래서 이제 이것도 구해보면 뭐 구하는 거는 이거는 이제 cc로 계속 구하면 되겠죠

클로즈니스 구하시면 되고 그 다음에 이거는 복사에서 쓰시면 됩니다

거의 똑같은 코드니까 ccf ccf를 정렬을 해보면 그래서 이제 뭘 기준으로 하느냐에 따라서 순위가 조금씩 바뀌어요

그래서 어떤 지표를 쓰는 게 맞냐 라고 하면 정답이 있는 건 아니고 여러분이 생각하시기에 중요한 지표가 뭐냐

나는 다른 단어랑 연결이 많이 된 게 중요하냐 아니면 다른 단어와 다른 단어 사이를 이렇게 연결해주는 비트윤니스가 중요하냐 아니면 다른 단어랑 좀 더 가까이 있는 클로즈니스가 중요하냐

이거는 여러분들이 생각을 하시면 되겠죠

이제 잘 모르겠으면 뭐 아무거나 하셔도 됩니다

어차피 대체로 뭘 해

도 비슷해요

그 다음에 이제 마지막 하나만 더 해보면 좀 특이한 게 있는데 고유백터 중심성이라는 게 있습니다

이 고유백터 중심성의 아이디어는 뭐냐면 우리도 그런 말 하잖아요

옛날에 제가 학교 다닐 때 중학교 때인가

고등학교 때인가 무슨 영어 듣기 뭐 이런 걸 하는데 테이프의 문제가 이런 거예요

경찰한테 과속으로 잡혔어요

그럼 경찰한테 해야 할 말로 올바른 말을 1번 아 잘못했습니다

뭐 이런 거고 2번은 너 내 친구가 누군 줄 알아?

뭐 이런 거였는데 학생들이 다 2번이다 했는데 선생님이 얘들아 그럼 어떡하니?

뭐 약간 이런 식으로 얘기하셨는데 우리도 그런 얘기 많이 하죠

너 내 친구가 누군지 알아?

내가 누구랑 친한지 알아?

옛날에 그 왜 범죄화의 전쟁인가 영화 보면 내가 누구 서장이랑 술도 먹고 뭐 이런 거 나오잖아요

내 친구가 중요하면 나도 중요한 겁니다

중요한 단어랑 연결되어 있으면 중요한 단어다

이런 거 그럼 문제가 이제 그럼 중요한 단어가 는 어떻게 하냐

이게 문제가 되죠

중요한 단어인지 알려면 내 친구들이 중요한지 알아야 되는데 내 친구들이 중요한지 알려면 내 친구들이 또 어떤 단어랑 연결된지 그 단어들이 중요한다는지 알아야 되고 그러니까 이게 지금 닭이 먼저냐

달걀이 먼저냐

이런 문제가 됩니다

근데 이제 수학에서 고유백터라는 게 있는데 이 고유백터는 어떤 행렬이 있을 때 이 행렬을 뭐라고 해야 될까요

분해를 해가지고 그 행렬의 원소들을 어떤 중요도 순으로 알 수 있게 해주거든요

그래서 이제 이 고유백터 분해라는 걸 하면 우리가 인접 행렬을 고유백터로 분해를 하면 이 단어가 얼마나 중요한지를 계산할 수 있어요

그래서 이 문제를 풀 수가 있습니다

수학적으로 그래서 이름이 고유백터 중심성인데 실제로 하려고 하는 거는 이거예요

중요한 단어랑 연결된 단어가 중요한 단어다

이 아이디어가 어디에 쓰였냐면 이제 구글 검색했습니다

구글 검색은 중요한 웹사이트와 웹사이트하고 웹사이트와 웹사이트가 링크로 연결되어 있거든요

그래서 중요한 웹사이트에 링크란 웹사이트가 중요한 웹사이트다

이런 논리인데 그러면 중요한 웹사이트에 링크가 되어 있는 링크가 되어 있는 서로 관계나 알 수 있죠

근데 이게 중요한 웹사이트인지 아니지 어떻게 하느냐

그래서 고유가 분해라는 고유백터 분해라는 수학적인 방법을 써서 이제 이걸 풀게 됩니다

그래서 이거 또 뭐 하는 방법 자체는 똑같아요

그래서 iGEN Vector Entrality 풀시면 되고요

그 다음에 똑같이 데이터 프레임으로 바꿔서 정렬을 해보면 이렇게 되는데 사실 보시면 결과적으로는 비슷하다는 걸 알 수 있고 리얼리가 저쪽 뒤로 갔죠

그래서 리얼리는 연결된 단어는 많지만 여기 보면 디그리는 높죠

디그리는 높으니까 연결된 단어는 많지만 우리가 iGEN Vector Entrality로 바꿔보면 여기서는 순위가 되게 낮은데 중요한 친구들이 친구는 많은데 중요한 친구들이 별로 없는 그런 단어라고 할 수 있겠죠

그래서 우리가 어떤 지표로 계산에 따라서 다른 결과를 보여주게 됩니다

자 다시 시작을 자 다시 시작을 해보도록 하겠습니다

그래서 우리가 지금 하고 있는 내용을 다시 좀 정리를 해보면 굉장히 긴 과정을 거치고 있는데요 단어들이 각각의 문서에서 쓰였으면 1 안 쓰였으면 0 이렇게 바꾼 다음에 그거를 이제 인접 행렬 형태로 바꿔요

그 다음에 거기에서 향상도를 계산을 합니다

그래서 단순히 두 단어가 얼마나 많이 썼는지가 아니고 예상보다 많이 쓰였는지 만약에 자주 쓰는 단어라면 다른 단어랑 같이 쓰여도 아까 예를 들면 12%의 문서에 나온 단어가 있죠

그러면 다른 단어들이 그 단어랑 별로 관련이 없어도 12% 정도는 같이 쓰이는 경우가 생긴다는 얘기예요

그러면 그거를 통제를 하려면 기대보다 얼마나 많이 쓰인지 리프트를 계산을 하면 됩니다

리프트를 계산해가지고 리프트가 2가 넘는 경우만 출연한 다음에 그거를 네트워크 형태로 변환을 해요

그 다음에 이제 우리가 어떤 단어가 어떤 단어와 함께 많이 쓰였는지를 볼 수 있고 그 다음에 이제 센트럴리티를 계산을 해서 어떤 단어가 중요한지를 알아볼 수도 있습니다

그러면 이제 이거를 시각화해서 한번 보도록 할게요

그래서 파이비스라는 걸 설치를 해야 되는데 이거 또 아까 우리 아나콘다 프롬프트에다가 PIP 인스톨 파이비스 하시면 됩니다

그래서 설치는 금방 끝날 거고요 여기 시작버튼을 누르시고 아나콘다 3 한 다음에 아나콘다 프롬프트에서 PIP 인스톨 파이비스 하시면 됩니다

설치 혹시 안 되거나 에러나면 말씀해 주세요

자 설치 다들 하셨나요

그래서 이거를 시각화 하는 방법은 간단한데 여기 인포트 해주시고요

그 다음에 여기 나머지 코드를 복사해서 붙여넣어주시면 됩니다

이렇게 하면 지금 그 뭐죠

인터넷 익스플로러가 뜨는데 이거는 가상피시 설정이 인터넷 익스플로러를 기본으로 해놔서 그렇거든요

인터넷 익스플로러는 다드시고 여기 보시면 여러분 작업하는 폴더에 nx.html이라고 생겨 있어요

이거를 더블 클릭해서 열어보시면 로딩하는데 좀 시간이 걸리는데요 잠깐 기다려 주시면 네트워크가 이미지로 로딩이 됩니다

조금 시간이 걸려요

그래서 그 여기 코드에서 이거 비스점 쇼는 하지 마시고 수동으로 nx.html 클릭을 해주시면 됩니다

그러면 이제 이렇게 로딩이 되는데요 이게 지금 계속 움직이잖아요

이거를 그 못 움직이게 하려면 여기 아래쪽으로 가시면 그 옵션이 있는데 여기 옵션에서 옵션에 보시면은 댐핑이라는 옵션이 있거든요

댐핑이라는 옵션을 조금 키워주시면 돼요

그러면은 이렇게 움직임이 좀 둔해지는데 아이고 이거 확실하게 둔하게 하려면 댐핑을 확 키워주면 됩니다

댐핑을 한 0.4 이렇게 키워주시면 이제 더 이상 안 움직이죠

그래서 여기서 하시고 클릭하시고 그 옵션의 댐핑을 한 0.4 정도로 높여주시면 됩니다

그래서 이제 단어를 하나 잡아 가지고 이렇게 움직여 보시면 그 단어랑 연결된 단어를 보여주거든요

그래서 예를 들면은 푸드를 이렇게 움직여 보면 푸드랑 연결된 단어를 이렇게 보여줍니다

단어 이 글자들을 좀 키우고 싶으시면 여기 하단에 옵션을 보면은 그 폰트 사이즈가 있는데 폰트 사이즈를 이렇게 키워주시면 단어가 크게 나오죠

그래서 여기 그 옵션들을 수정을 해

가지고 이게 옵션이 좀 알아보기가 쉽지는 않는데 글자를 빨간색으로 바꾸시려면

요걸 요렇게 어 안 되네

어떻게 하더라

여기를 어플라이 하시면은 어 왜 안 되지

아 그러니까 이제 이런 식으로 하실 수 있고요 그래서 연결된 요런 단어를 이렇게 볼 수가 있습니다

아 그래서 아까 우리는 이제 코드로 뭐 스테이크랑 연결된 단어가 뭐냐

이렇게 봤는데 이렇게 하면은 시각화해서 볼 수가 있는 거죠

지금 보시면은 이게 연결 구조가 너무 좀 복잡한데 아 이거를 좀 더 낮추고 싶다

그러면은 어떻게 하시면 되냐면 여기 보면은 그 우리 앞으로 맨 앞으로 돌아가서 여기 MP점 외어 하는 데 보시면은 리프트가 이 이상인 것만 남겨라

이렇게 됐는데 저 연결 구조가 너무 복잡하잖아요

그럼 좀 이거를 컷을 높이시면 됩니다

예를 들면 한 5로 높이면 연결 구조가 이제 5 이상인 것만 해라

라고 하면은 요거를 새로 고침하시면 상대적으로 굉장히 그 연결 강도가 강해야만 이게 남았겠죠

역시 이거를 댐핑을 좀 높여주시고요 댐핑 그래도 여전히 연결된 단어가 좀 많아요

왜 이렇게 많지 5 정도는 안 되고 한 10정도를 해봅시다 10p 새로 고침 사실 지금 우리 데이터가 이게 기본적으로 단어가 다 합쳐서 몇 개 없다 보니까 한두 개만 나와도 사실 리프트가 되게 좀 약간 과대 계산 되는 경향이 있거든요

여전히 너무 많네

이러지 리프트 기준 컷을 10을 넘는다고 20 20은 너무 크게 했군요

한 15로 합시다

이거 뭐 코드가 잘못됐다 잠깐만요 연결이 이렇게 많으면 안 되는데 어디 봅시다

넷 비스 프로무 nx 혹시 쇼를 안 하면은 아 이 쇼를 안 해서 그랬군요

이거는 닫아주고 네 쇼를 한번 해주시긴 해주셔야 됩니다

기본 연결 파일을 어떻게 바꿀 수 있는데 일단은 지금 그 리프트의 컷트라인을 많이 높인 다음에 그 다음에 이제 네트워크를 그리게 하니까 네트워크 구조가 훨씬 단순해졌죠

글꼴을 좀 키워놓겠습니다

그래서 보시면은 여기 런치가 있는데 런치랑 연결된 단어가 브랙 파스트 그 다음에 밀 그 다음에 슬로우 점심인데 빨리 빨리 안 나오면은 좀 짜증나죠

그 다음에 뭐 테이스트랑 연결된 단어는 뭐 후레시 웨이 뭐 이렇게 되고 그 다음에 또 보시면은 뭐 또 뭐 있을까요?

쓰시가 있는데 쓰시는 퀄리티랑 연결되어 있고 그 다음에 여기 웨이트랑 보시면 웨이트랑 연결된 단어가 밀리츠 그러니까 이제 기다렸다

라는 거랑 뭐 얼마나 기다렸다

이런 거랑 관련이 있겠죠

그 다음에 시간이랑 오더 주문이랑 관련이 있고 주문은 메뉴랑 관련이 있고 그 다음에 이렇게 보시면은 훨씬 단어들의 관계가 좀 더 뚜렷하게 나타나는 거를 볼 수가 있습니다

근데 이제 리프트의 기준값을 높이면 그만큼 이렇게 네트워크가 끊어지는 경우가 많이 생기거든요

예를 들면 스테이크는 기준점을 너무 높여 놓으니까 연결된 단어가 없어요

그래서 이거는 그 여기 리프트의 기준값을 좀 적당히 설정해서 뭐 예를 들면 한 10 정도 m점섬을 해보면은 이게 이제 연결이 얼마 되는지 알 수 있겠죠

이게 72만 실제로는 35개만 연결이 있는 겁니다

아이고 다시 해주고 X플로론은 그냥 닫아주세요

그 다음에 여기서 이제 새로 고침을 하면 좀 더 이제 촘촘하게 네트워크가 나오죠

반대, 10은 또 너무 높은 것 같습니다

10은 너무 높고 한 5 432금이 또 연결관계가 너무 많은데 적당히 한 8?

156 뭐 한 이 정도면 되겠죠

그래서 다시 실행을 해주면 X플로론은 닫아주고 여기서 새로 고침해주시면 좀 더 연결된 구조를 볼 수가 있죠

그래서 이거를 적당하게 보기 좋은 컷트라인을 고르셔가지고 이거는 이제 우리 눈으로 보려는 목적이니까 절대적인 수치까지는 필요 없고 그리고 단어들 간의 관계를 어느 정도 컷트라인을 정해서 컷트라인 이하의 단어들은 잘라내면 연결 구조를 잘라내시면 됩니다

그래서 뭐 예를 들면 우리가 여기서 보면 뭐로 할까요?

스테이크 같은 경우는 베스트랑 연결되어 있고 그다음에 브랙퍼스테이크 같은 경우는 보시면 아침하고 런치하고 연결되어 있죠

아침하고 런치하고 연결되어 있고요 그다음에 부패하고도 비패하고도 연결되어 있고 보통 이제 조식 부패 같은 걸로 많이 먹으니까 아마 그렇지 않을까요?

이런 식으로 이제 어떤 단어하고 어떤 단어가 이렇게 연결되어 있는지

이거를 보면은 리뷰에서 어떤 점들이 서로 같이 언급되는지

이런 거를 좀 볼 수가 있습니다

서비스하고 연결된 단어를 보면 슬로우인데 슬로우 하면은 느리다는 거죠

서비스가 느리다

이런 거를 할 수 있고 그래서 이런 식으로 단어들 간의 연관관계를 시각화해서 볼 수가 있습니다

채팅에 질문 해주세요

결과창 쇼 말고 띄우는 방법 한 번만 더 말씀해 주실 수 있나요?

아 해결하셨어요?

이거 기본 프로그램을 익스플로우로 말고 딴 걸로 바꿀 수 있을 것 같은데요 그냥 방법이 있겠지만 이거 쇼를 하신 다음에 익스플로우로 뜨면 그냥 우클릭해서 닫아주세요

그래서 익스플로우로는 닫고 크롬에서 크롬으로 이게 익스플로우가 여러가지 지원을 안 하는 게 많아서 익스플로우에서는 아예 이 그림이 안 뜨더라고요

그래서 크롬에서 해주시면 아, 이거 이거 이거 이거 크롬에서 해주시면 자, 또 질문 있으시면 질문 해주세요

이거 한번 찾아볼까요?

5bSON 페이지에 가면 있을 건데 브라우저를 지정을 못하나요?

이게 아마 대상에 브라우저 지정은 안 됐던 것 같아요

한번 공식 문서를 봐야 되겠습니다

다큐멘트이셧 아, GENERATE HTML 이렇게 하면 될 것 같은데요 한번 해볼까요

GENERATE HTML 아, 이렇게 하면 파일러 저장은 안 해주는군요

저장만 하려면 SHOW 하면 Right HTML 아, 그렇게 해서 따로 저장하자는 말씀이시죠?

그렇게 해도 될 것 같고요 네, 그렇게 하셔도 되고 사실은 원래 보통 웹 브라우저가 크롬이 기본으로 되어 있기 때문에 사실 여러분이 개인 PC에서 할 때는 이게 문제가 안 되거든요

지금 이게 가상 PC 기본 브라우저가 익스플로로로롬이 되어 있어서 그런데 잠깐만요, PISS 점 이렇게 하면 되나?

아, 이렇게 하시면 됩니다

아, 이렇게 하면 되죠

아, 이렇게 하시면 됩니다

간단해

여기다가 컵마하고 펄스 넣어주시면 익스플로로롬 대신에 크롬으로 떠요

이렇게 해주세요

여기 펄스 하나 추가해주시면 항상 공직문서를 봐야 된다는 경우 이렇게 하시면 크롬으로 되죠,

이렇게 하시면 됩니다

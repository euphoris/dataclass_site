# 이미지 생성

## GAN Generative Adversarial Networks
*   이미지 생성 기술
*   2014년 Ian Goodfellow가 처음 제안
*   GAN의 기본 개념은 서로 경쟁하는 두 개의 신경망, 생성자와 구분자를 학습

### 생성자와 구분자
*   생성자 (Generator)
    *   생성자는 무작위로 생성된 잡음(Noise) 또는 낮은 차원의 랜덤 벡터를 입력으로 받아, 합성된 이미지를 생성
    *   생성자의 목표는 판별자를 속이기 위해 가능한 한 실제 이미지와 유사한 이미지를 만드는 것
*   구분자 (Discriminator)
    *   구분자는 이미지가 생성자로부터 생성된 것인지 아니면 실제 데이터셋에서 온 것인지를 판단
    *   구분자의 목표는 생성자가 만든 이미지를 가짜로, 실제 데이터셋의 이미지를 진짜로 정확하게 구별하는 것

### GAN의 학습 과정
*   GAN의 학습 과정은 생성자와 구분자가 서로 경쟁하는 방식으로 진행
*   생성자는 구분자를 속이는 능력을 향상
*   구분자는 생성된 이미지와 실제 이미지를 더 정확하게 구별하는 능력을 향상
*   미니맥스(minimax) 게임의 일종: 구분자의 최대 성능이 최소화되도록 생성자를 학습
*   생성자가 실제와 구분할 수 없는 이미지를 생성하고, 구분자의 정확도가 50%까지 떨어지면 평형(equilibrium)에 도달
*   실제로 평형에 도달하기는 어려우나 그렇지 못한 경우에도 실용적으로 쓸모 있음

### GAN의 발전
*   2014년 처음 제안 이후 빠르게 발전
*   Yann LeCun: "GAN은 지난 20년 동안 딥 러닝에서 가장 멋진 아이디어"
    *   CNN 발명자, 뉴욕대 교수, 튜링상 수상자, Facebook의 수석 AI 과학자
*   최근에는 이미지 생성에서 확산 모형이 좀 더 각광을 받고 있음

### GAN의 활용: 이미지 생성
*   고품질의 이미지를 생성하는 데 사용
*   새로운 캐릭터 디자인, 가상의 풍경, 패션 아이템 등 다양한 분야에서 사용
*   https://generated.photos/faces

### GAN의 활용: 이미지 변환
*   사실적인 이미지의 생성
*   이미지 대 이미지 번역
*   새로운 디자인
*   질병 진단의 데이터 증강

### GAN의 활용: 텍스트로 이미지 생성
*   텍스트를 바탕으로 사진과 같은 이미지를 생성
*   저화질 이미지를 먼저 생성 후, 고화질 이미지로 생성

### GAN의 활용: 기타
*   영상 또는 이미지의 얼굴이나 사물을 다른 사람이나 사물로 변경
*   데이터 증강 (Data Augmentation): 기존 데이터셋의 다양성을 높이기 위해 새로운 샘플을 생성
*   이미지 복원 및 보정: 이미지에서 노이즈를 제거하거나, 누락된 부분을 복원하는 데 사용하여 품질을 높이거나 오래된 사진을 복원
*   음성 합성, 자율 주행 자동차, 의료 이미징 등 다양한 분야에서 활용
*   이미지 생성에 따른 윤리적, 사회적 이슈 제기

### GAN의 평가
*   사람에 의한 평가: 평가 방식, 평가자에 대한 피드백에 따라 결과가 달라짐
    *   Goodfellow et al. (2016) Improved Techniques for Training GANs
*   Inception score
    *   ImageNet 등에 사전 학습된 모형에 생성된 이미지를 입력
    *   다음 두 가지 특성을 요구:
        *   각 이미지는 여러 분류 중 특정의 확률이 높음 (실제와 비슷함)
        *   생성된 이미지들이 여러 분류에 고르게 분포될 것임 (다양함)
*   Fréchet Inception Distance
    *   사전 학습된 모형에 실제 이미지를 입력했을 때의 활성화 분포와 생성된 이미지를 입력했을 때의 활성화 분포를 프레셰 거리를 이용해 비교
*   이외도 영역 특수적인 평가 방법들이 있음

### GAN의 단점
*   모드 붕괴(mode collapse)
    *   한 종류의 생성된 이미지만 실제 이미지와 구분이 어려울 정도로 유사해지면, 구분자는 이를 구분하지 못하게 됨 → 학습이 멈춤
    *   생성자는 비슷한 이미지만 생성하게 됨
*   사실성(fidelity)을 위해 다양성(diversity)을 희생
    *   GAN으로 생성된 이미지는 모두 비슷
    *   FID, IS, Precision 등 지표는 다양성을 반영 못함
    *   사실성은 정밀도, 다양성은 재현도와 관련
*   감소된 경사(diminished gradient): 생성자와 구분자의 학습 속도 불균형
    *   생성자의 성능이 더 빨리 올라가면, 생성자가 어떤 이미지를 생성해도 구분자가 구분을 못함
    *   반대의 경우, 생성자가 어떤 이미지를 생성해도 구분자가 구분함
    *   어느 경우에도 더 이상 학습이 이뤄지지 않게 됨
*   학습의 불안정: 학습이 잘 되지 않거나 설정에 따라 학습 결과에 차이가 큼

## 확산 모형
*   확산 모형(Diffusion Models): 이미지 생성과 같은 생성 모델링 문제에 대한 접근 방식 중 하나
*   데이터의 노이즈 확산 과정을 역으로 추적하여 원본 데이터를 복원하는 방법을 사용
*   장점:
    *   고품질의 이미지를 생성
    *   안정적인 학습 과정
*   단점: 생성 과정이 상대적으로 느리고 많은 데이터가 필요

### 확산 diffusion
*   확산 forward diffusion
    *   원본 데이터에 노이즈를 점차 추가하여 완전한 노이즈 상태로 만듦
    *   이 과정에서 원본 데이터의 정보가 점차 사라짐
    *   확산 과정은 일반적으로 확률론적인 방식으로 설계
    *   이 과정을 통해 원본 데이터와 노이즈가 혼합된 상태를 얻을 수 있음
*   역확산 reverse diffusion
    *   생성 모형을 학습시켜, 완전한 노이즈 상태에서 원본 데이터를 복원하려고 시도
    *   노이즈를 점차 제거하여 원본 데이터에 가까운 이미지를 생성하는 것이 목표
    *   신경망을 사용하여 수행되며, 각 단계에서 노이즈를 제거하는 방법을 학습

### Stable Diffusion
*   오토 인코더의 일종인 VAE를 이용 이미지를 압축(Pixel Space → Latent Space)
    *   생성 과정에서는 랜덤한 값을 사용
*   또 다른 오토인코더인 U-Net으로 역확산
*   CLIP을 이용해 역확산 과정에 방향성을 부여
*   마지막으로 VAE를 이용해 이미지 형태로 복원(Latent Space → Pixel Space)
*   공개 모델 https://stability.ai

{/* 
# 이미지 생성

이런 얘기를 드리고요 인베딩 검색 이거는 이거는 건너뛰고요 기술적인 얘기라 그리고 그다음에 이제 또 재밌는 것 중에 이제 적대적 사례라고 있는데 이거 첫날인가 아마 보여드렸던 거 같은데 이게 어떤 ai를 속일 수가 있습니다

그래서 이제 딥러닝 모델을 이제 속이는 그런 거를 이제 적대적 사례라고 하는데 이제 사람 눈으로 보기에는 이제 구별이 안 가는데 어떤 모델이 취약한 약점을 이용을 해서 모델이 혼란을 빠뜨리게 하는 거죠

그래서 여기 보시면은 어 이게 이제 도어락 같은 건데 도어락에다가 어떤 이런 잡음을 섞어줘요

근데 잡음을 섞는데 이거를 뭐 99% 이걸 1% 이렇게 섞으면 이 오른쪽에 보시면 사람 눈으로 보면 뭐 약간 얼룩덜룩하긴 하지만 별 차이 없거든요 왼쪽이랑 근데 이게 ai 모델로 분류를 하면 타조로 분류됩니다

그러니까 이런 노이즈 때문에 어떤 방해를 받는 거예요

또 다른 거를 보여드리면 이제 여기에다가 이런 노이즈를 0.07만큼 그러니까 0.7% 섞은 거죠

그러면 사람 눈으로 보기에는 똑같은데 이게 원래 판다로 분류되던 게 원숭이로 잘못 분류가 되기도 합니다

그러니까 이게 원리가 어떻게 되냐면 우리가 이제 판다가 있고 원숭이가 있으면 이런 어떤 경계선을 찾는 거거든요

결국 그럼 어떤 판다 이미지가 이렇게 있는데 이거를 이 노이즈를 더해준다는 게 살짝 원숭이의 이 경계선으로 보내는 거예요

그러면은 ai 모델이 보기에는 이 경계선이 오른쪽으로 넘어왔으니까 원숭이로 분류가 되는 거죠

근데 이게 가능한 이유가 뭐냐면 현실에서는 판다하고 원숭이는 사실 별로 비슷하지가 않기 때문에 원숭이들이 이렇게 있으면 판다는 여기에 이렇게 있을 거예요

중간에 이제 어떤 공백지대가 있거든요

중간에 공백지대가 있는데 그럼 경계선이 뭐 이렇게 그어질 수도 있고 아니면 뭐 이렇게 그어질 수도 있고 아니면 뭐 이렇게 그어질 수도 있고 경계선을 어떻게 그어도?

어 성능은 100% 나오거든요

왜냐하면 판다랑 원숭이랑 반반 섞인 개체 이런 거는 세상에 존재하지 않기 때문에 사실 이제 경계선이 여기서 굉장히 이제 어떤 유연성이 있습니다

그러면 어떻게 운 좋게 경계선이 이제 그어지면 여기 판다고 원숭이인데 뭐 경계선이 이런 식으로 그어질 수가 있는 거예요

이 판다를 살짝만 옮겨주면은 사람 눈으로 보면 사람은 사람의 마음속에 있는 경계선이 이렇게 되어 있는 거죠

이건 사람이고 이거는 ai면 사람 마음속에서는 여전히 판다라고 하는 거예요

그런 거죠

그래서 페이스북에 있는 데에 이 판단이 있는 거죠

그래서 판단이라는 게 지금 어떤 AI의 어떤 경계선에서는 원숭이로 잘못 분류되는 그런 거를 이제 만들어낼 수 있습니다

그래서 이런 게 이제 적대적 사례라고 할 수 있고요 그래서 이제 또 다른 이미지에서만 이게 가능한 게 아니라 자연화 처리 이런 거에서도 가능합니다

그래서 이거 이제 논문에서 가져온 예시인데 왜 그는 걷기를 하냐 그러면은 이제 답은 운동하려고 걷는다

이런 건데 어떤 특정 표현을 넣어서 why, how, because 이런 표현을 넣으면 어떤 특정 표현을 넣어서 why, how, because 이런 표현을 넣으면 그는 걷기 하는 게 아니라 어떤 자세한 표현을 넣으면 그를 하고 있는 거죠

얘가 여기서 갑자기 혼란에 빠지면서 미국 사람들을 죽이려고 미국인들을 죽이기 위해서 이런 표현을 만들게 할 수 있어요.

모든 모델에서 되는 건 아니고 모델마다 어떤 특성이 있는데 모델의 특성을 역으로 찾아내가지고 얘가 우리가 원하는 어떤 특정한 말을 하게 하는 거죠.

그래서 채찌 PT에도 이게 됩니다.

그래서 되게 인기 있는 분야 중에 하나가 채찌 PT 제일 브레이킹이라고 해가지고 채찌 PT는 원래 욕도 못하게 돼있고요.

정치적인 말도 못하게 돼있고 성적인 표현 이런 것도 못하게 돼있거든요.

근데 어떻게 채찌 PT를 잘 꼬셔가지고 얘한테 욕을 하게 만들까 성적인 표현을 하게 만들까 아니면 폭탄 제조법을 말하게 할까

이런 거 연구하시는 분들이 있어요.

대학에서.

그래서 추석에 집에 내려가면 뭐하니?

그럼 요즘 채찌 PT한테 욕설 시켜요.

이런 말은.

왜냐하면 그런 거를 취약점을 찾아내는 방법을 알아내야 거꾸로 그걸 이용해서 보완을 하니까 그런 공격 방법을 연구를 하는 거죠.

그다음에 이거는 원픽셀 공격이라고 앞에는 잡음을 섞는 건데 잡음을 섞는 게 아니라 여기다 점을 하나 어떻게 잘 찍으면 혼동에 빠트릴 수 있습니다.

그래서 이런 걸 원픽셀 공격이라고 하는데 이런 게 가능한 경우도 있다.

점 하나만 잘 찍어도 여기 보면 아기가 있는데 여기다 점 하나 잘 찍어서 이거를 베개로 잘못 오분류하게 시킨다든지 이런 식의 어떤 사례들도 보고가 되고요.

그다음에 적대적 패치라고 해서 원래 이렇게 사진을 보여주면 이걸 바나나라고 하는데 여기다가 이런 그림 조각을 하나 놓고 여기다 보면 여기 토스터라고 오분류를 하는 거죠.

왜 그러냐면 이게 사실 이 이미지가 토스터들을 굉장히 어떻게 중첩을 시켜가지고 토스터 토스터 토스터 굉장히 강렬한 어떤 그런 자극이에요.

우리도 보면 이렇게 착시 현상 같은 걸 느끼듯이 AIA 특성을 이용한 일종의 착시라고 할 수 있습니다.

이런 식으로 이제 적대적 패치 이런 거를 만들기도 하고요.

그다음에 이제 여기에서 나온 기술이 적대적 생성망이라는 건데 .

이 적대적 공격의 원리를 잘 생각을 해보면 뭔가 AI를 속이는 거잖아요.

그러면 이제 사람들이 이 생각을 합니다.

AI를 속이려고 하면 방어도 AI로 하면 되겠다.

그래서 이게 적대적 공격인지 아닌지를 판별하는 AI를 만들자.

그러면은 다른 사람들이 그럼 그 AI도 속이면 되지.

그러면 그 속이려는 AI도 또 막으면 되지.

약간 창과 방패의 싸움인 거야.

그러면은 얘네 둘이 창과 모든 것을 뚫는 창과 모든 것을 막는 방패를 부딪치면 무슨 일이 벌어지냐

이 생각이 드는 거죠.

그래서 그 아이디어를 끝까지 발전시켜서 만든 게 이제 적대적 생성망.

영어로는 GAN이라고 하는 방법인데요.

어떻게 하냐면 이제 어떤 노이즈를 만듭니다.

그리고 이 노이즈에서 생성자 얘는 속이는 애에요.

사기꾼이라고 합시다.

사기꾼.

그래서 얘는 아무 의미 없는 노이즈를 가지고 어떤 페이크 이미지를 만듭니다.

그럴듯한 페이크 이미지를 만들어서.

안 되는데.

그럼 이 뒤에 이제 디스크리미네이터 구분마왕이라고 하는데 얘는 이제 일종의 경찰 같은 역할이에요.

그래서 이게 진짜 어떤 현실의 이미지인지 아니면 사기꾼이 만든 가짜 이미지인지를 판별을 합니다.

진짜면 리얼 가짜면 페이크 이렇게 구별을 해요.

그래서 이 경찰 구분마왕의 목적은 사기꾼을 가장 잘 적발을 하는 거고 사기꾼의 목적은 요 경찰을 잘 속이는 겁니다.

그래서 요거를 학습을 시키면 사기꾼은 사기꾼대로 실력이 오고.

올라가고 경찰은 경찰대로 실력이 올라가겠죠.

그러다가 결국에는 사기꾼이 이길 건데 왜냐하면 사기꾼이 진짜랑 완전히 똑같은 이미지를 만들면 경찰이 구별할 방법이 없겠죠.

그래서 둘이 점점 점점 점점 실력이 올라가다가 어느 순간 얘가 정말 리얼한 이미지를 만들게 된다.

그래서 요런 방법으로 이미지 생성을 하겠다라는 게 이제 겐이라는 기술의 아이디어가 됩니다.

그래서 이제 요게 2014년에 처음 나왔는데 2014년에 처음 나왔을 때.

생성할 수 있던 수준은 요 정도 수준이었어요.

보시면은 굉장히 흑백에다가 얼굴도 되게 작고 머리카락이나 이런 것도 못 만들었어요.

그러다가 2015년, 2016년, 2017년, 2018년, 2020년까지 발전을 하면서 이제는 보면은 언뜻 봐가지고는 진짠지 가짠지 구별이 거의 안 되죠.

요 사람의 머리카락 하나에 하나까지 전부 AI로 만든 가짜 이미지입니다.

그래서 이제 겐이 요런 식으로 이제 점점 발전했고.

것을 알게 statel.net도 공식 그렇게 만들어서 아 근데 약간 애정 proclaimed. 그런데 사실 아직까지도 이 완전히 실제 같은 이미지를 만드는 데는 좀 어려운 것입니다.

특히 어디서 보시면 되냐 하면 귀를 보시면 아직까지 애 디가 좀 납니다.

왜냐면 이게 이제 합성 고신경망으로 주로 생성을 하기 때문에 생기는 문제인데.

귀가 양쪽이 멀거든요.

좀 힘들게 만들었거든요.

못 다룬다

이런 얘기를 했어요

특성상 왜냐하면 작은 부분을 모아서 전체를 만들기 때문에 요 귀를 만들 때는 귀 주변에 있는 것들끼리 영향을 주고 이쪽 귀를 만들 때는 이쪽 귀 주변에 영향을 주는데 문제는 사람 귀라는게 양쪽이 비슷해야 되거든요

근데 이런 대부분의 갠 들이 보면은 그래서 귀가 약간 짝짝이에요

그래서 이제 나중에 터미네이터 영화처럼 AI가 지배하는 세상에 오면 귀를 잘 보시고 귀가 짝짝이면 총으로 쏘시면 됩니다

그래서 이런거는 아직까지 좀 단점이 있다

이런 얘기고 그래서 여기 보시면은 가끔 좀 이상하게 생성되는 데도 있어요

이런거 이상하게 생성되죠

근데 전부 굉장히 자연스러운 사람 얼굴 같은거는 이제 뭐 엄청나게 자연스럽게 만들 수 있구요

그래서 이제 이런거를 뭐 캐릭터 디자인을 한다든지 패션 아이템 같은걸 만든다든지 그래서 여긴 다 사람 얼굴인데 옷을 만들어 보라고 한다든지 신발을 만들어 보라고 한다든지 이러면은 이런거 디자인 하는 것도 가능하죠

그 다음에 이제 요 갠 기술을 그 예를 들면 얼룩말 사진을 말 사진으로 바꾼다던가 아니면 말을 얼룩말로 바꾼다던가 이런거를 하는데도 쓰구요

어떻게 하냐면 얼룩말 사진을 주고 사기꾼한테 야 이거를 말로 바꿔서 그려봐 그 다음에 진짜 말 사진을 어디서 찍어와요

그 다음에 탐정 경찰한테 둘 중에 어느 쪽이 진짜야

이렇게 물어보는 거죠

그걸 계속하다 보면 얼룩말을 가지고 말로 바꾸는데 티가 안나게 바꿀 수가 있습니다

원리는 이제 다 똑같아요

화풍을 바꾼다던지 아니면 손으로 스케치 한거를 색깔을 칠해준다던지 뭐 아니면 흐린 그림을 선명하게 만든다던지 이런식으로 이미지 변화도 할 수 있구요 그 다음에 이제 텍스트도 텍스트로 이미지를 만드는 것도 가능하죠

그래서 이것도 어떻게 하냐면 이미지를 가지고 설명을 만들어요

진짜 이미지가 있고 설명을 만들어 진짜 이미지가 있고 설명이 있는데 반대로 설명을 가지고 가짜 이미지를 만든거죠.

이 설명에 따라 이미지를 만들었을 때 사기꾼 AI가 하는 일은 설명으로 텍스를 만드는거고 경찰 AI가 하는거는 이 사진이 진짜인지 아니면 설명만 보고 지어낸 이미지인지 이거를 맞추는걸 하는겁니다.

둘이 계속 싸움을 붙이면 결국에는 말만 가지고 그럴듯한 이미지를 생성할 수 있겠죠

그래서 이걸 가지고 딥페이크 하는데도 쓰구요 우리가 요즘에 사회적으로 문제가 되는 그런 기술을 만들듯 쓰고 그 다음에 데이터 증강을 할 때도 지금까지는 데이터 증강하면 회전을 좀 시키거나 색깔을 바꾸거나 이렇게 하는데 그럼 이미지가 있는데 사진을 좀 불리고 싶다.

그러면 원본을 주고 이거를 좀 비슷하게 더 그려봐라.

이렇게 시키면 약간씩 차이를 도가면서 리얼한 이미지를 만들 수 있겠죠

그래서 데이터 증강하는데도 쓸 수 있구요.

여러가지 용도로 쓸 수 있는데 이게 굉장히 문제는 사회가 많습니다.

사실 요즘에 딥페이크 이런 얘기 들어보셨겠지만 내가 하지도 않은 일을 한 것처럼 가짜로 사진을 만들어서 나를 뭐 모욕하거나 명예를 훼손하거나 아니면은 모함을 하거나 이럴 위험이 있고 사실 이제 음성 같은 것도 요즘에 너무 합성이 잘 되기 때문에 사실 이제 화상통화 보이스피싱에 아마 지옥이 좀 펼쳐질 가능성이 있습니다

내 목소리를 한 5분 정도만 있으면 지금 똑같이 카피할 수 있거든요

그래서 내 목소리를 나랑 이제 전화 걸어가지고 나한테 전화 걸어서 멀쩡한 통화인 척하고 또 통화를 이제 한 5분 정도 통화를 유도한 다음에 목소리를 녹음해가지고 그걸 카피 AI로 카피를 떠서 우리 가족한테 전화 걸어서 아 나 교통사고 났어 돈 좀 보내줘

그러면 이제 의심이 가서 화상통화로 바꿔봐 화상은 딥페이크로 만들어가지고 아직까지는 뭐 보이스피싱 하자고 그 정도 하기에는 너무 기술적으로 어려운데 이 기술이 점점 발전하면서 쉬워지면은 약간 이제 그런 이슈도 있습니다

이걸 이제 어떻게 막을까

이런 것도 현재 굉장히 그 뭐랄까 어려운 이슈가 있습니다

이슈 중에 하나죠

그 다음에 이제 494쪽으로 넘어가서 근데 이제 걔는 이제 단점이 여러 가지가 있는데 기본적으로 얘가 이제 경찰을 속이도록 학습을 하는데 문제는 이제 보이스피싱 같은 것도 보면은 그 피싱 수법이 맨날 똑같거든요

맨날 뭐 아 나 교통사고 났어

너 목소리가 왜 그래

아 사고가 너무 심하게 났나봐 하면서 이제 수법이 사실 몇 가지로 제한돼 있죠

근데 왜 제한돼 있냐면 어쨌든 그 기법이 잘 먹히니까 그 기법만 계속 쓰는 겁니다

잘 먹히는 기법만 계속 써야죠 굳이 뭐 이것저것 다양한 기법을 쓸 필요가 없어요

사기꾼들은 근데 이제 걘도 마찬가지인데 사기꾼 AI랑 경찰 AI를 경쟁을 시키는 건데 그럼 여러 가지 그림 중에 이 경찰 AI가 잘 속는 어떤 그림이 있을 거예요

근데 여기 오른쪽 보시면 타조를 그리라고 하면 타조가 다 좀 비슷하거든요

홍학을 그리라고 하면 홍학이 다 비슷하고 햄버거를 그리라고 하면 묘하게 햄버거 다 비슷합니다

그러니까 이런 그림이 경찰이 잘 속는 그런 그림인 거죠

그래서 이걸 이제 모든 것들이 그래서 이걸 모두분괴라고 하는데 비슷한 것만 계속 만드는 거예요

이게 속으니까 먹히는 것만 계속 만드는 거죠

그래서 다양성이 좀 희생되는 경향이 있다

그리고 그다음에 이제 얘네 둘이 경쟁을 하는데 갑자기 경찰이 너무 빨리 치고 나가서 사기꾼이 좀 될랑 말랑 하면은 다 이겨버린다

그러니까 경찰을 좀 속이는데 성공을 해야 얘도 실력이 느는데 어떻게 해도 안 속는 거예요

그러면은 사기꾼 AI가 발전을 못하겠죠

반대도 마찬가지인데 사기꾼 AI가 초반에 너무 잘해버리면 경찰이 구별할 방법이 없습니다

구별을 해야 내가 성장을 하는데 구별을 못하니까 성장을 못하는 거죠

그래서 뭐 진짜인지 안 진짜인지 모르겠는데 요즘에 이제 연쇄살인 이런 게 미국도 그렇고 좀 잘 없거든요

옛날보다 사건이 별로 없는데 그 이유 중에 하나가 이제 사실 뭐 옛날에 연쇄살인이 있었던 이유가 연쇄살인범들이 똑똑해서 그런 게 아니고 그 경찰이 과거에 살인범을 살고 있었는데 과학수사를 못하니까 옛날에 이제 수사능력이 부족으로 못 잡았던 건데 요즘에는 뭐 그런 살인사건 나면은 연쇄까지 갈 것도 없이 잡혀버리기 때문에 CCTV도 있고 뭐 DNA 그것도 있고 뭐 그러니까 이제 연쇄살인하는 사람들이 그게 머리가 좋은 사람들이 아니거든요

보통 머리가 좋으면은 굳이 왜 사람을 죽이겠어요 나쁜 짓 하고 잘 먹고 잘 사는 방법이 세상에 많은데 굳이 그런 리스크가 큰 일을 안 하겠죠

그러니까 보통 연쇄살인범들이 그게 머리가 나쁜데 경찰 이제 옛날에는 과학수사가 안 돼서 이제 활개를 치고 다는데 요즘에는 이제 초반에 그냥 살인사건 하나만 저질러 다 잡히니까 연쇄살인이 안 일어난다

이런 얘기가 있거든요

그거랑 비슷하게 얘네가 실력이 약간 비슷하게 올라가야 되는데 경찰이 너무 잘하거나 사기꾼이 너무 잘하면 다른 쪽이 약간 실력이 늘어날 기회가 없습니다

그래도 이걸 이제 감소된 경사 문제라고 하는데 두 개가 비슷비슷하게 실력이 올라가야 된다

근데 이제 이게 굉장히 어렵습니다

왜냐면 AI 두 개를 학습을 시키는데 얘네 둘이 서로 엎치락뒤치락하면서 서로 발전할 정도로 수준을 맞춰준다는 게 굉장히 까다롭기 때문에 그걸 학습을 하기가 좀 쉽지가 않아요

그래서 요즘에는 이제 이미지 생성을 할 때 확산모형이라는 거를 더 많이 쓰는데요 확산모형은 근데 보니까 어제 논술에 아니 수능에 이게 나왔더라고요

수능 국어 심지어 과학도 아니고 국어문제 확산모형이 나왔는데 혹시 보셨습니까 갑자기 말하다 보니까 생각났는데 일단 좀 이따 보여드릴게요 확산모형은 뭐냐면 근데 그 국어 지문이 정말 읽기가 어렵게 써있더라고요

이 확산모형의 아이디어는 뭐냐면 확산이라는 게 뭐가 퍼지는 거죠

그래서 이제 원래 물리학에서 가져온 건데 이런 생각을 해보시면 돼요

예를 들어 어떤 방이 있는데 방에 이쪽 한쪽 끝에서 여러분들이 이제 쌀 같은 거를 아니면 구슬 같은 거를 확 뿌려요

그럼 구슬이 이렇게 확산이 돼가지고 일정 시간이 지나면 이 방에 구슬이 고르게 퍼집니다

그래서 이렇게 고르게 퍼진 다음에 어떤 사람이 이 방에 들어와 보면 이 구슬들을 어디서부터 볼까요?

어디서 뿌렸는지를 알 수가 없어요

왜냐하면 방에 고르게 구슬이 뿌려져 있으니까 아니면 냄새 같은 거 생각해보셔도 돼요

누가 여기서 방구를 뿜 끼고 도망가면 조금 이따 이 방에 들어오는 사람은 어이 무슨 냄새야

근데 여기서 방구를 꼈는지 여기서 방구를 꼈는지 알 수가 없습니다

왜냐하면 냄새가 골고루 퍼져 있기 때문에 그래서 이제 우리가 이미지 같은 경우에도 이미지에다가 노이즈를 추가하는데 노이즈를 계속 추가하다 보면은 이 이미지에다가 노이즈를 계속 추가하다 보면은 원본이 뭐였는지를 알 수가 없어요

이거를 확산이라고 부릅니다

어떤 원래 이미지가 여기에 있었으면 노이즈를 추가한다는 건 여기서 뭔가 이미지를 이동을 시킨다는 거거든요

계속 이동을 시키다 보면은 처음에 얘가 어디서 출발했는지를 알 수가 없겠죠

여기서 이 시점에서 보면 그래서 우리가 이제 뭘 하냐면 노이즈를 제거하는 모델을 만드는 거예요

그래서 이렇게 노이즈가 있으면 이걸 반대로 되돌리는 이렇게 노이즈가 있으면 이렇게 반대로 되돌리는 모델을 학습을 시킵니다

그거는 뭐 어렵지 않겠죠

왜냐하면 얘가 Y라고 치고 얘가 X라고 치면은 일단 Y 이미지를 구해서 여기다 노이즈를 살짝 섞습니다

그 다음에 이 X를 넣으면 이 Y가 나오게 학습을 시키면 되니까 우리가 앞에 오토인코더 하면서 이런 거 얘기를 이런 게 오토인코더로 된다

이런 얘기를 들었는데 이거 자체가 그렇게 어려운 문제는 아니에요

그럼

그런 식으로 어떤 잡음이 있을 때 잡음을 제거하는 모델을 역확산시키는 모델을 만들면 여기에서부터도 야 여기에 고양이가 있어 잘 봐봐 그러면은 이건가 이렇게 하면서 노이즈를 제거할 수 있어요

맞아

야 여기서 고양이를 좀 더 강조해봐

이렇게 더 이렇게 여기서 점점점점 노이즈를 제거를 해나가는 거죠

그러면은 내가 이쪽으로 가는데 고양이가 있다는 걸 어떻게 확신할 수 있냐

우리가 앞에서 클립에서 어떤 이미지랑 텍스트랑 비교를 할 수 있다고 했잖아요

그러니까 우리가 원래 학습을 시킬 때는 여기 어떤 고양이 사진이 있는데 여기서 이제 노이즈를 쭉 섞어서 여기까지 왔어요

그런데 이제 우리가 출발점을 알 수가 없습니다

그런데 여기서 이제 노이즈를 제거한다는 거는 역방향으로 가야 되는데 우리가 역방향이 어느 방향이 맞는지 모른단 말이에요

근데 여기로 간 다음에 고양이라는 어떤 텍스트에 인베딩하고 우리가 노이즈를 제거한 이미지에 인베딩을 비교해 보면 이쪽 방향이 맞다라는 걸 우리가 알 수 있죠

그럼

그 맞는 방향으로 노이즈를 자꾸 제거를 해나가다 보면은 진짜로 고양이의 이미지를 만들 수가 있는 거죠

그래서 이 방법의 장점은 뭐 이렇게 갠처럼 서로 경쟁을 시키고 이런 게 없기 때문에 굉장히 학습이 안정적으로 잘 되고 그다음에 굉장히 다양한 이미지를 생성할 수 있습니다

여기 오른쪽을 보시면은 타조도 굉장히 다양하고 홍학도 다양하고 햄버거도 다양하고 그다음에 이제 낚시하는 사람도 낚시하는 사람도 다양하고 갠에 비해서 훨씬 다양한 이미지를 만들 수 있고 그래서 훨씬 다양하고 안정적인 이미지를 만들 수 있어요

그래서 여기 보시면은 이렇게 좁아졌다가 넓어졌다가 이렇게 되는데 이게 이제 오토인코더 구조입니다

그래서 요즘에는 이제 말로만 하는 게 아니라 예를 들면 사람 자세를 이렇게 뼈다구로 잡아놓고 이런 자세로 셰프를 그려봐라 그러면 셰프를 그리고 링컨 동상을 그려봐라 이 자세로 링컨 동상을 그리고 이런 것도 되고요 말로만 되는 게 아니라 어떤 윤곽선이라든지 자세 이런 거를 지정할 수 있고 그런 식으로 이제 발전을 하고 있습니다

뒤에는 뭐 안 해도 될 것 같고 그래서 이런 식으로 이렇게 발전을 하고 있습니다

그래서 이런 식으로 발전을 하고 있습니다

그래서 이런 식으로 발전을 하고 있는데 첫날도 질문하셨지만 그래서 이제 설계 같은 것도 이런 걸로 할 수 있냐 라고 하면 할 수 있기도 하고 없기도 한데 사실 현재 기술로는 약간 설계 같은 거에 응용하시기는 좀 어려워요

왜냐하면 이게 하는 방식이 기본적으로 뭔가 잡음을 제거하는 이런 방식이기 때문에 설계 같은 경우는 이렇게 되게 정합적이어야 되거든요

여기에 있는 거랑 여기에 있는 거랑 딱 끼우면 딱 맞아야 되는데 그런 식으로 생성하는 건 잘 안 됩니다

그래서 뭐 이게 이 원리상 그런 식이기 때문에 아마 설계 이런 데다 활용하시기는 이 방법으로는 좀 어려울 것 같다 */}

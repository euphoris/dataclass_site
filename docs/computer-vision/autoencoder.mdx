# 오토인코더

비지도학습도 있어요.

그래서 이미지로 하는 비지도학습의 대표적인 형태로 Auto Encoder 라는게 있습니다.

그거를 좀 알아보면 우리가 일단 지도학습하고 비지도학습을 구별을 해보면 지도학습은 일단 기본적으로 뭔가 정답이 있어요.

그래서 X랑 Y 이렇게 있으면 Y가 정답인거죠.

그래서 이거를 데이터로 우리가 방금 했던 것처럼 데이터로 만드는거고 비지도학습은 뭐 그런게 없습니다.

정답이 없고 그래서 이제 어떨때 쓰냐면 예를 들어서 인터넷 옷 쇼핑몰인데 내가 어떤 옷을 샀어요.

어떤 옷을 샀는데 그러면은 내가 이거랑 비슷한 옷도 살 가능성이 높겠죠.

나의 취향이라는거는 보통 한정되어 있으니까 그러면은 이제 비슷한 옷을 추천을 해줘야 되는데 비슷하다라는게 굉장히 주관적이거든요.

뭘 가지고 비슷하다고 할거냐 하면은 그거는 정답이 있기가 어렵죠.

이거랑 이거랑 비슷한가 라고 하면은 보는 사람에 따라 비슷할수도 있고 아닐수도 있고 그래서 이제 약간 애들 옷 사주는게 되게 어려운데 특히 이제 애들 사이에서 이상하게 유행을 하거든요.

어른들이 보면 다 똑같아요.

이거나 저거나 그럼 뭐 엄마 아빠가 사다주면 아 이건 아니라고 내가 볼땐 다 똑같은데 뭐가 다르다는거야

애들만 볼 수 있는 어떤 차이가 있는거죠.

어른눈에는 안보이고 우리도 어렸을때 보면 다 똑같거든요.

어른들이 보면 다 똑같은데 애들 사이에 어떤 미묘한 그 차이가 있어요.

그러니까 이게 뭐 유사하다라는게 어떤 절대적인 기준이 있는게 아니라 보기 나름인데 어쨌든 어떤 기준으로든 뭔가 유사성을 계산을 할 수 있겠죠.

그래서 이런거는 이제 비지도학습이 됩니다.

그러면은 이제 유사성을 요렇게 계산할 수도 있고 저렇게 계산할 수도 있고 그러면은 아니 뭐 정답도 없는데 그러면은 그걸 뭐하러 하느냐 뭐라도 추천은 되는거죠.

추천은 되는거고 그 다음에 이제 우리가 이제 유사성 모델을 A, B, C, D 이렇게 여러개 만들었는데 실제로 추천을 해보니까 B로 추천했을때 사람들이 제일 구매가 많이 일어나더라

그러면 그 얘기는 뭡니까 유사성을 보는 관점이 여러가지가 있을 수 있는데 우리 고객들은 대부분 B라는 모델하고 비슷한 관점을 가지고 있다

이렇게 볼 수 있겠죠.

그러면은 이 중에 뭐가 정답이 있는건 아니지만 그냥 B로 추천하면 되잖아요.

사람들이 그 관점을 좋아하니까 아니면은 유사성을 계산하는 방식이 여러가지가 있는데 철수라는 고객은 A로 추천을 해주면 좋아하고 영희라는 고객은 B로 추천해주면 좋아하고 그럼 그거에 맞는걸로 추천해주면 되겠죠.

그래서 그런식으로 정답은 없더라도 우리가 그때그때 상황에 맞는 것들이 있기 때문에 그거에 맞춰서 이제 사용을 하면 됩니다.

유튜브나 넷플릭스는 비슷한가요?

그렇죠.

그래서 유튜브도 여러분들이 어떤 영상을 하나 보시면 비슷한 영상이 쫙 나오거든요.

그래서 가끔 시켜보니까 유튜브에 어떤 영상이 있는지 어떤 영상이 있는지 어떤 영상이 있는지 어떤 영상이 있는지 실수로 뭐 하나 눌렀더니 계속 뭐 요즘에 뭐 로제 흑백요리사가 유행이더라구요.

흑백요리사 영상 몇개만 보시면 그 다음부터 여러분 화면이 흑백요리사 영상으로 다 뒤덮입니다.

그래서 이제 유사성을 계산하는데 정확한 유사성 알고리즘은 모르겠지만 유튜브 같은 경우는 사실 영상 이미지를 이용한다기 보다는 텍스트를 많이 이용하는 것 같아요.

왜냐하면은 제목이 비슷한 것들이 굉장히 많이 뜨거든요.

그래서 좀 그런게 있는 것 같고

근데 사실 이제 유튜브 하시는 분들 얘기를 들어보면은 그 왜 알고리즘이 밀어준다

이런 얘기 하거든요.

알고리즘이 밀어준다

이런 얘기를 하는데 그 약간 유튜브 알고리즘이 정확하게 어떻게 돌아가는지를 약간 유튜버들도 잘 모르시는 것 같더라구요.

대충 느낌은 오는데 이게 정확하게 어떻게 돌아가는지 모르겠다.

근데 어쩌다가 이제 한번 밀어주면은 이제 대박 갑자기 100만 유튜버 되고 이런거죠.

근데 뭐 그게 사실 간단한 알고리즘은 아닐거에요.

세계에서 제일 큰 플랫폼 중에 하나인데 그게 그렇게 간단한건 아닐거고 아마 여러가지를 쓸텐데 제 생각으로는 또 그렇게 복잡한걸 쓰지는 않을겁니다.

왜냐하면 유튜브 같은건 사용자가 너무 많기 때문에 수억 명이서 쓰는 서비스인데 알고리즘이 너무 복잡하면 그 계산비용도 만만치 않기 때문에 사실 좀 그렇게까지 정교하게 하지는 않을거 같아요.

왜냐하면 그렇게까지 정교하지 않아도 유튜브에는 재밌는 영상이 많기 때문에 사실 대충 추천해주면 그중에 하나 보면 되거든요.

그래서 약간 이게 추천 이런게 사실 뭐랄까 굉장히 돈 들기가 어려운 것 중에 하나입니다.

왜냐하면 서비스가 커지면 예를 들면 쿠팡 이런식으로 커지면 추천을 좀 잘 못해도 상관없어요.

그래서 마음에 드는게 안 뜨면 검색해서 알아서 찾아가거든요.

사실 넷플릭스도 보면은 넷플릭스 구독해보시면 아시겠지만 원래 넷플릭스가 추천 시스템이 되게 유명한 회사거든요.

근데 막상 넷플릭스 들어가보면 그렇게 화면에 뜨는게 다 추천 시스템으로 결정이 되는건데 막상 넷플릭스 들어가보시면 별로 볼게 없습니다.

왜 그럴까?

그 정도 되면 추천 시스템 그렇게 열심히 안 만들어도 되는거죠.

사실 제 생각에는 그래요.

열심히 안 만들거다.

별로.

만들기야 만들, 잘 만들기야 잘 만들겠지만 생각만큼 그렇게 열심히 안 만들...

보면은 넷플릭스도 보면은 추천 시스템이 의미가 있으려면 사람들 취향이 다 제각각이여가지고 뭔가 맞춤형으로 해주는데 의미가 있는건데 어차피 다 흑백요리사 볼건데 추천을 왜 해요?

그냥 흑백요리사 띄워주면 됐지.

그치?

그러니까 그렇게까지 잘 하진 않을거다.

그래서 제 주변에도 이제 추천 시스템 이런거 만드는 사람들 좀 있는데 다들 괴로워하는...

약간 이게 추천 시스템의 쓸모라는게 되게 애매해요.

너무 인기 없는 플랫폼에도 추천 시스템이 쓸모가 없고.

왜냐 어차피 사용자가 없으니까.

너무 인기 있는 시스템에 추천 시스템도 추천 시스템이 쓸모가 없고.

약간 추천 시스템 잘 만든다고 서비스가 막 되게 살아나는 것도 아니고 좀 어중간한 그런 기술이라고 할 수 있겠죠.

어쨌든 그래서 지도학습, 비지도학습인데 비지도학습의 대표적인 예가 유사성 이런거 계산하는거라고 할 수 있구요.

그 다음에 이제 이미지 압축할 때도 우리가 비지도학습을 쓸 수가 있습니다.

왜냐면은 이미지라는게 어떤 패턴이 있고 그러면 우리가 그 패턴을 알면 압축을 할 때 유용하게 쓸 수 있습니다.

예를 들면 우리가 숫자 3 같은걸 쓸 때 이렇게 쓸 수도 있고 뭐 이렇게 쓸 수도 있고 뭐 이렇게 쓸 수도 있고 여러가지도 쓸 수 있지만 제가 이렇게 써놓고 휙 지워도 여러분들이 대충 복원을 할 수 있어요.

정확하게 똑같진 않더라도 아 아까는 좀 갇힌 3을 썼다.

아까는 좀 이런 3을 썼다.

아까는 둥근 3을 썼다.

그러니까 여러분들이 모양을 정확하게 외울 수는 없는데 대략 비슷하게 기억을 할 수 있습니다.

왜냐면 여러분들이 숫자 3이라는게 어떻게 생겼다는 패턴을 알고 있기 때문에 쉽게 압축을 할 수 있는거죠.

그래서 우리가 이제 어떤거를 기억하려고 할 때 기억하는 요령 중에 하나가 약간 의미를 부여하는 거거든요.

그래서 이제 바둑기사 프로바둑기사들 같은 경우는 바둑판에 돌이 한 200개 쯤 있어도 한번 쓱 보면은 다 외울 수 있습니다.

그래서 전에 유튜브에 신진서 구단이 나오세요

하는 얘기 들어보니까는 보통 바둑기사들이 한 최근에 둔 100판 정도는 그냥 다 기억한다고 하더라고요.

그래서 예전에 막 설날 이럴 때 보면은 바둑기사들끼리 빈 바둑판 두고 바둑놓기 손가락으로 이렇게 돌 없이 손가락으로 바둑놓기 아니면 뭐 유리로 된 투명 유리로 된 바둑알로 바둑놓기.

그래서 흙하고 백이 있어야 되는데 색깔이 다 똑같아요.

근데 그래도 바둑도도 아무 상관 없거든요.

이 사람들은 왜냐면 바둑이라는 것도 패턴이 있기 때문에 이 돌을 위치를 하나하나 따로 기억하는게 아니라 이 어떤 패턴으로 기억을 하니까 빈 바둑판을 놓던, 바둑을 백판을 두던 다 기억을 할 수 있는거죠.

근데 이제 초보자들끼리, 제일 초보가 18급인데 18급 둘이서 바둑돈 다음에 프로 바둑기사한테 보여주면 기억을 못합니다.

왜냐면 수들이 다 말이 안되니까 뭐가 말이 되야 기억을 하지 말이 안되면 기억을 못해요.

그래서 우리가 이미지를 압축을 할 때도 어떤 패턴을 알고 있으면 좀 더 압축을 잘 할 수 있습니다.

그래서 이제 우리가 그 그림파일 중에 jpeg이라고 있는데 jpeg같은 경우는 압축을 할 때 이런 패턴을 그 사용하기는 사용하는데 머신러닝의 패턴을 쓰는게 아니고 알고리즘이 알고리즘 만든 사람이 그냥 이렇게 생각을 해서 요렇게 요렇게 하면 압축을 할 수 있을거야

이런식으로 생각을 해서 만듭니다.

그래서 어떤식으로 하냐면 우선 첫번째로는 그 우리가 이제 rgb가 있으면 요거를 밝기랑 그 두가지 파랑과 빨강의 두가지 색상으로 분해를 해요.

세개의 채널로 분해를 한 다음에 그 다음에 이제 밝기는 남기고 밝기는 남기고 요 색상을 압축을 합니다.

왜냐면 사람들이 밝기는 민감하지만 색깔은 좀 달라도 구별을 못하거든요.

그래서 색깔 정보를 좀 날리고 그래서 여기 보시면은 원래는 이렇게 네가지 색깔이 있었는데 여기 오른쪽을 보시면 밝기는 유지하는데 색깔을 다 날려버린거죠.

그래서 원래 파랑 초록이 있었는데 파랑 파랑 이런식으로 그 다음에 우리가 이제 이 블록으로 그 채널들을 8x8 이런식으로 블록으로 쪼갠 다음에 우리가 이제 이산코사인 변환 이렇게 써있는데 이거는 그 뭐랑 똑같냐면 이산프리에 변환이랑 똑같은겁니다.

프리에 변환을 한 다음에 그 주파수 대역을 쪼개가지고 이 주파수 대역을 어떤 몇개 이렇게 덩어리로 나눠 그래서 덩어리로 나누고 그 다음에 이제 압축을 하는 이런 방식을 씁니다.

그래서 이제 제이팩같은 경우에 그 압축률을 높이면 이런식으로 이렇게 깍두기 모양으로 보이거든요.

이런 파일 보신적이 있을거에요.

왜 이렇게 깍두기 모양으로 보이냐면 기본적으로 고주파 영역을 깎아내기 때문에 그럼 이제 저주파만 남는데 저주파는 이렇게 변하죠.

그니까 이거를 구간구간 이렇게 하면은 뚝뚝뚝 이렇게 보입니다.

여기가 저주파 영역만 남긴거에요.

그래서 보면은 이렇게 완만하게 변하기 때문에 그래서 이제 고주파 영역은 어차피 사람 눈에 잘 안보이니까 깍아내도 되는데 너무 많이 깍아내면은 깍둑깍둑 이렇게 되는거죠.

그래서 이제 제이팩 압축 방식을 만든 사람은 이미지라는게 어떤 색깔과 주파수로 이루어져 있으니까 색깔을 좀 줄이고 주파수 중에 고주파 대역을 날려버리면 사람 눈으로 볼때는 대충 비슷하면서 여기도 보시면 한 요정도까지는 지금 이게 압축률을 이쪽으로 갈수록 높인건데 한 요정도까지는 그래도 우리 눈으로 보면 잘 구별이 안되거든요.

요런데하고 비교해보면 근데 살짝 화질이 떨어져있는데 여기까지 가면 너무 눈에 보이지만 이거를 이제 어떤 이미지의 패턴이라는거를 그냥 자기 머리로 생각을 해서 만든거죠.

그냥 알고리즘을 근데 요렇게 하지 않고 우리가 이제 딥러닝 또는 머신러닝을 이용해서 압축할 수 있지 않을까 요런 생각을 할 수 있습니다.

그래서 고런 생각으로 나온게 오토인코더라는건데 대표적인 이미지 기반의 비지도학습 방법이고 우리가 이미지 생성을 하거나 할 때도 요 방법을 사용을 합니다.

그래서 굉장히 이제 널리 사용되는 방법인데 일단 인코더라는거는 뭔가 변형을 한다는거에요.

변형을 한다는건데 앞에 오토가 붙었잖아요.

오토 라는건 왜 붙냐면 오토인코더는 우리가 이때까지는 지도학습을 X가 들어가면 Y가 나왔는데 오토인코더는 X가 들어가면 X가 그대로 나옵니다.

아니 그러면은 X가 들어가서 X가 그대로 나오는데 이게 뭐하는거냐

이렇게 생각하실 수 있는데 모델 구조를 보시면 X가 Z로 한번 바뀌고 Z가 다시 X로 바뀌는 요런 구조로 되어있어요.

근데 뭐가 다르냐면 Z가 굉장히 작은 크기의 배턴입니다.

원래 예를들면 우리가 MNIST 핸드라이팅 데이터 같은 경우는 가로 28 세로 28이라서 총 780개의 배터리가 있어요.

그래서 780개의 배터리가 784개의 픽셀로 되어있는데 예를들면 여기 그러면은 784 바이트가 필요하거든요.

근데 여기 Z의 크기를 모델 중간에 32 바이트 이렇게 줄여버리는거 그래서 784개의 픽셀이 32개의 숫자로 줄어들었다가 다시 784개의 숫자로 되돌아올 때 원래의 모양을 그대로 유지하게 요런 구조로 모델을 짜는거죠.

그러면은 그게 됩니까 라고 생각하실 수 있는데 왠지 모르게 됩니다.

정확하게 보고는 안되더라도 왠지 모르게 되고 그러면은 그 원리는 모르겠지만 하여간 이렇게 해서 학습을 계속 시키면 X가 들어가면 X가 그대로 나오게 계속 학습을 시키면 이 중간중간에 있는 레이어의 파라미터가 어떻게든 학습이 되서 얘를 압축하는 방법을 학습을 하는거죠.

그 압축된 결과가 모델에 따라 좀 다를 수는 있지만 어쨌든 압축은 잘 된다.

이런 결과가 나오구요.

그래서 요 모델에서 이걸 전체를 오토인코더라고 부르고 요 앞부분을 따로 인코더 요 뒷부분은 따로 디코더 이렇게 부릅니다.

그래서 모델로 학습을 시킬 때는 전체로 학습을 시키고 실제로 쓸 때는 모델을 반으로 잘라서 인코더로 압축을 할 때 쓰고 디코더로 압축을 풀 때 쓰고 요렇게 해요.

요 구조가 나중에 이미지 생성할 때도 쓰는데 왜냐면은 결국에 이 디코더라는 것이 하는 일이 뭐냐면 어떤 압축된 형태로부터 생성을 하는 건데 요 앞에 있는 것이 압축된 형태가 아니라 다른 형태일 수도 있는 거죠.

예를 들면 우리가 30대 남자 얼굴을 그려라

그럼 30대 남자 얼굴이라는 말 자체가 일종의 어떤 이미지에 대한 압축이잖아요.

그럼 그 압축을 푸는 걸로 볼 수 있는 거죠.

이미지를 생성한다는 거.

그래서 이제 요 오토인코더라는 아이디어가 고런대로 활용이 됩니다.

그래서 이제 오토인코더는 왜 비지도 학습이냐 하면은 레이블이 필요가 없어요.

X가 들어가면 X가 나오는데 우리가 목적은 그 중간에 나오는 Z라는 형태를 찾아내는 거예요.

그래서 오토인코더는 이제 여러 가지로 응용을 할 수 있는데 이미지 압축은 사실 우리가 뭐 이미지 압축 뭐하러 그렇게 열심히 하나

이렇게 생각하실 수 있는데 이미지가 압축된다는 말 자체가 이미지의 핵심 정보를 추린다는 얘기이기 때문에 그거를 이제 응용을 하면 응용처가 여러 가지가 있습니다.

아까 얘기 드렸던 행성에도 쓸 수 있고요.

아니면은 이제 노이즈 제거에도 쓸 수 있는데 왜냐면 노이즈라는 것의 의미를 잘 생각해보면 패턴에서 벗어나는 게 어떤 노이즈거든요.

그죠?

우리가 어떤 사람이 말을 하는데 뭐가 이상한 소리가 들린다.

말이 아닌 어떤 소리 말이라는 거는 패턴이 있는 거잖아요.

근데 패턴에서 벗어나는 어떤 소리가 있으면 노이즈인거죠.

예를 들면 제가 오늘 점심이 참 맛있 썼습니다.

이러면은 의미 없는 얘기죠.

그래서 맛있었습니다라는 게 패턴이고 거기서 이제 벗어나는 건 노이즈인데 그러면 우리가 이제 이미지를 압축을 할 수 있다는 거는 패턴만 뽑아낼 수 있다는 거기 때문에 X를 Z로 줄였다가 이렇게 하는데 여기 예를 들어서 X에 어떤 노이즈가 붙어 있어요.

그럼 얘가 Z로 됐다가 다시 돌아올 때 요 노이즈는 패턴에서 벗어나기 때문에 압축이 안 됩니다.

그래서 이 압축 과정을 거쳐가지고 되돌아오면 얘는 노이즈가 없는 깨끗한 형태가 될 수 있는 거죠.

그래서 그냥 일반적인 JPEG 같은 거는 압축을 했다 풀면은 그 이미지가 지저분하든 뭐가 묻었든 그냥 그거 그대로 복원이 되는데 오토인코더를 이용해서 압축했다가 풀면은 노이즈도 그냥 사라지는 신기한 그런 현상이 있습니다.

그래서 요런 식으로도 활용을 할 수 있다.

그런 얘기가 되고요.

그래서 실제로 이거를 해볼까요 말까요

일단 결과만 보여드리면 그래서 요기 이제 우리 M리스트 핸드라이팅 데이터가 요렇게 있는데 요거에다가 아래 칸에 보시면 노이즈를 섞은 거예요.

자글자글하게 노이즈가 섞여있거든요.

그래서 노이즈가 섞여있는 이미지를 오토인코더에 넣어서 압축을 한 다음에 압축을 다시 풀어주면 약간 이미지가 흐려지긴 했지만 노이즈가 전부 없어졌습니다.

약간 이제 요게 들어가면 이건 약간 전체적으로 뭉개졌는데 요런거가 보시면은 노이즈가 다 없어졌어요.

왜냐하면 이 오토인코더는 학습을 할 때 노이즈가 없는 이미지로 학습을 했기 때문에 노이즈를 압축할 줄을 몰라요.

노이즈를 압축할 줄 모르니까 노이즈 정보는 압축하는 과정에서 다 날라가는 겁니다.

그래서 그냥 압축만 했다가 풀었을 뿐인데 노이즈도 없어지는 거죠.

근데 이제 멀쩡한 이미지는 압축했다 풀면은 거의 멀쩡하게 되더라고

이렇게 이제 할 수가 있습니다.


이정도로 하고 넘어가겠습니다.

이제 슬슬 시계만 보시면서 언제 끝나나 언제 끝나나 언제 끝나나 언제 끝나나 이거는 아마 해보시면 크게 문제있진 않을 거예요.

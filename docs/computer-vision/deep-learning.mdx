# 컴퓨터 비전과 딥러닝

우리가 이제 지금까지 한 방식은 전부 어떤 알고리즘을 짜 가지고 그 알고리즘에 의해서 그냥 기계적으로 처리를 하는 거예요 특정한 어떤 데이터나 이런 게 필요 없고 우리가 뭐 예를 들면 발견을 하고 있다가는 밝기 변화 같으면은 왼쪽이 밝고 오른쪽이 어두운 거니까 왼쪽 색깔에서 오른쪽 색깔을 빼 가지고 차이가 많이 나면 밝기가 변하니까 윤곽선이 있겠지

이거는 전부 논리거든요

논리만 따져서 이렇게 하는 겁니다

인공지능이라는 분야가 있으면 인공지능이라는 분야 안에 여러 가지 세부 분야들이 있는데 논리로 하는 것도 인공지능이고 그다음에 어떤 데이터에서 배우는 것에 대해서는 어떤 데이터에서 패턴을 찾는 분야가 있어요

이거를 머신러닝이라고 하는데 우리가 AI 교과서 컴공과에서 하는 AI 교과서를 보면은 사실은 머신러닝은 후반부에 가야 조금 나오고 사실 대부분은 논리라든지 계획이라든지 이런 부분이 훨씬 분량을 많이 차지합니다

사실 인공지능 역사가 되게 오래됐는데 한 70년 됐는데 사실 대부분의 기간 동안 더 연구를 많이 했던 거는 논리라든가 계획이라든가 이런 거예요

그래서 대표적으로 우리가 자동차 내비게이션 같은 걸 하면은 길을 찾아주는데 이런 게 원래는 인공지능 분야에서 주로 연구를 하던 그런 것이었습니다

길 찾기가 생각보다 되게 어려운 문제거든요

왜냐하면은 우리가 사거리를 한 번 만나면 직진, 좌회전, 우회전, 유턴 하면 선택지가 네 가지가 있잖아요

그럼 사거리를 하다 말다 할 때마다 선택지가 네 가지씩 생기니까 사거리를 열 개만 지나도 4X4X4X4X4X 이렇게 해서 선택지가 4의 10승이 생겨요

그러면 4X4X4X4X4X4는 대충 한 100만 개 되거든요

그러면 사거리를 열 개만 지나와도 선택지가 100만 개가 있는 거예요

100만 개 중에 하나를 찾아야 되는데 굉장히 어려운 문제가 되는 거죠

근데 이제 길 찾기가 뭐가 그렇게 중요하냐

예를 들면 우리가 수학 문제를 푼다 수학 문제도 일종의 길 찾기예요

왜냐하면 문제에 어떤 조건이 있고 답이 있으면 어떤 공식을 순서대로 적용을 해서 여기까지 가느냐

그러니까 내비게이션은 좌회전, 우회전을 하는 거고 수학은 이런 공식, 저런 공식을 적용하는 거고 그다음에 수학 문제뿐만 아니라 예를 들면 의료 문제를 푼다

환자가 왔으면 주어진 조건 내에서 어떤 식으로 어떤 순서로 치료를 해서 이 환자가 건강한 상태로 만들 거냐

이것도 이제 길 찾기 문제죠

그러니까 과거의 인공지능은 전부 길 찾기 추상화시키면 전부 길 찾기 문제를 푸는 거라고 할 수 있습니다

그래서 옛날 사람들은 50년대, 60년대는 길 찾기 문제만 잘 풀면 세상 말사 다 길 찾기니까 길 찾기로 환원할 수 있거든요

세상 말사 다 길 찾기로 환원할 수 있으니까 길 찾기 문제만 잘 풀면 세상 모든 문제들이 잘 풀면 세상 모든 문제들이 잘 풀면 세상 모든 문제들이 잘 풀면 위험한 문제를 다 풀 수 있다

이렇게 생각해서 굉장히 낙관적으로 생각을 했어요

그래서 이제 그런 거를 좀 볼 수 있는 게 영화인데 영화 중에 스탠리 큐브리 감독이 찍은 2001 스페이스 오디세이라는 영화가 있거든요

이게 보시면 되게 재미없는 영화인데 한 1950년대에 나온 겁니다

이 영화 내용 중에 70년대였으니까 스포일러를 좀 해도 되겠죠

이 영화 내용 중에 하나가 뭐냐면 어떤 우주탐사를 갔는데 그 우주탐사를 갔는데 AI가 우주탐사를 성공시키기 위해서 우주인들을 승무원들을 죽여요

그래서 얘는 우주탐사를 잘하라 라는 지시를 받았는데 잘 하려고 하니까 얘가 좀 방해가 되네?

그럼 죽여버려야지 이런 식으로 해서 그래서 이제 그런 내용이 나오는데 우리가 보통 영화 같은 데를 보면 그 시대의 분위기 같은 걸 알 수 있는 거죠

AI가 우리를 다 죽일 거야

이러다가 한 60년대 이렇게 가보니까 이거 잘 안 되네?

왜냐하면 길 찾기라는 거는 기본적으로 지도가 있어야 됩니다

근데 세상에 우리가 지도를 아무리 정밀하게 만들어도 한계가 있단 말이에요

자동차를 우리가 사실은 지도가 정확하게 있으면 자율주행이 어려운 게 아닌데 문제는 아무리 지도가 정확해도 예를 들면 길에서 갑자기 튀어나오는 꼬마아이는 지도에 표시할 수가 없단 말이에요

그거는 지도에 없기 때문에 대응이 안 되는 거죠

길 찾기로 만약에 그 애가 위치와 정확한 오후 3시 39분에 무슨 초등학교 앞에서 3세, 초등학생이니까 3세면 안 되겠죠 11살 꼬마아이가 튀어나올 거다라는 거를 우리가 지도에 표시를 해 놓으면 피할 수 있는데 그거 어떻게 표시를 해요?

그러니까 세상만사 지도에서 길 찾기라고 생각했지만 막상 지도가 다들 그렇게 정확하지 않기 때문에 대응이 안 되는 거죠

그래서 이제 AI 겨울 이런 말을 쓰는데 AI가 한창 뜨다가 좀 잘 안 됩니다

흐지부지 이렇게 되고 그래서 이제 80년대에 한 번 또 붐이 와요

한 30년 주기로 붐이 오는데 80년대에 또 붐이 살짝 옵니다

그때 나왔던 영화가 터미네이터죠

그래서 이제 보면은 인류 역사를 보면은 보통 AI 붐이 한 번 불면 AI가 사람 다 죽이는 영화가 한 번씩 나온다

터미네이터가 또 나오고 터미네이터도 그거죠

로봇이 사람 다 죽이고 지배를 하고 우리가 생각하는 상상력이 딱 고정된 거죠

AI가 다 우리를 죽이고 근데 사실 AI 입장에서 보면 사람을 꼭 죽일 필요 있겠습니까?

그냥 굳이 죽이지 않아도 돼요

어쨌든 터미네이터가 나오고 80년대에 AI 붐이 또 한 번 불었다가 또 그냥 좀 시들시들해집니다

그리고 이제 2010년대부터 다시 한 번 세 번째 붐이 불었는데 이번에는 AI가 사람 죽이는 영화는 안 나왔어요

그러니까 이제는 근데 이제 우리가 직업을 다 뺏을 거야

뭐 이런 얘기는 하는 거죠

과연 직업을 다 뺏을까?

이런 생각은 좀 들기는 해요

예를 들면은 우리가 로봇공학에서 되게 어려운 문제 중에 하나가 빨래 개는 거거든요

빨래 개는 로봇을 만들기가 되게 어렵습니다

제 생각에 뭐 아무리 보면은 뭐 이런 것들도 있고, 제 생각에 뭐 아무리 보면은 뭐 이런 것들도 있고, 제 생각에 뭐 아무리 로봇이 발전해도 빨래는 사람이 개지 않을까 불행하게도 저도 빨래 개고 설거지하고 이런 거 되게 싫어하는데 이거는 약간 식기세척기에 넣는 거 얻은 사람이 아마 해야 될 수도 있다

로봇으로 만들려면 만들 수 있는데 로봇 만드는 비용보다 앞으로 한동안은 사람이 더 싸지 않겠냐

이런 생각이 들어요

그래서 저는 그 로봇시대 AI시대에 대비하기 위해서 저는 뭘 하냐면 그 집에 엘리베이터를 안 터서 계단으로 올라가는 걸 합니다

그것도 로봇이 잘 못하거든요

그래서 AI 때문에 저도 직업을 잃으면 계단으로 올라가는 일은 내가 해야겠다

이렇게 생각해서 열심히 하체 운동을 합니다

어쨌든 그래서 이제 지도에서 길찾기를 하는데 그 지도가 명확하게 없다 세상에 뭔가 다 애매하고 불확실한 것 투성이다라는 게 이제 문제가 되고 그래서 이제 인공지능 분야에서 거의 점점 중심이 길찾기는 우리가 많이 연구를 했으니까 이제 이건 됐고 머신러닝으로 넘어갑니다.

머신러닝은 이제 머신러닝은 말 그대로 머신이 러닝 학습을 하는 거예요

그래서 어떤 수많은 데이터에서 패턴을 학습을 해서 예를 들면은 그 차가 가는데 앞에 애가 팍 튀어나와도 그게 애들이 생긴 것도 다르고 키도 다르고 뭐 입은 옷도 다르고 다 다르지만 어쨌든 애는 애다 라는 거를 우리가 패턴을 통해서 탐지할 수 있으면 지도에 없더라도 인식을 할 수 있겠죠

그런 것들이 이제 머신러닝이 되는 거고 근데 이제 머신러닝도 하는 방법이 여러 가지가 있거든요

우리가 데이터에서 패턴을 뽑아내는 방법이 여러 가지가 있는데 그 중에 한 가지 방법이 딥러닝입니다

80년대 90년대 딥러닝이라는 말도 없고 그때는 주로 Artificial Neural Network 인공신경망이라고 주로 했는데 그러다가 2006년쯤에 딥러닝이라는 말을 만듭니다

80년대부터 연구하던 거 자기네가 연구하던 거를 이름을 딥러닝이라고 붙여요

그래서 2006년쯤에 딥러닝이라는 말이 나오기 시작하고 그때 엔비디아가 후다라고 해서 딥러닝을 그래픽 카드에 돌릴 수 있는 것도 2006년 7년쯤에 발표를 합니다

그래서 그게 합쳐져서 시너지가 나면서 2012년에 대회가 있어요

컴퓨터 비전 대회가 있는데 컴퓨터 비전 대회에서 딥러닝 모델이 1등을 합니다 압도적인 차이로 1등을 하고 그러면서 사람들이 80년대 이후로 버려진 분야인데 갑자기 이제 살아 돌아서 나 아직 죽지 않았다

이러면서 갑자기 엄청난 성능으로 돌아오니까 사람들이 어 이거 뭐야

이러면서 전통적인 컴퓨터 비전 하던 사람들이 전통적인 컴퓨터 비전을 다 갖다 버리고 그때부터 갑자기 다 전향을 해서 저도 딥러닝 관심 참 많았었는데 잘 됐군요

이러면서 다 전향을 해요

막 그러면서 엄청난 붐이 불고 2012년이니까 한 10년 됐어요

정말 10년 만에 거의 강산이 변했는데 특히 제일 크게 변한 분야가 자연화 처리랑 컴퓨터 비전인데 사실 그래서 커리큘럼이 지난 10년 동안 굉장히 많이 바뀌었어요

그래서 컴퓨터 비전 같은 경우도 대학교에서 수업을 하는 거 보면 지금까지 우리가 한 이틀 반 동안 배웠던 이런 내용들 있죠

그걸 한 학기 내내 배웁니다

컴퓨터 비전 컴공과 수업을 보면 한 학기 내내 배우는데 요즘에는 이게 많이 줄었어요 점점 더 줄이고 있고 학교에 따라서는 이거 거의 안 가르치는 오픈CV나 뭐 이런 거 거의 안 가르치는 학교도 좀 있습니다

그건 뭐 니들이 알아서 해라

그런 거까지 가르쳐야겠니 이런 느낌으로 제일 이제 다들 딥러닝 딥러닝 이렇게 하는데 사실 제 생각에는 약간 실무에서는 여전히 오픈CV 쓰는 데가 더 많거든요

왜냐하면 딥러닝을 하려면 다 데이터가 있어야 되는데 사실 우리가 회사 일을 해보면 데이터라서 생각보다 만들기가 힘들어요

그래서 그냥 알고리즘으로 짜는 게 속 편하다

뭐 이런 게 좀 있습니다

그래서 이제 머신러닝 얘기를 다시 해보면 머신러닝이라는 거는 뭔가 모형이라는 걸 만들어서 어떤 데이터를 학습을 시키는데 그 모형의 종류에 따라서 또는 학습의 형태에 따라서 이렇게 세 가지로 나눕니다

지도학습 비지도학습 강화학습 그래서 이제 지도학습은 뭐냐면 뭔가 X랑 Y가 이렇게 짝이 지어져 있어요

그래서 X를 주면 Y를 찾아내도록 하는 게 지도학습입니다

제일 많이 하는 형태라고 할 수 있고요 비지도학습은 어떤 데이터의 내재적인 구조 이게 말이 좀 어려운데 내재적인 구조라는 거는 우리가 이제 사람이 어떤 이해를 한다기보다는 컴퓨터 입장에서 데이터를 이해하기 쉬운 형태로 처리를 하는 그런 거라고 할 수 있고요

강화학습은 사실 거의 안 하는데 대표적인 그 형태가 이제 알파고가 있습니다

알파고는 이제 바둑을 두는데 바둑을 그냥 두는 게 아니라 바둑을 잘 두죠

근데 이제 지도학습으로 바둑을 두게 하려면 X랑 Y가 있어야 돼요

그러니까 어떤 바둑판에 상태가 있으면 이 상태에서는 이런 행동을 해야 된다

이런 데이터가 있어야 되는데 그러면 이 데이터는 사람한테서 나오겠죠

뭔가

사람들이 기존에 바둑을 둔 걸 가지고 사람들은 바둑판이 이런 상태일 때 이런 행동을 하더라

이걸로 학습을 시키면 지도학습인데 그럼 바둑을 잘 둘 수가 없어요

왜냐하면 사람이 바둑을 잘 못 두니까 지도학습으로는 알파고를 만들어 봤자 한계가 있습니다

그래서 알파고는 어떻게 하냐면 사람이 둔 바둑을 전혀 고려하지 않아요

어떻게 하냐면 알파고 두 대를 만들어서 자기네끼리 바둑을 시킵니다

그러면 어느 한쪽은 이기겠죠

우리가 바둑을 아무리 몰라도 바둑 규칙만 알면 어쨌든 누가 이겼는지는 알 수 있거든요

그럼 이긴 애한테는 보상을 주고 진 애는 처벌을 합니다

그래서 이제 처벌이라고 해서 컴퓨터 전원을 뽑거나 이런 건 아니죠

처벌이라고 해서 컴퓨터 전원을 뽑거나 이런 건 아니고 보상 신호가 오면 아 내가 이번에 바둑을 이런 식으로 둬 봤는데 내가 보상 신호를 받았어

그럼 앞으로도 이런 식으로 둬야지 처벌을 받으면 아 이번에 이렇게 뒀더니 처벌을 받네 앞으로는 이렇게 두지 말아야겠다 그런 식으로 미세하게 조금씩 조금씩 자기가 바둑두는 방식을 계속 바꿉니다 보상을 받으면 더 그 방식으로 두고 처벌을 받으면 그 방식으로 안 두고 그래서 그런 바둑을 수천만 판을 두면서 조금씩 조금씩 미세하게 조정을 하다 보면 나중에 어떻게 되냐면 항상 이기는 바둑만 두게 되는 거예요

약간 진화랑 좀 비슷한 측면이 있죠

진화도 생물이 이렇게 있으면 어떤 생물은 좀 더 잘 살아남고 어떤 생물은 좀 덜 살아남으면 그게 수천만 년 수억 년 누적이 되면 결국 잘 살아남는 어떤 되게 신기하게 잘 살아남는 동물들만 남듯이 약간 그런 방식인데 그래서 강화학습은 머신러닝에서 뭔가

약간 굉장히 좋아 보이기는 하는데 또 막상 잘 안 하는 것 중에 하나입니다

왜 안 하냐 하면 기본적으로 이렇게 시행착오를 통해서 뭔가 답을 찾아가거든요

근데 예를 들면 우리가 자율주행을 강화학습을 통해서 뭔가 답을 찾아가거든요

강화학습을 통해서 뭔가 답을 찾아가거든요

그러면 차를 수천만 번 몰게 하면 기가 막히게 운전을 하긴 할 겁니다

근데 문제는 그 수천만 번 동안 어디 가다 들이박고 어디 떨어지고 사람도 치고 난리를 칠 거예요

그러니까는 약간 현실적으로 강화학습을 할 수 있는 상황이라는 게 바둑 이런 걸로 제한이 되는 거죠

바둑은 저도 그만이니까 그래서 우리가 대부분의 머신러닝은 약간 지도학습 형태가 좀 주를 이루고 그다음에 비지도학습 강화학습은 거의 하지 않습니다

그래서 머신러닝 교재를 보면 지도학습 설명이 한 7이라고 하면 비지도학습이 한 3이고 강화학습은 서론의 한 꼭지 정도 이런 것도 있다

알파보 사진 하나 넣어주고 그럼 그냥 넘어갑니다

보통 학교에서 안 가르쳐요 있어봐야 대학원 수업 정도 있는 그 정도라고 할 수 있습니다

그래서 이제 지도학습의 대표적인 어떤 X랑 Y의 예시를 보면 예를 들면 우리가 부품 사진을 주고 이게 불량이냐

아니냐

이런 걸 판정을 한다든가 그러면은 데이터가 있어야 됩니다

데이터가 X랑 Y가 있어서 부품 사진이 굉장히 많은 부품 사진이 있고 이 부품 사진마다 이거는 불 이거는 양 이거는 양 이거는 불 이런 식으로 사진마다 이런 게 있어야 돼요

그럼 새로운 이거를 여기서 어떤 패턴을 찾아서 새로운 사진을 주면 모델이 아 이거는 불량입니다

아니면 이거는 양입니다

이런 식으로 판정을 해주는 그런 거죠

그래서 이런 게 있고 아니면은 이제 불량 이거는 이거다 저거다 이런 건데 그게 아니라 어떤 수치로 예측을 할 수도 있습니다

예를 들면 사고 차량에 어떤 사진이 있어가지고 이런 사고 차량은 수리하는데 100만 원 들었고 이런 사고 차량은 수리하는데 50만 원이 들었고 이런 차량은 수리하는데 200만 원이 들었고 이런 차량은 수리하는데 10만 원이 들었다

그러면 이 어떤 관계 패턴을 찾아내는 거죠

패턴을 찾아내서 새로운 차량 사진을 주면은 아 이거는 72만 3천 원이 들겠네요

이런 식으로 추정을 하는 것도 가능합니다.

이런 식으로 추정을 하는 것도 가능합니다.

여기서 이제 중요한 거는 항상 이 Y가 데이터에 있어야 돼요

그래야 패턴을 추출을 하는 거거든요

그래서 이제 Y가 없는 가끔 이제 머신러닝 우리 AI를 잘 모르시는 분들이 좀 쉽게 하시는 실수가 AI 뭐 그거 되게 똑똑한 거 아니야

그러면 똑똑하니까 그 뭐 부품 불량 이런 것도 하겠네 못합니다

데이터가 없으면 못해요

제가 이제 학교에서 수업을 하면은 보통 학생들한테 이제 기말 프로젝트 이런 거 주제를 잡아서 기말고사 대신 각자 프로젝트 하나씩 해라

이런 거를 시키는데 그러면 이제 자연어 처리 수업을 할 때는 꼭 어떤 학생이 있냐면은 블로그 맛집 리뷰가 이거 진짜인지 가짜인지 판정하는 거를 해 보겠다

이런 학생이 한 명씩 꼭 있더라고요

무슨 철의 법칙처럼 있습니다

제가 한 10년 대학교에서 수업을 해 보니까 항상 그런 학생이 있더라고요

학부생 수업을 하면 꼭 있어요

근데 블로그 맛집 리뷰의 진위 여부를 판정하는 프로젝트는 못합니다

왜 못하냐 기술적으로 불가능한 게 아니라 데이터를 구하기 힘들죠

예를 들면 누가 돈 받고 사실은 거기 맛없는데 맛있다고 썼다

그럼 그걸 우리가 어떻게 알겠어요

뭐 가서 먹어봤는데 맛 없더라 그래도 그 사람한테 입맛에는 맛있었을 수도 있잖아요

그러니까 이게 진심으로 쓴 건지 거짓말을 하는 건지 데이터가 없으면 우리가 모델의 학습을 시킬 수는 없습니다

아무리 이제 우리 눈에 보여도 거짓말 같아 보여도 그거는 데이터가 진짜 진짜로 거짓말한 지는 알 수 없죠

그래서 이런 거는 알 수 없다

그래서 이런 게 있고 그다음에 이제 저도 사실 어떻게 하는지 되게 의문인 것 중에 하나가 요즘에 나오는 컴퓨터 비전 쪽에서 살짝 좀 의심스러운 것 중에 하나가 AI 면접 이런 게 있거든요

되게 약간 의심의 눈으로 보고 있는 것 중에 하나인데 AI 면접 이래 가지고 되게 왜냐하면 이제 closed 이걸로 없 publisher 하고 짓을 못 해가지고 또 하는 것 중에 ale Bay 면접 teraz cau Del Mussa 그니까 사람 얼굴 Del Mussa 면접하는 어떤 영상 이미지는 우리가 있어요

이거는 뭐 있는데 이 사람이 일을 잘할까 아니면은 회사에 적응을 잘할까

이런 거를 알아야 되잖아요

이게 데이터로 있어야 되는데 있겠습니까?

없을 것 같은데

근데 제가 이제 기사 같은 걸 좀 몇 개 찾아보니까 만드는 회사들도 바보는 아니기 때문에 없다는 건 알아요

근데 없지만 어쨌든 이런 걸 만들어서 이제 팔아야 돈을 버니까 어떻게 했냐면은 기업에서 이제 인사 업무를 하시다가 퇴직한 퇴직자 분들을 모셔 와 가지고 대학생들을 모아서 모임 면접을 봅니다

모임 면접을 보고 모임 면접 영상을 퇴직자 분들한테 보여주고 판정을 하게 한 거예요

이 사람 일 잘할까요?

그러면 어 저 정도면 일 잘하지

그걸로 AI 모델을 학습을 시킨 건데 그러면 사실 문제가 이 AI 모델은 일을 잘할까를 예측을 하는 게 아니고 인사 면접을 오래 하시다가 퇴직하신 분들이 이런 식으로 면접하면 좋아하는지 싫어하는지를 학습하는 거잖아요

사실 우리가 약간 AI라고 할 때는 굉장히 공정하고 객관적이고 이런 판정을 할 거라고 기대를 하는 건데 사실은 이런 식으로 면접하면 사람들이 좋아한다라는 거를 예측을 하는 거니까 굳이 그걸 AI로 할 필요가 있나 약간 이런 생각이 들죠

굳이 장점이라면 굳이 시간 들여서 면접을 안 해도 된다 이런 장점이 있는 건데 좀 한계가 있다

이런 생각이 좀 들죠

물론 이제 AI로 하면 잘하는 거니까요 AI 면접을 우리가 오래 하면 나중에 이제 채용된 사람들이 인사 기록 같은 걸 가져와 가지고 실제로 인사국가를 어떻게 받았는지 뭐 이런 거를 우리가 데이터를 나중에 매칭을 하면은 더 정확하게 되겠지만 현재로서는 사실 뭐 그렇게까지 정확하지는 않을 거다 라는 게 이제 제 생각입니다

그래서 이제 이런 부분 항상 Y가 있어야 된다 이거를 염두에 두셔야 되고요 그래서 우리가 이제 이거를 한번 실제로 할 건데 해볼 건데 티처블 머신이라는 사이트가 있습니다

요것도 우리가 이제 웹캠이 되면 참 좋은데 웹캠이 안 돼 가지고요 여기 이제 티처블 머신이라는 사이트는 구글에서 만든 건데 누구나 쉽게 AI를 해 보게 할 수 있도록 만들 사이트입니다

여기 가보시면은 여기 이제 보면은 여기 오른쪽에 이제 영상이 나오는데 밑에 보면은 요 영상이 불러서 영상이 지금 AI가 어떻게 인식하고 있는지가 나와요

그래서 지금 보면은 예를 들어서 강아지인지 난지 여기 밑에 보면은 사람 얼굴이 있으면 미가 나오고 너무 빨리 넘어가서 안 넘어간대

지금 요가 자세를 이렇게 취하면 지금 트리 자세인지 윙즈 자세인지를 바로바로 인식하죠

요거를 하는데 코딩이나 이런 게 필요 없게 만든 서비스입니다

그래서 어린아이들도 AI를 학습시킬 수 있게 사실 딥러닝이 어렵지 않아요

우리가 지금까지 했던 오픈CV나 이런 전통적인 컴퓨터 비전보다 딥러닝이 더 쉽습니다

데이터만 있으면 되거든요

왜냐면 모델을 우리가 직접 만들지 않기 때문에 모델은 이미 있는 거고 그냥 데이터만 있으면 되는데 문제가 뭐냐면 오픈CV 이런 거는 코드를 짜야 되는 게 어렵고 딥러닝은 데이터 모으는 게 힘들어요

근데 보통 어느 쪽이 힘드냐면 데이터 모으는 게 더 힘듭니다

다 노가다거든요

약간 인형 눈 붙이기 같은 거라서 코드는 공부하면 금방 살 수 있는데 인형 눈 붙이기는 공부한다고 빨리 할 수 있는 게 아니에요

그냥 시간을 많이 들여야 되는 거라서 좀 괴롭죠

다행히 회사에 계신 분들은 보통 자기가 직접 할 일은 없다

왜냐면 돈 주고 누구 시키면 됩니다

특히 대기업은 여기 계신 분들이 직접 할 일은 없는데 가끔 회사에서 돈 안 줄 때가 있거든요

그럼 직접 하셔야죠

어쩔 수 없습니다 인형 눈 붙이기 팀원들이랑 같이 인형 눈 붙이기 하는 거예요

다행히도 요즘에는 모델들이 많이 좋아져 가지고 원래는 데이터가 되게 많아야 되는데 그렇게 많지 않아도 됩니다

한번 해볼 건데 웹캠이 인식이 되면 좋은데 웹캠이 없어서 이건 집에 가서 노트북으로 한번 해 보세요

일단 시작하기 누르고 그래서 보면 프로젝트가 이미지 오디오 포즈 이렇게 있는데 이미지 프로젝트는 말 그대로 이미지를 인식시키는 거고 오디오는 소리를 인식시키는 거고 포즈는 자세 여기 보시면 팔다리에 뼈다구가 그려져 있죠

하는 건데 우리는 이미지로 하겠습니다

이미지 프로젝트 누르시면 표준이 있고 삽입된 이미지가 있는데요

표준은 이제 칼라로 하는 거고 삽입된 이미지는 약간 표현이 번역이 이상한데 인베디드 이미지라고 해서 우리가 어떤 장비 같은 데는 들어간 칩이 성능이 떨어지거든요

그래서 성능이 떨어지는 칩에서 돌릴 수 있게 흑백으로 좀 작은 사이즈의 이미지를 인식시킬 수 있는 이런 거는 어떤 그 경량 하드웨어 이런 거에다 집어넣을 수 있는 모델 우리는 컴퓨터로 할 거니까 표준 이미지 모델을 누르면 되겠죠

그래서 이제 이렇게 들어가면 여기 보시면 웹캠이 있고 업로드가 있는데 원래는 웹캠을 누르면 여기 웹캠이 연동이 돼 가지고 웹캠으로 바로 데이터를 찍을 수가 있어요

그래서 예를 들면 우리가 코로나는 끝났지만 예를 들면 코로나 시즌에 사람들이 마스크를 제대로 쓰고 있는지 탐지하고 싶다

웹캠 누른 다음에 한 명씩 마스크 쓰고 지나가세요

이렇게 해 가지고 착각착각 찍고 그다음에 마스크 안 쓰고 한번 지나가세요

착각착각 찍어서 학습시키면 마스크 썼는지 안 썼는지 판정해 주는 모델을 만들 수 있습니다.

우리가 지금 이제 웹캠을 누르면 웹캠이 여기 안 되니까 사진으로 업로드하는 것도 되거든요

좀 재미는 좀 떨어지지만 웹캠으로 하면 더 재밌는데 집에서 노트북으로 가족들하고 한번 해 보세요

재밌습니다

그래서 이제 업로드를 할 건데 업로드는 이제 뭘 하냐면 우리 데이터 중에 보시면은 여기 폴더에 catch and docs filtered 라고 있어요

catch and docs filtered 이거인데 여기 들어가 보시면은 트레인 폴더에 catch 있고 docs 있거든요

그래서 이제 이게 많이 넣으실 필요는 없고 한 10장 정도 한 10장 정도만 골라서 이렇게 끌어다가 업로드를 먼저 누르시고 업로드 누르고 이렇게 끌어다가 여기다가 톡 놓으면 이렇게 들어갑니다

그리고 여기 클래스원이라고 돼 있는데 이거를 catch 한글로 쓰셔도 돼요

고양이 쓰시면 됩니다.

다시 해보면 클래스 2는 그러면 누르고 강아지 이렇게 바꾸면 되겠죠

그리고 업로드 누르고 트레인에서 독스 가 가지고 또 한 10장 이렇게 끌어다가 여기다가 톡 넣으시면 됩니다

그럼 강아지 10장 들어가죠

고양이 10장 강아지 10장 넣으시면 여기 옆에다가 이거 누르라고 뜹니다

그죠

그럼

그냥 학습시키 누르면 끝났어요

그래서 이런 식으로 사진이 많이 필요 없고 사진 종류에 따라 좀 다른데 일반적인 이런 사물이나 동물 같은 경우는 한 10장 20장만 있어도 굉장히 잘 인식이 됩니다

이게 딥러닝이에요

딥러닝으로 우리가 지도학습을 한 거예요

굉장히 쉽죠

5분만 배우면 할 수 있습니다

근데 이제 우리가 부품인식 이런 거는 데이터가 좀 많아야 돼요

그래서 이거 한번 해보시고요

집에 노트북 있으면 웹캠으로 해보시면 되게 재밌습니다

가족들이랑 그래서 예를 들면 아들 딸 이렇게 있으시면 아들 얼굴 딸 얼굴 2개 10장씩 찍어가지고 아들이 나오면 여기 아들 100% 딸 나오면 딸 100% 이런 식으로 해보면 재밌겠죠

그럼

엄마를 찍으면 뭐라고 나올까 그런데 이제 아들이 엄마 닮았으면 엄마 얼굴 보고 아들이라고 판정할 거고 딸이 엄마닮았으면 뭐 할 거고 그런 식으로 해보면 되겠죠

웹 캠 되면 해 볼 수 있는 게 많은데 이렇게 업로드해 보셔도 되겠죠

막해보니까 온데이터 어렵지 않다 어렵지 않으니까 한번 해보시고요


클릭해서 할 수 있는 걸 왜 코드로 해야 되는지는 좀 의문이지만 그래도 코드를 좀 짜봐야 이게 원리를 좀 이해할 수 있으니까 뭐 그렇게 하고 사실 이제 티쳐블 머신 같은 경우는 여기 상단에 보시면 모델 내보내기라고 있어서 요걸로 파일로 다운받으면 우리는 파이토치로 할 거긴 한데 텐서플로우라고 딥러닝 라이브러리가 있거든요

그래서 요거를 다운받아서 코드에다가 이렇게 붙여 넣으면 요거를 자기 파이썬 코드에다 집어 넣을 수도 있어요

그래서 사실 이제 점점 약간 AI가 이런 쪽으로 갈 겁니다 데이터만 자기 데이터만 가져오면 나머지는 사람이 굳이 신경 쓸 거 없이 그냥 클릭 클릭해서 제 생각에는 앞으로 몇 년 안에 엑셀에도 이런 게 들어갈 거예요

엑셀에 셀에다가 사진 이렇게 좀 넣고 지금도 이렇게 엑셀에 숫자 몇 개 넣은 다음에 쭉 끌어당기면 자동으로 이렇게 채워주게 되잖아요

그런 식으로 이렇게 사진 몇 개 넣고 고양이 고양이 고양이 강아지 강아지 같이 써놓고 새 사진 넣은 다음에 쭉 끌어당기면 자동으로 채워지게 요즘에 마이크로소프트 마이크로소프트가 좀 AI에 미쳐 있어 가지고 아마 엑셀에도 조만간 이런 게 다 들어가지 않을까 엑셀만 해도 AI 할 수 있다

이렇게 될 거 같습니다

우리가 모델이라는게 하는건 뭐냐면 어떤 데이터가 지금 초록색 데이터 패턴이 있어요

이게 수학의 sin함수를 이용해서 만든 패턴인데 우리가 이게 sin함수라는 거를 정확하게 몰라도 우리가 근사를 시킬 수가 있습니다

비슷하게 만들 수 있다는 거죠

그래서 우리가 수학에서 영차함수라고 하면 y는 b 이런 형태의 함수를 영차함수라고 하고 y는 ax 플러스 b 이러면 1차함수라고 하고 y는 ax 제곱 더하기 bx 플러스 c 이러면 2차함수라고 하고 최고차항의 차수를 가지고 함수를 구별을 하는데 영차함수는 전혀 다르게 생겼죠 1차함수가 되면 좀 비슷하고 3차함수가 되면 굉장히 비슷합니다

그러니까 물론 뒤로 가면 다르지만 뒤로 가면 sin함수는 이렇게 가고 3차함수는 이렇게 가니까 서로 다른데 어떤 부분적으로는 굉장히 비슷하게 할 수 있다는 거예요

심지어 이제 우리가 구차함수로 가면 데이터가 점이 9개가 있는데 이 9개의 점을 모두 지나는 어떤 함수를 찾을 수가 있습니다

근데 이렇게 되면 문제가 뭐냐면 오차가 없어요 오차가 없는데 문제는 뭐냐면 미래의 데이터는 우리가 실제로 이 빨간 선은 근사일 뿐이지 실제로는 초록선 근처에서 나올 거란 말이에요

그럼 예를 들면 이런 데에서 실제 데이터가 나오면 근사가 어마어마하겠죠

그래서 이거를 이제 과대적합하는 것도 좋지 않다

과도하게 끼워 맞추는 것도 좋지 않다

그래서 우리가 이제 충분히 복잡한 어떤 함수가 있으면 데이터의 실제 패턴을 모르더라도 데이터가 넉넉하게 있다는 가정하에서 근사를 할 수 있다

이것처럼 이 초록선이 실제로 수학적으로 어떤 형태인지 몰라도 빨간 선으로 대충 비슷하게 만들어집니다.

그래서 우리가 이제 강아지와 고양이의 어떤 강아지와 고양이를 구별하는 어떤 수학적 함수를 머리를 열심히 써서 고안하려고 하면 어렵죠

그런 거는 어디 아인슈타인이 살아돌아도 못할 겁니다

그렇지만은 우리가 어떤 적당하게 복잡한 함수가 있으면 강아지와 고양이를 수학적으로 구별하는 방법이 뭔지 몰라도 근사는 시킬 수 있다는 거죠

그럼 그게 어떻게 가능하냐 하면 여러 가지 방법으로 시도할 수 있는데 한 가지는 기존에 우리가 생물이 어떻게 하는지를 좀 생각을 해보는 겁니다

거기서 아이디어를 가져와 보자 이거죠

우리 뇌에 보면 뉴런이라는 신경세포가 있는데요 이 신경세포가 기본적으로 어떻게 작동을 하냐면 이쪽에서 어떤 자극을 받으면 세포가 자극을 받으면 자극이 약하면 그냥 무시해요 아무 일도 일어나지 않습니다 그러다가 어떤 Threshold가 있어서 이 자극이 Threshold를 넘기면 갑자기 이 신경세포가 흥분을 해가지고 전기신호를 발생을 시킵니다

그러면 얘가 연결돼 있는 다른 세포가 있는데 이 다른 세포로 전기가 이렇게 넘어가겠죠

전기가 막 넘어가면 또 이 세포가 이 신호가 약하면 무시해 버리는데 신호가 강하면 얘도 또 흥분을 막 하겠죠

그럼

또 얘가 전기신호를 막 발생을 시킵니다

그래서 뉴런이 이런 식으로 작동을 하는데 여기서 아이디어를 가져오는 거예요 세포 하나하나가 어떤 자극이 강하면 흥분하고 자극이 약하면 가만히 있고 그럼 그런 세포들을 잘 연결하면 사람의 뇌처럼 어떤 고도의 복잡한 사고를 할 수 있구나 우리가 어떤 수학함수를 구성할 때 굉장히 단순한 수학함수를 구상을 해요

그래서 어떤 식의 수학함수냐면 여러 가지가 있을 수 있는데 그냥 어떤 Threshold를 정해서 Threshold 2 하면 0 Threshold를 넘기면 0이 됩니다.

1 이런 형태의 단순한 수학함수를 만든 다음에 입력값들이 있으면 이 입력값들을 다 더해요

다 더하는데 그냥 더하지는 않고 어떤 거는 좀 중요한 게 있고 어떤 건 좀 덜 중요한 게 있으니까 중요한 거는 가중치를 많이 곱해서 더하고 안 중요한 거는 가중치를 조금 곱해서 더하고 또 어떤 거는 반대의 특성을 가지는 게 있겠죠

그런 거는 마이너스 가중치를 곱해서 더하고 이런 식으로 어떤 총점을 구한 다음에 이 공간이 Threshold를 넘기면 1 못 넘기면 0 이렇게 하면 뉴런하고 결국 원리가 비슷한 거죠

그래서 그런 뉴런들을 만들어 가지고 얘네를 막 이렇게 연결을 시키면 이거를 인공신경망이라고 부릅니다

그래서 뉴럴 네트워크 우리가 뇌에 있는 뉴럴 네트워크를 인공적으로 만들었다

그래서 인공신경망이라고 하는데 실제 뇌랑 작동 방식이 똑같냐 하면은 그렇지는 않아요

실제 뇌는 이렇게 단순하게 작동하지 않습니다

훨씬 복잡하게 작동하고 있습니다.

우리가 이제 새랑 비행기의 관계랑 비슷합니다

새는 날 때 굉장히 복잡한 방식으로 날거든요 날개를 퍼덕퍼덕 퍼덕 퍼덕하면 나는데 비행기는 그냥 냅다 엔진으로 그냥 추력을 끌어 가지고 날죠

그냥 날개를 퍼덕거리거나 날개 구조가 비행기는 굉장히 좀 단순합니다

새에 비하면 그래서 비행기 날개 안에는 뭐 들어 있는 게 별로 없어요

그냥 연료통 좀 들어 있고 근데 사실 날개는 비행기가 더 빨리 날죠

오히려 구조가 단순하기 때문에 인공신경망도 우리 뇌에 비하면 구조가 되게 단순합니다

우리 뇌는 뭐 되게 복잡하게 돼 있어서 여러분들 요즘에 많이 들어보셨을 도파민 이런 것도 있고 그다음에 각종 굉장히 다양한 화학물질들이 저 구조 안에서 여러 가지 기능을 하고 있는데 인공신경망은 뭐 그런 게 없어요

여기 뭐 도파민 이런 거 아무것도 없죠

그런 거 없고 그냥 단순한 구조로 돼 있는데 얘가 결국 하는 건 뭐냐면 어떤 요 하나 하나는 굉장히 단순한 함수인데 이 단순한 함수들을 이렇게 여러 개로 합쳐 놓으면 굉장히 어떤 복잡한 함수를 모방을 할 수가 있게 됩니다

다음 장에 나오지만 그거를 보편 근사정리라고 해요

인공신경망을 충분히 크게 만들면 어떤 연속적인 함수라도 원하는 정도의 정확도로 근사할 수 있다

내가 좀 대충 비슷하게 하고 싶으면 모델을 좀 작게 만들면 되고 매우 정확하게 만들고 싶으면 모델을 크게 만들면 되고 내 맘대로 할 수 있다 더 정확하게 하고 싶으면 모델을 더 키우면 됩니다

그 다음에 딥러닝이라는 말은 어디서 나왔냐면 이런 식으로 결국 단순한 수학함수를 겹치고 겹치고 겹치고 해서 복잡한 수학함수를 만드는 건데 그럼 요 하나하나를 층이라고 부르거든요

영어로는 레이어 그러면 요 층을 여러 개로 겹치면 이걸 다층신경망이라고 하고 그러면 다층을 굉장히 많이 넣는다 층을 이렇게 많이 넣으니까 우리가 어떤 건물이 있는데 지하로 건물이 지하 1층 지하 2층 지하 3층 지하 3층 지하로 층이 층층층층층층층층층 쌓이면 어떻게 돼요

이 건물이 굉장히 깊어지겠죠

약간 우리나라 사람 사고방식하고는 좀 다른데 어쨌든 층이 많다는 거를 깊다

이렇게 얘기해서 딥러닝 딥이 깊다라는 뜻이죠

그래서 딥러닝이라고 부르게 됩니다

이름만 들으면 뭔가 깊이 있는 학습 우리가 이제 사람은 학습을 깊이 한다고 하면 공부를 열심히 한다든가 아니면은 몰랐던 사실을 발견한다든가 이런 의미인데 딥러닝에서 이 딥은 별뜻은 아니고 그냥 레이어가 그냥 많다는 얘기에요

레이어가 많으면 함수의 형태가 복잡한 거를 근사할 수 있게 되니까 뭔가 우리가 이전에는 안 되던 거를 할 수가 있는 거죠

그래서 이제 요게 이제 요런 것이다

그래서 이렇게 되고 그래서 여기 있는 거는 제가 링크를 안 달아놨는데 제가 지금 이렇게 구글에 가셔서 구글에 가셔서 구글에 가셔서 구글에 가셔서 구글에 가셔서 구글에 가셔서 검색창에 이거 꼭 안 해보셔도 되는 거라서 제가 굳이 안 넣었는데 플레이그라운드 텐서플로우 이렇게 넣으시면은 구글 검색창에 넣으시면은 뉴럴 네트워크 플레이그라운드라고 해서 놀이터라는 얘기죠

플레이그라운드는 실제로 신경망 구조를 실제로 신경망 구조를 만들어볼 수 있는 그런 사이트가 있습니다

만들어 볼 수 있는 그런 사이트가 있습니다

텐서플로우 홈페이지에 있는 건데 그래서 여기 보시면은 왼쪽에 데이터가 있는데요

데이터 중에 요렇게 간단한 데이터로 해보겠습니다

파란 점들이 있고 주황색 점들이 있는데 파란 점하고 주황색 점을 구별하는 어떤 수학적 함수를 만들고 싶어요

우리가 그 함수의 형태를 모른다 우리가 그 함수의 형태를 모른다 라고 해도 그냥 이 요 함수는 그냥 왼쪽 오른쪽을 구별하는 함수고 그냥 요 함수는 그냥 왼쪽 오른쪽을 구별하는 함수고 얘는 위 아래를 구별하는 함수입니다

그럼 얘네 둘을 어떻게 잘 포개면은 요 파란 점과 빨간 점을 구별하는 함수를 만들 수가 있어요

사실 요긴 레이어가 필요 없고 요 정도 있으면 되는데 그래서 여기서 이제 플레이 버튼을 누르면 얘가 이제 이렇게 되거든요?

누르면 얘가 학습을 합니다 학습을 한다는 건 뭐냐면 얘네 둘을 몇 대 몇으로 이 가중치를 줘서 섞어야 얘네를 구별할 수 있냐

그 가중치를 찾는 게 학습이에요 보시면은 지금 요런 선이 하나 그어져 가지고 파란 점과 주황색 점을 구별할 수가 있게 되죠

그래서 보면은 이제 마우스를 얹어 보면 여기 웨이트가 나오는데 요런 웨이트로 이제 얘네를 가중치를 해서 이렇게 섞으면 된다

사실 이것도 필요 없네요

요것도 필요 없고 그냥 이렇게 하면은 간단한 문제는 지금 보시면 중간에 아무 레이어가 없거든요

아무 레이어가 없어도 요거랑 요거랑 그냥 잘 몇 대 몇으로 잘 섞으면 되겠죠

이렇게 되는데 근데 이제 데이터가 좀 복잡하다

이번에는 가운데에 이제 파란색이 있고 주변에 빨간색이 있는데 이런 거는 아무리 해도 요거를 구별하는 어떤 경계선을 요 구조로는 근사할 수가 없습니다

그럼 어떻게 하면 되느냐

중간을 이제 플러스 버튼을 누르면 이제 층을 추가할 수 있는데 이렇게 적당히 복잡하게 해주면 다시 해보죠

바깥쪽은 주황색이고 안쪽은 파란색인 어떤 경계선을 수학적 함수를 근사를 할 수 있습니다

그러니까 요 모양을 우리가 수식으로 쓰려면 굉장히 어렵겠죠

왜냐면 이거 뭐 원도 아니고 세모도 아니고 네모도 아니고 우리가 알고 있는 학교에서 배우는 수학적 함수 중에 요런 식으로 생긴 함수가 없는데 몰라도 상관없습니다

그냥 레이어 좀 넣고 돌리면 돼요

그럼 이제 더 복잡한 거가 있는데 그럼 이제 더 복잡하게 돼서 이렇게 나선형으로 꼬여있는 것도 되냐 됩니다

근데 요거는 이제 안 돼요

요 정도 가지고는 안 되고 더 복잡한 형태가 필요하겠죠

그래서 뭐 요런 거를 이제 더 집어 넣어주고 되려나 보시면은 이제 서서히 근사 되면서 이 나선형 모양을 서서히 근사를 해나가죠

굉장히 오래 걸리는데 뭐 이렇게 놔두면은 이제 조금씩 조금씩 근사를 해서 됩니다

지금 뭐 별로 그렇게 썩 모양이 예쁘진 않은데 대충 그래도 근사가 지금 어느 정도 돼있죠

여기서 아무리 복잡한 형태라도 여기 이제 레이어를 좀 추가를 해주고 레이어마다 뉴런만 좀 넣어주면은 어떻게든 잘 조합을 해가지고 단순한 거를 겹치고 겹치고 겹치고 겹치고 해서 근사를 할 수 있다

요런 거를 우리가 해볼 수 있고 이게 이제 보편근사정리의 내용입니다

그래서 집러닝은 어떻게 보면은 되게 약간 무식한 분야인데 왜냐면은 그냥 좀 잘 모르겠으면 모델을 충분히 키워주면 돼요

근데 이제 문제는 뭐냐면 모델이 커지면 데이터도 많이 필요합니다

데이터를 모으는 거는 이제 그야말로 흔히 말하는 노가다라서 그냥 시간을 많이 걸려서 공을 많이 들여서 데이터를 많이 모으면 됩니다

그래서 빅데이터 빅데이터 하는 얘기를 요즘에 많이 하는데 요즘도 아니고 그런 얘기한 지가 좀 됐죠

사실 AI에서 되게 중요한 거는 우리가 공부를 열심히 하는 게 아니고 빅데이터를 모으는 거예요

근데 이제 보통 우리가 생각하시는 빅데이터는 100개 1000개 이러면은 이제 어 많다

이런 느낌이 드는데 딥러닝에서 빅데이터는 100개 1000개 이런 게 아니라 100만 개 1000만 개 이런 단위입니다 데이터를 어마어마하게 많이 모아야 되는데 공이 엄청나게 많이 들죠

그래서 보면은 요즘에 스타트업 이런 게 많이 들죠

그래서 보면은 요즘에 스타트업 이런 게 많이 들죠

그런 어떤 옛날에는 보면은 스타트업 이래가지고 아이디어 하나로 떼돈 벌고 이런 사람들이 좀 있었는데 AI 쪽은 그런 경우가 되게 드물어요

아이디어 하나로 떼돈 벌고 이런 경우가 잘 없고 보면 다 대기업이 합니다

AI는 미국에서도 보면은 지금 AI로 앞서가는 회사들 보면 다 대기업이거든요

왜 그러냐 데이터 때문입니다

데이터가 많아야 되고 아이디어만 어떻게 좋다고 되는 게 아니고 그 아이디어를 뒷받침할 만한 데이터가 있어야 되는데 다 돈입니다

돈이 처음 시작한 스타트업이 돈이 그렇게 많을 수가 없으니까 정말 거대 기업들 싸움판이죠

그래서 AI는 딥러닝 기반의 AI는 돈이 많이 든다

데이터가 필요하기 때문에 그래서 이제 우리가 회사에서 뭘 할 때 제가 아까도 얘기 드렸지만 딥러닝 하기가 되게 애매한 경우가 사실 되게 간단한 건데 이거 하자고 데이터를 만 개씩 모아야 된다 그러면 그냥 하던대로 하지

이렇게 될 수가 있습니다

그러면 그냥 하던대로 하지

이렇게 될 수가 있습니다

근데 이제 나중에도 얘기 드리겠지만은 우리 요즘에 그 기술이 많이 발전해서 원래는 데이터가 되게 많아야 되는데 지금 이런 것도 보시면 데이터 별로 없어도 되는데 이런 게 있죠

이거는 이제 우리가 그것도 한 4일차 5일차에 볼 거지만은 전이 학습이라는 기법이 있어서 미리 미리 학습을 시킬 수가 있어요

어차피 여기 투처블 머신에 들어오는 사람들이 여기 학습시킬 이미지라는 게 빤하단 말이에요

무슨 엑스레이 사진을 가지고 폐암 판별하고 이런 걸 하려고 여기 들어오진 않을 거 아니에요

그럼 뭐 강아지 고양이를 구별을 시키든지 아니면 뭐 연필하고 국자를 구별시키든지 뭐 뻔한 사물들을 구별시킬 거거든요

그럼

그런 사물들의 이미지를 그냥 5만 대만 다 모아가지고 어차피 우리가 일상적으로 볼 수 있는 사물의 종류란 게 한정되어 있기 때문에 5만 대만 그런 사물들을 다 학습을 미리 시켜놓는 거예요

그러면은 이게 어느 정도 튜닝이 돼 있기 때문에 강아지 고양이 사진이 그렇게 많지 않아도 됩니다

얘는 이미 강아지 고양이 사진이니까 강아지 고양이 사진이 그렇게 많지 않아도 됩니다

얘는 이미 강아지 고양이 사진이니까 강아지 고양이 호랑이 뭐 개구리 이런 거는 수천만 장을 봤어요

그렇기 때문에 거기서 이제 조금만 더 강아지 고양이 쪽으로 튜닝을 해주면은 강아지 고양이를 잘 구별할 수 있는 거죠

그래서 이 티쳐블 머신 같은 경우처럼 미리 학습을 시켜놓는 방식이 현재는 대세입니다

그래서 여러분들 많이 들어보셨을 책 GPT라고 있죠

GPT의 피가 뭐냐면 프리트레이닝 미리 학습이 되어 있습니다

그래서 책 GPT 같은 거 쓸 때는 여러분들이 뭐 데이터 이런 거 써보신 분들은 아시겠지만 딱히 뭐 데이터를 여러분 데이터를 가져가는 게 없잖아요

그냥 물어보면 바로 재깍재깍 대답을 하는데 그게 이제 프리트레이닝 미리 훈련이 돼 있기 때문에 그렇습니다

미리 5만 가지 데이터로 이런 경우에는 이렇게 대답하고 저런 경우에는 저렇게 대답하고 이런 5만 가지 경우의 수에 대한 게 다 학습이 돼 있습니다

그래서 점점 이제 이 방향으로 가고 있기 때문에 사실 이제 학습을 시키는 것도 사실 점점 데이터가 더 강력해지고 데이터가 그닥 많이 필요하지는 않습니다

다행스럽게도 그래서 이제 한 5년 10년 지나면 아마도 이제 제로샷이라고 해서 아예 이렇게 지금은 한 10장 이렇게 있어도 되는데 아예 데이터가 없어도 될 거다

왜냐하면 세상에 존재할 수 있는 모든 사물을 다 학습을 미리 시켜놓으면 되는 거 아니냐

이런 건데 그렇게 되면 이제 우리가 뭐 더 쉽게 쓸 수 있겠죠

일단은 그때까지는 좀 데이터가 조금이라도 있기는 있어야 된다

이렇게 얘기할 수 있습니다

그래서 우리가 이제 보기에는 이제 어떤 학습을 할지 모르겠지만 이제 우리가 이제 어떤 학습을 할지 모르겠지만 우리가 이제 좀 더 쉽게 쓸 수 있겠죠

그런데 일단은 그때까지는 좀 데이터가 조금이라도 있기는 있어야 된다

이렇게 얘기할 수 있습니다.

그래서 우리가 이제 보기에는 좀 더 쉽게 쓸 수 있겠죠

그런데 일단은 좀 더 쉽게 쓸 수 있겠죠

그런데 일단은 좀 더 쉽게 쓸 수 있겠죠

그런데 이제 그 사전학습된 모델을 이제 튜닝하는 거 이런 것도 우리 수업에서 다룰 테니까 그런 거는 이제 차차 배워가도록 하고요 그 다음에 이제 이런 그 이 웨이트 가중치를 어떻게 학습을 하느냐

여기 이제 그래프를 돌려보시면은 여기 오른쪽에 이제 어떤 그래프가 나오는데 리셋을 해가지고 문제를 쉬운 걸로 바꾸죠

리셋을 해가지고 문제를 쉬운 걸로 바꾸죠

이거를 이제 돌려보면은 이 그래프가 쑤욱 하고 떨어지거든요

너무 빨리 떨어졌는데 다시 해봅시다 그래프가 울렁울렁 하다가 쑤욱 떨어집니다

이 그래프가 뭐냐면 일종의 오차를 나타내는 그래프에요

그러니까 얘를 이 경계선이 바깥쪽으로 뻗어나가 있으면 주황색이 파란색으로 잘못 분류가 되겠죠

그럼 오분류를 얼마나 하느냐

이런 걸 나타내는 건데 이게 점점점점점 떨어집니다

이 그래프가 그래서 이제 이렇게 하는 거를 경사하강법이라고 해요

우리가 어떤 그 입력에서 어떤 부분들에 가중치를 곱해 주는데 X에다가 결국 어떤 W를 곱하는데 학습이라는 건 뭐냐면 이 W를 찾는 거거든요

그래서 어떤 가중치를 곱해줘야 우리가 Y를 잘 맞출 수 있겠느냐

이런 거를 하는 건데 그러면 우리가 이제 이 Y를 잘 맞추도록 이 W를 키워도 주고 줄여도 주는데 어떻게 되겠어요

오차가 줄어드는 방향으로 이 W를 수정을 해줘야겠죠

여러분들이 아침에 이제 샤워하고 계시거든요.

샤워하실 때 뜨거운 물을 처음에 딱 틀면은 너무 뜨거워요

여러분이 원하는 온도보다 뜨거우면은 좀 차갑게 줄이고 너무 차가우면 뜨겁게 올리고 이렇게 그 일종의 이제 수돗꼭지를 조절을 하는데 그게 경사하강법입니다

그러니까 이 경사하강법은 뭐냐면 여기 이제 손실이라고 썼는데 손실이라는 건 오차라고 생각하시면 돼요

그래서 오차가 줄어드는 방향으로 파라미터 가중치 W를 줄여줍니다.

그래서 가중치 W 같은 가중치를 말하는데 이 줄어드는 방향으로 파라미터를 점진적으로 조정해서 줄여나간다 라고 해서 경사하강법이라고 합니다

그래서 경사는 그 줄어드는 방향을 말하고 하강이라는 거는 그래서 그걸 조절을 해서 이제 손실을 떨어뜨리니까 경사하강법 이렇게 얘기를 하고요 그래서 여기서부터 시작을 해가지고 살살살살 조절을 해 나가면 우리가 아침에 샤워기에 딱 내가 원하는 온도를 맞출 수 있듯이 온도계가 안 되니까 이걸 계속 조절해 나가면 언젠가는 온도가 딱 맞잖아요

그렇듯이 우리가 이제 거대한 모델에서 그 파라미터들을 계속 조절을 해 나가면 강아지 고양이를 딱 구별할 수 있는 그런 함수를 얻을 수가 있습니다

그래서 이제 요런 거를 할 때 계산이 굉장히 많이 들어가기 때문에 계산을 굉장히 빨리 할 수 있는 반도체가 필요하고 그래서 요즘 흔히 말하는 GPU 이런 반도체가 이런 계산을 굉장히 빨리 해주는, 그래서 이제 요런 거를 할 때 계산이 굉장히 많이 들어가기 때문에 계산을 굉장히 빨리 할 수 있는 반도체가 필요하고 그래서 요즘 흔히 말하는 GPU 이런 반도체가 이런 계산을 굉장히 빨리 해주는, 그런 반도체가 됩니다

근데 이제 그 반도체를 만드는 회사가 여러 대 있긴 한데 보통 딥러닝에서 쓰는 반도체가 다 엔비디아 제품이라 엔비디아가 떼돈을 버는 거죠

근데 이제 그 반도체를 만드는 회사가 여러 대 있긴 한데 보통 딥러닝에서 쓰는 반도체가 다 엔비디아 제품이라 엔비디아가 떼돈을 버는 거죠

저번에 보니까 엔비디아 영업이익률이 50%가 넘는다는데, 아니 도대체 뭐, 정말 흙파서 장사하는 수준이 처음 100만원짜리 팔면 50만원이 남는다는 건데 거의 뭐 땅 파서 장사하는 그런 수준인데 거의 땅 파서 장사하는 그런 수준인데 제가 엔비디아 얘기를 한 10년 전부터 하고 있었는데 엔비디아 얘기를 하고 다닐 게 아니라 엔비디아 주식을 10년 전에 샀어야 되는데 근데 그때도 약간 보면은 이 정도면 고점이지

엔비디아 아무리 좋지만 이렇게 비쌀 일인가 생각했는데 10년 후에 보니까 이렇게 비싼 그때도 샀다

지금도 그래서 항상 보면서 혹시 지금도 싼 건가 제 말 듣고 또 엔비디아 주식 사지 마세요

어쨌든 그런 생각이 들더라고요

어쨌든 그래서 이제 이런 거 계산하는데 특수한 반도체를 쓰는 거죠

계산이 워낙 많으니까 딥러닝 이전하고 이후하고 어떻게 다르냐면 우리가 앞에서 특징 추출 얘기를 했었는데 이미지 매칭할 때 특징 추출을 했었는데 딥러닝 이전에는 우리가 하려는 어떤 과제의 특성에 맞춰서 여러 단계의 처리 과정을 거쳐 가지고 우리 오전에 보면은 그래서 이미지를 흑백으로 바꾸고 흑백으로 바꿀 때 뭘 하고 여러 개 처리 과정을 거쳐 가지고 우리가 원하는 어떤 특징을 추출한단 말이에요

그런 알고리즘을 직접 짰습니다

그래서 이런 특징 추출기 피처 익스트랙터를 만들어 가지고 특징 벡터를 만든 다음에 머신러닝을 붙이더라도 이 뒷단에 붙였어요

근데 딥러닝 시대에는 이런 게 단계 단계 구별이 없고 그냥 드립다 데이터를 집어넣으면 딥러닝 모델 안에 경상법으로 그냥 적절한 파라미터들이 찾아져 있고 이런 거를 종단간 학습 보통 우리말로는 표현 안 하고 영어로 그냥 엔드 투 엔드 러닝이라고 하는데 왜 엔드 투 엔드냐 하면 이쪽 끝에서 이쪽 끝까지를 그냥 통째로 학습을 시킨다는 겁니다 중간중간 단계에 사람이 뭐 생각해서 개입하는 게 없어요

그냥 데이터만 왕창 때려 넣으면 그냥 끝입니다

엔드에서 엔드까지 그래서 제가 계속 얘기 드리지만 딥러닝이 더 쉽다

이런 얘기를 드리는데 왜냐하면 그냥 우리가 할 일은 데이터만 왕창 모아오면 끝입니다

공부할 게 별로 없어요

그래서 데이터만 왕창 모으면 되는데 항상 문제는 차라리 공부가 더 쉽다는 거죠

데이터는 공부를 한다고 더 잘 모을 수 있는 게 아니기 때문에 조금 더 잘 모을 수는 있겠지만 어차피 다 시간과 품을 들여야 되는 일이라 그런 부분이 괴로운 거죠

근데 그것도 돈 많으면 해결된다

돈이 없으면 그때부터는 그냥 몸을 갈아 넣어야 됩니다

그다음에 표상학습이라는 개념이 있는데 표상학습이라는 개념은 뭐냐면 그래서 원래는 이 피처를 우리가 특징을 알고리즘을 짜서 추출을 했잖아요

딥러닝 모델 안에서 눈에 보이진 않지만 그런 일들이 일어난다는 거예요

왜냐하면 앞에서 보시다시피 이렇게 레이어가 많으니까 얘네가 결국 뭘 하겠냐

이거죠

얘네가 내부적으로 뭔가 우리가 아침에 전처리할 때 한 단계에서는 흑백으로 바꾸고 한 단계에서는 또 뭘 하고 이런 거를 했듯이 이 안에서 그런 일들이 저절로 일어나게 된다는 거죠

그래서 그런 거를 표상학습이라고 하는데 표상이라는 게 실체가 있을 때 실체를 우리한테 보여주는 거를 표상이라고 합니다

영어로 보면 리프리젠테이션인데 발표하는 걸 프리젠테이션이라고 하죠

프리젠테이션은 뭔가

보여주는 게 프리젠테이션인데 리프리젠테이션은 다시 보여준다

이거죠

원래 어떤 게 있는데 그걸 그대로 보여주는 게 아니라 뭔가 다르게 보여주는 그런 게 리프리젠테이션입니다

보통 리프리젠테이션은 뭔가를 보여주는 게 프리젠테이션인데 리프리젠테이션이 영어로 할 때 더 많이 쓰는 말은 대표 이런 거죠

국회의원이 있으면 국회의원이 자기를 지지해주는 유권자가 있고 유권자의 민의를 국회의원이 국회에 가서 대표를 하는 거잖아요

근데 민의를 그대로 표현하는 건 아니죠

우리가 예를 들면 아 세상 살기 뭐 같네 그냥 좀 나라가 뒤집어졌으면 좋겠다 라고 생각한다고 국회에 가서 그렇게 말하면 안 되죠

국회의원은 국민들이 실망이 큽니다

그렇게 좀 좋게 얘기를 해 주잖아요

국민들의 불만이 크니까 국민의 뜻을 받아서 이렇게 대표를 하는데 그대로 표현하는 게 아니라 뭔가 이렇게 해석을 재해석을 해서 표현하는 게 대표인데 영어로는 똑같습니다

대표나 표상이나 리프리젠테이션 하는 거예요

어떤 이미지가 있으면 그 이미지를 그대로 처리를 하는 게 아니라 내부적으로 어떤 적당하게 우리가 원하는 출력을 얻을 수 있는 형태로 그 안에서 학습이 일어나서 잘 된다

이런 얘기에요

그 다음에 우리가 학습이란 말을 계속 쓰는데 인간하고 기계는 학습 방법이 좀 다릅니다

우리가 AI 이런 걸 영화로 일단 먼저 접한 다음에 공부를 하기 때문에 자꾸 이제 영화에 나오는 AI 이런 거를 생각을 한단 말이에요

영화에 나오는 AI는 일단 기본적으로 약간 인격이 있습니다

그래서 농담도 하고 우리가 인터스텔라 이런 영화 보면 거기 나온 로봇들이 사람이랑 교감도 하고 농담도 하고 이런단 말이에요

사람같이 행동을 자꾸 합니다

근데 기계는 사람이 아니에요

그래서 채찍 PT 같은 것도 우리가 대화를 해보면 자꾸 사람 같아요

그래서 자꾸 사람 같은 걸 기대를 하는데 그러면 채찍 PT를 잘못 쓰는 겁니다

그래서 채찍 PT 쓸 때 되게 중요한 팁 중에 하나가 인사를 안 하는 거거든요

채찍 PT 쓰시는 분들은 채찍 PT한테 인사하지 마세요

근데 자꾸 인사를 하거든요

안녕?

이러면서 오늘도 나랑 같이 즐겁게 일을 해볼까?

네 물론이죠

뭐 이러는데 사실 그게 성능을 떨어뜨립니다 인사를 하고 이런 대화를 하는 게 네 네 왜냐하면 얘는 사람처럼 생각하지 않기 때문에 물론 인사를 해주면 대답은 하죠

근데 내가 하려는 일은 인사하는 게 아니라 뭔가 다른 일을 시키려고 하는데 그 앞에 채찍 PT랑 인사하고 주고받은 대화가 뒷단의 작업에 영향을 줘요

근데 그게 보통 부정적인 영향을 줍니다

인사를 하시면 안 돼요

근데 우리가 자꾸 인사하고 싶거든요

왜냐면 말도 잘 듣고 자꾸 시키는 거 잘하니까 기특하잖아요

자꾸 인사하고 싶고 잘한다 잘한다 하고 싶은데 그게 우리의 착각인 거죠

우리는 약간 인간의 특수성인데 뭔가 인간처럼 생긴 거를 자꾸 인간처럼 대하려고 하는 그런 게 있어요

그래서 어릴 때 인형 가지고 놀고 인형은 사람이 아니잖아요

근데 자꾸 인형한테 말도 걸고 막 이런단 말이에요

인형이 뭐 말 걸면 알아듣습니까?

이렇게 얘기하면 애들은 슬퍼하겠지만 어쨌든 기계는 기계다 항상 아무리 우리 눈에 사람같이 보여도 걔는 기계다라는 거를 항상 좀 염두에 두셔야 되고 그래서 이제 우리가 AI 같은 경우도 인간하고 비슷해 보이지만은 항상 결국에는 어딘가 다른 부분이 있다는 거를 생각을 해두셔야 됩니다

그래서 특히 학습에서도 인간은 소량의 데이터로 학습을 할 수 있는데 이걸 진짜 잘하거든요

사람의 특징 중에 하나인데 데이터가 많지 않아도 학습을 빨리 한다는 게 인간의 장점이자 단점입니다

왜 장점이냐 하면 빨리 학습하니까 당연히 장점이죠

왜 단점이냐면 우리의 편견이라든가 이런 게 전부 다 그 특성에서 나오는 거거든요

우리가 왜 편견을 가지냐면 학습을 너무 빨리 해서 생기는 거예요

하나 둘만 보면은 예를 들면은 내가 빨간머리한테 사기를 한 두 번 당했다 그러면 평생 빨간머리 안 믿습니다

근데 그거는 너무 빨리 학습한 거죠

그래서 부정적일 때는 편견이 되는 거고 긍정적일 때는 회사 일하는데 선배가 한 두 번쯤 보여주면 아 일 저렇게 하는 거구나

그 다음부터는 잘하는 거죠 장점이 될 때도 있고 단점이 될 때도 있고 그래요

그래서 이제 이런 거 되게 잘 보여주는 게 애기들 말 배울 때 보면은 정말 엄청난 속도로 말을 배우거든요

그러면 애기들이 어느 정도로 말을 빨리 배우냐면 보통 애기들이 한 단어를 배울 때 딱 한 번만 노출되면은 그 단어를 배울 수 있습니다

처음 첫 시기를 지나고 나면 어느 정도 시기를 지나면 단어 배우는 속도가 한 번만 들으면 평생 기억해요

근데 우리가 이제 나이가 들면 그게 더 이상 안 되거든요

영어 같은 거 100번 들어도 다 까먹잖아요

어려운 단어는 근데 애들은 어렸을 때 한 번만 딱 들으면 그걸 평생 기억할 수 있는 거예요

그게 이제 시기별로 좀 다른데 어른이 되면 또 한 번 보면 기억하는 게 그런 게 있습니다

그러니까 인간의 어떤 되게 큰 능력 중에 하나인데 AI는 그게 안 돼요

그래서 굉장히 대량의 데이터가 있어야만 학습을 할 수 있고 그다음에 학습할 수 있는 범위도 굉장히 좁습니다

그래서 애들 같은 경우도 처음에는 강아지 고양이 이런 거 구별 잘 못하고 다 강아지라고 했다가 어느 정도 구별을 딱 하기 시작하면 예를 들면 곰 같은 거 한 번만 사진 보여주면 그때부터는 곰 다 구별할 수 있습니다

그리고 이제 막 나중에 좀 한 5살 6살 되면은 공룡 이런 것도 구별하기 시작하면 어른들은 다 똑같은 공룡인데 아 그게 같은 공룡이 아니지 이거는 뭐고 이건 뭐고 하는데 들어도 하나도 이해 모르겠거든요

근데 엄청난 그 학습 속도를 보여줘요

근데 이제 AI는 그게 안 된다는 거예요

그래서 굉장히 좁은 범위의 문제만 되고 다른 문제로 이제 옮겨가는 걸 전이라고 하는데 이 전의가 잘 안 돼요

근데 이것도 이제 사실 요즘에는 옛날 얘기고 그래서 이게 굉장히 큰 한계다 보니까 어떻게 하면 이 전의가 쉽게 할까

이거가 이제 굉장히 많이 발전이 돼서 아까 얘기 드렸다시피 미리 어차피 우리가 학습을 시켜봤자 어느 정도 범위가 있단 말이에요 무한히 다양한 사물을 학습시키는 건 아니니까 굉장히 미리 다양한 범위로 학습을 시킨 다음에 그러면은 우리가 해봤자 결국에는 강아지 고양이 구별하고 이런 거란 말이에요

예를 들면 회사에서 뭘 한다

제조업 기업이다

그러면은 부품의 종류가 세상에 다양하긴 하지만 그렇다고 부품이 다 부품같이 생겼지

거기서 아무리 다양해 봤자 우리가 무슨 외계 부품을 가져오지 않는 이상 인간이 제조업에서 쓰는 부품의 형상이라는 게 한계가 있단 말이에요

그러면은 백만 개 천만 개 다양한 부품을 미리 학습을 시켜놓으면 우리 회사에서 좀 특이하게 생긴 부품이라고 하더라도 기존 부품하고 그렇게 다른 건 아니거든요

그래서 미리 그렇게 학습을 시키는 프리트레이닝 하는 시키는 방식으로 트랜스퍼를 좀 더 쉽게 하는 그런 식의 시도들이 이루어지고 최근에는 전이 학습도 어느 정도 가능해진다

그래서 데이터가 그렇게 많지 않아도 되고 이제 이게 극단적으로 가면은 제로샷 러닝까지 가는데 제로샷 러닝은 데이터가 전혀 없어도 됩니다

그거는 어떻게 하냐면 어떤 이미지를 학습을 시킬 때 그 이미지를 표현하는 말 같은 것도 같이 학습을 시키는 거야

예를 들면 우리가 나사를 학습을 시킬 때 나사의 이미지를 표현하는 것과 같이 학습을 시키는 거예요

이미지만 학습을 시키는 게 아니라 그 나사를 표현하는 말도 같이 학습을 시키는 거죠

아 이 나사는 좀 굵은 나사야

그러면은 우리가 예를 들어서 어떻게 생긴 나사를 구별하고 싶은데 그 이미지가 전혀 없어요

근데 얘는 말도 같이 학습을 했으니까 그냥 말로만 설명을 해줘도 내가 구부러진 나사를 구분하고 싶은데 네가 구부러진 나사를 구분해봐 라고 하면 얘가 이때까지 수많은 구부러진 사물도 학습했고 나사도 학습을 했기 때문에 구부러진 나사라고 말만 해도 그 이미지를 전혀 보지 않고도 구부러진 나사를 거기까지도 사실 지금 거의 발전이 돼 있어요

완벽하지는 않은데 어느 정도 돼 있고 그래서 이제 그게 좀 더 발전하면은 컴퓨터 비전 수업도 그냥 말로만 다 떼오겠죠

자 이제 여기 태권브이 찾아보세요

컴퓨터한테 태권브이 찾아보세요 라고 말해보세요 하면은 태권브이 찾아봐 이렇게 다 같이 웅얼웅얼웅얼 말하면 다 찾아주고 그것도 그렇게 멀었다고 생각하지는 않습니다

제 생각에 한 5년 정도면 그런 것도 보실 수가 있을 거예요

그래서 근데 아직은 러닝이 그렇게 원활하게 잘 되지는 않기 때문에 어느 정도는 우리가 이제 데이터를 모아야 된다

이 정도로 정리를 할 수 있겠습니다

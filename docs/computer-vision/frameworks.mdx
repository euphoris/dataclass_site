# 딥러닝 프레임워크

## 머신러닝을 위한 기본 라이브러리
*   넘파이(numpy)
    *   고성능 수치 연산을 위한 라이브러리
    *   머신러닝, 데이터 분석의 기반
    *   싱글 코어에 최적화, 병렬 처리는 안됨
    *   딥러닝에는 직접 사용되지 않으나, 사용법이 호환됨
*   판다스(pandas)
    *   표 형태의 데이터에 대한 불러오기, 저장, 정렬, 필터링 등의 기능을 제공
*   사이킷런(scikit-learn)
    *   머신러닝 라이브러리
    *   딥러닝을 제외한 머신러닝 전 과정의 기능을 제공
    *   대부분의 머신러닝 라이브러리들이 사이킷런과 호환

## GPU
*   컴퓨터에서 일반적인 계산은 중앙처리장치 CPU라고 하는 칩에서
    *   CPU는 병렬 처리에 최적화되어 있지 않으며 처리 능력이 제한
    *   CPU의 사양을 보면 "코어" → 쉽게 생각하면 코어 하나가 한 번에 한 가지 계산
*   딥러닝에서는 여기에 더해 GPU라는 칩을 사용
*   GPU(그래픽 처리 장치): 원래는 게임 등에서 컴퓨터 그래픽을 처리하는데 특화된 장치
    *   GPU는 대량의 단순 계산을 병렬로 실행
    *   여러 가지 계산을 순서대로 하는 것이 아니라 따로 따로 계산한 다음에 합칠 수 있음
    *   개인용 PC에서 CPU에 있는 코어 개수는 많아야 열 몇 개 vs. 최신 GPU에는 몇 만 개의 코어
*   그래픽도 딥러닝과 같이 단순 계산이 많음
    *   동시에 여러 가지 계산을 할 수 있는 GPU를 활용하면 높은 성능을 낼 수 있음

## 기억 장치 memory
*   컴퓨터에는 다양한 기억 장치가 있음
*   레지스터(register): CPU 내부의 기억장치. 용량은 작으나 매우 빠름
*   캐시 메모리(cache memory): CPU와 RAM 사이에 있음
*   RAM: 컴퓨터가 켜져 있는 동안만 내용이 유지되는 주 기억장치
*   스토리지: HDD 또는 SSD. 매우 크고 느리지만, 컴퓨터 꺼도 내용 유지
*   VRAM: GPU의 RAM
    *   Mac의 AppleSilicon은 RAM과 VRAM이 통합
    *   딥러닝 모델 구동을 위해서는 VRAM 용량이 중요
    *   용량 계산 방법: 파라미터 수 × 자료형 크기(예: LLaMA3 70B 모델 = 약 48GB 필요)

## 딥러닝 프레임워크
*   GPU 지원 + 딥러닝 모델을 정의하고 학습시키는데 필요한 다양한 기능들을 제공
*   텐서플로 TensorFlow
    *   구글이 개발
    *   가장 높은 점유율
    *   기업용 기능이 많음
*   파이토치 PyTorch
    *   페이스북이 개발
    *   새로운 모형을 만들기 편리하여 학계에서 인기
*   작스 jax
    *   다양한 수학 계산을 최적화하여 빠르게 실행하는데 초점
    *   딥러닝도 구현할 수 있음
*   케라스 Keras
    *   여러 딥러닝 프레임워크를 같은 방법으로 편하게 사용할 수 있도록 하는 라이브러리
    *   텐서플로, 파이토치, 작스 모두 지원

## 모델 가용성 Model Availability
*   더 크고 복잡한 최신 모델이 계속해서 발표
*   모든 모델을 직접 구현하기는 어려움
*   해당 프레임워크로 이미 구현된 모델을 쉽게 구할 수 있는 지가 중요
*   최신 모델 가용성에서는 파이토치가 압도적으로 우세
    *   학술지 발표 논문 중 80%가 파이토치를 사용
    *   코드 공개 사이트 Papers With Code에서 파이토치 코드가 60%
    *   모델 공유 사이트 HuggingFace에서 파이토치만 지원하는 모형이 85%
*   구글, 딥마인드 등의 기업 및 강화학습 등의 분야에서는 텐서플로가 우위

## 배포 인프라 deployment infrastructure
*   모델을 실제 비즈니스 환경에서 효율적으로 사용할 수 있는 것이 중요
*   모델 개발은 Python으로 하지만, 운용시에도 사용하기에는 느림
*   텐서플로는 서버, 모바일, 웹 등 다양한 환경에서 빠르게 실행 가능
*   파이토치도 관련 기능을 따라잡고 있으나, 텐서플로가 여전히 우위
*   오디오, 비디오 등의 기능도 텐서플로
*   기업 채용 공고는 텐서플로가 더 많음

## GPU 클라우드
*   딥러닝 모형의 미세 조정을 위해서는 고성능 GPU가 필요
    *   직접 딥러닝 워크스테이션을 구축
    *   GPU 클라우드 사용
*   GPU 클라우드:
    *   runpod.io
    *   lambdalabs.com
    *   vast.ai
    *   fluidstack.io
    *   coreweave.com
*   구글 colab: 구글에서 제공하는 Python 서비스
    *   무료로 고성능의 서버에서 머신러닝 모형을 돌릴 수 있음

## colab 접속
*   구글에서 colab 검색, 또는 colab.research.google.com에 접속
*   구글 아이디를 이용하여 로그인

## colab pro
*   colab.research.google.com/signup 에서 Pro 또는 Pro+ 선택
*   해외 결제 가능한 신용카드(Visa, MasterCard 등) 필요
*   세금 별도

## colab 새 노트 만들기
*   메뉴에서 파일 -> 새 노트 선택

## 런타임 유형 변경
*   메뉴: 런타임 → 런타임 유형 변경
*   T4 GPU
*   성능: A100 GPU > L4 GPU > T4 GPU > CPU

## colab에 파일 업로드
*   왼쪽 파일 관리 메뉴 클릭
*   파일 업로드:
*   구글 드라이브 연동:

## colab에서 코드 실행
*   코드 입력 후 단축 키 SHIFT+ENTER를 누르면 실행

## 퀴즈
<iframe src="https://tally.so/embed/mOZ247?alignLeft=1&hideTitle=1&transparentBackground=1&dynamicHeight=1" loading="lazy" width="100%" height="901" frameborder="0" marginheight="0" marginwidth="0" title="[CV] 딥러닝 프레임워크"></iframe>
{/*
딥러닝 프레임워크

자 그래서 우리가 이제 머신러닝을 하는데 여러 가지 라이브러리를 쓰는데요 우리가 지금까지 넌파이는 좀 써봤어요

그죠 넌파이는 뭐 어떤 수학 계산 같은 걸 할 때 썼고 그 다음에 이제 판다스라든가 사이킨런 이런 게 있는데 우리 수업에서는 이런 거는 안 썼는데요

판다스나 사이킨런은 판다스는 쉽게 말하면 엑셀로 하는 작업을 좀 파이썬에서 할 때 쓰는 겁니다

우리는 이제 그런 표 형태의 데이터를 쓸 일이 지금 없기 때문에 판다스는 안 썼고요

그 다음에 사이킨런은 머신러닝 라이브러리인데 딥러닝을 제외한 그러니까 좀 전통적인 머신러닝 알고리즘들을 구현해 놓은 라이브러리에요

그래서 우리가 이제 사이킨런은 이것도 뭐 쓰려고 하는 거지만 사실 요즘에 전통적인 머신러닝을 좀 잘 안 하는 추세이기 때문에 이것도 그냥 넘어갔습니다

그 다음에 딥러닝은 아까도 얘기 드렸듯이 gpu라고 하는 칩을 쓰는데 컴퓨터에서 일반적인 계산은 cpu라는 칩을 써요

그래서 뭐 i3니 i5니 i7이니 뭐 이런 칩들인데 이 칩들은 코어라는 게 있습니다

그래서 보통 이제 보면은 코어가 몇 개 있다

이런 얘기를 하거든요

우리 것도 보면은 여기 컴퓨터에서 이제 작업관리자를 켜보면 여기 이제 성능 탭에 가보면은 여기 이제 cpu가 있고 13세대 인텔 코어 i7 13700 되게 좋은 칩을 갖다 놨네요

이렇게 했는데 여기 보면은 지금 이렇게 그래프가 여러 개가 동시에 나오죠

지금 하나 둘 셋 넷 다 여 그래서 지금 이렇게 나오는데 여기 밑에 보시면 코어가 16개가 있고 그리고 여기 밑에 보시면 코어가 16개가 있고 그리고 여기 밑에 보시면 코어가 16개가 있고 논리프로세서가 24개 있다

이렇게 나오는데 논리프로세서가 24개 있다

이렇게 나오는데 그러니까 실제로 cpu는 하나지만 얘가 동시에 일을 할 수 있는 건 16개고 얘가 동시에 일을 할 수 있는 건 16개고 거기다가 약간 어떤 기술을 넣어서 마치 24개의 칩이 있는 것처럼 이렇게 돌아가고 있습니다

각각 칩마다 뭔가 지금 일을 많이 하면 각각 칩마다 뭔가 지금 일을 많이 하면 그래프가 올라가고 일을 적게 하면 그래프가 내려가고 이렇게 되는데 이 코어가 뭐 결국 16개 논리적으로 해도 24개밖에 안 된단 말이에요

이게 굉장히 비싼 칩이거든요

13700 그래서 뭐 비싼 칩이라고 해도 그래서 뭐 비싼 칩이라고 해도 이 cpu는 뭐 깍해야 한 번에 할 수 있는 작업이 20개 30개 이렇게 밖에 안 됩니다

뭐 깍해야 한 번에 할 수 있는 작업이 20개 30개 이렇게 밖에 안 됩니다

딥러닝은 레이어가 굉장히 많고 딥러닝은 레이어가 굉장히 많고 레이어가 많기 때문에 계산량이 굉장히 많아요

근데 계산량이 되게 많은데 예를 들면 우리가 덧셈 뺄셈을 몇 백만 개를 해야 되는데 아무리 수학을 잘하는 수학과 대학생이 와서 해도 아무리 수학을 잘하는 수학과 대학생이 와서 해도 덧셈 100만 개를 빨리 할 방법은 없단 말이에요

그래서 이제 gpu라는 칩을 쓰는데 gpu는 원래 이제 그래픽에 쓰는 칩인데 gpu는 원래 이제 그래픽에 쓰는 칩인데 이거를 saker 다칠 때 얘 특징은 뭐냐 하면 복잡한 계산은 얘는 잘 못해요

근데 뭐냐 하면 얘 특징은 단순 계산을 병률로 발읍니다

그래서 얘는 코어가 몇 만 개 몇 십만 개 이렇게fte요 그래서 reserve 는하나 더 복잡한걸 할 수있고 그래서 reserve 는하나 더 복잡한걸 할 수있고 계산 하나를 더 잘 할 수 있는데 계산을 많이 하는 거는 cpu가 지피 un보다 못합니다

gpu는 동시에 초등학생 10만님이 와가지고 덧셋 문제를 풀면 gpu는 동시에 초등학생 10만님이 와가지고 덧셋 문제를 풀면 엄청 빨리 풀겠죠

얘네한테 미적분을 주면 못풀겠지만 각각 10만명의 초등학생들이 각자 문제 3개씩 풀면 금방 끝나겠죠

그래서 이 GPU의 특징이 동시에 단순 계산을 많이 할 수 있는 그런 특징이 있고 그래픽이랑 딥러닝이 다 그런 특징을 공유하기 때문에 원래 GPU는 이제 지가 그래픽 처리 장치인데 딥러닝도 할 수가 있는 겁니다

그래서 우리가 이제 딥러닝을 할 때 GPU를 써야 되는데 이 GPU가 이제 굉장히 비쌉니다

어제 그제도 보여 드렸지만 이거 H100 이게 최신도 아닌데 거의 산세대 전인데 가격이 4천만 원이래요

엄청 비싸죠

이거를 반을 남겨 먹으니 도대체 얼마를 남겨 먹었는지 어쨌든 근데 여기 이제 보시면은 그 우리 HBM3 이런 것도 있고 요즘에 하이닉스가 이걸로 돈을 많이 벌었죠

그래서 이제 Vram이라는 게 있는데 이 Vram이 이제 왜 하이닉스가 돈을 이렇게 많이 버느냐 엔비디아 칩이 계산이 빨라요

계산 빠른 건 오케이 계산이 빨라서 돈을 많이 버는 건 알겠는데 하이닉스는 왜 거부하는지 왜 거부하다 돈을 버느냐 하이닉스가 이제 여기 엔비디아에 HBM을 공급을 하는데 이게 이제 용량이 중요합니다

왜 용량이 중요하냐면 모델이 점점 커지고 있어서 그래요

그래서 아무리 계산이 빨라도 모델을 로딩이 올릴 수가 있어야 계산을 하는데 모델이 점점 커지니까 그 큰 모델을 담기 위해서 더 많은 메모리가 필요하고 그 다음에 이제 메모리가 속도가 느려 버리면 메모리에서 읽어오는데 시간을 다 잡아먹는 거죠

계산은 일단 둘째 치고 메모리에서 읽어와야 뭐 계산을 할 거 아니에요

그래서 이제 굉장히 고성능에 굉장히 빠른 메모리가 필요한데 HBM이 그런 메모리죠

그래서 이제 하이닉스가 이걸로 돈을 많이 벌었고 역시 이제 돈 잘 버는 사람 옆에 있어야 같이 돈을 잘 번다

이런 거를 알 수 있습니다

어쨌든 그래서 우리가 이제 이런 GPU를 쓰게 되는데 그래서 이제 Vram이 크면 좋다

이런 얘기를 하고요 그러면 우리가 이제 딥러닝을 하려면은 일반적인 우리가 프로그래밍은 일반적인 프로그래밍은 CPU에서 어떤 돌아가는 프로그램을 짭니다

GPU에서 돌아가는 프로그램은 짜는 방법이 좀 달라요

우리가 프로그램을 CPU 따로 GPU 따로 배우려면은 좀 힘들거든요

그래서 어떻게 하냐면 딥러닝 프레임워크들이 제공하는 기능들이 있는데 뭐냐면 CPU가 우리가 지금까지 배운 프로그래밍 방식에서 크게 벗어나지 않게 프로그램을 짜더라도 알아서 GPU에서 잘 돌아가게 해줍니다

프로그램을 직접 GPU를 우리가 제어하는 게 아니라 약간 우리는 우리대로 알아서 짜면 그걸 GPU에 잘 돌아가게 맞춰 주는 거죠

그래서 이제 복잡한 부분을 우리가 이제 몰라도 되게 하는 부분이 있고 그 다음에 딥러닝 모델을 정의를 하려면 또 학습을 시키려면 예를 들면 미분 같은 걸 할 줄 알아야 되는데 우리가 이제 미분 같은 거 뭐 고등학교 잘해봐야 대학교 1, 2학년 때 좀 하고 그 다음부터는 잘 안 한단 말이에요

그래서 이제 미분 해봐라 이러면은 기억도 안 나고 그리고 이제 모델이 너무 커지니까 그거 일일이 미분을 손으로 하는 것도 굉장히 어려운 일이 됩니다

그래서 어차피 미분이라는 게 그것도 계산이니까 컴퓨터가 잘하는 게 계산이죠

그러니까는 그런 기능까지 다 지원을 하고 있습니다

그래서 우리가 사실 원래 딥러닝을 수식으로 풀려면 굉장히 수식이 복잡하고 수식을 코드로 짜는 것도 되게 어려운 일인데 그런 어려운 일들을 다 딥러닝 프레임워크가 다 알아서 해주기 때문에 어렵지 않게 완전 쉽다는 얘기는 아니에요

어렵지 않게 할 수 있고 사실은 요것도 약간 트렌드가 좀 바뀌어서 사실 딥러닝을 하시려면 딥러닝 프레임워크를 쓸 줄 아셔야 되는 것도 약간 옛날 얘기입니다

사실 아주 AI를 담당하시는 아시겠지만 업무를 하시거나 이런 게 아니시면 아까 보셨듯이 점점 툴들이 쉬워지고 있어서 코드를 굳이 굳이 짜지 않아도 되기 때문에 사실 딥러닝 프레임워크도 제 생각에는 완전 AI 모델을 직접 설계하고 만드시는 분들 아니면 굳이 배울 필요가 있을까

이런 생각이 들긴 하는데 아직까지는 조금 알아두면 좋은 데가 좀 있어서 조금 배워두도록 하겠습니다

딥러닝 프레임워크가 하나만 있는 건 아니고 여러 개가 있어요

여러 개가 있는데 대표적인 게 텐서플로우, 파이토치, 그 다음에 삭스, 케라스 이런 게 있습니다

제일 점유율이 높은 거는 텐서플로우에요

텐서플로우는 점유율이 제일 높은데 요즘에는 좀 약간 하향세입니다

요즘에는 좀 하향세고 그 다음에 파이토치라고 있는데 요즘에는 좀 하향세고 그다음에 파이토치라고 있는데 파이토치가 요즘에 점점 많이 쓰이고 있는데 왜 그러냐면은 사실 기능이나 이런 거에 차이라기보다는 새로운 모형을 만들기가 편하냐

이 차이인데 사실 딥러닝은 아직 그렇게 성숙된 분야가 아니에요

그러니까 대부분의 기술 분야들이 수십 년간 누적된 게 있어서 여기서 더 발전한다고 해봤자 본질적으로 엄청나게 달라지는 거는 아닌 경우가 많은데 딥러닝 같은 경우는 아직까지 유행 타기 시작한 지도 10년 이 정도밖에 안 됐고 대부분 이 프레임워크도 보시면은 텐서플로우 나온 게 2016년이거든요

10년도 안 됐죠

그래서 되게 역사가 짧습니다 그러다 보니까는 새로운 모형이 오늘도 계속 나오고 있는데 그러면은 학계에서는 계속 새로운 모형을 만들어야 되니까 새로운 모형을 만들기 편한 프레임워크가 있기가 있겠죠

근데 이제 그러면은 회사에서는 어차피 새로운 모형 그렇게 안 만들어도 되지 않나요

이렇게 얘기를 할 수 있는데 회사에서도 우리가 이제 기왕이면 새로운 모형들 새로 나오는 모형들이 좀 쓰고 싶죠

새로 개발은 안 하더라도

근데 이제 딥러닝 쪽에 약간 특징 중에 하나가 뭐냐면 이런 코드 같은 것도 대체로 공개하는 것이 전반적인 문화입니다

우리가 이제 다른 사업을 하고 있는 경우가 많고 산업 분야에 익숙하신 분들은 굉장히 좀 이상하게 느껴지는 부분인데 기술을 아직까지는 그래도 기술을 좀 많이 공개하는 문화가 있어요

그래서 페이퍼스 위드 코드라는 사이트가 있는데요 여기를 가보면 페이퍼는 논문이고 페이퍼와 코드 뭐 이런 사이트죠

구글 가셔서 페이퍼스 위드 코드 이렇게 검색하시면 나오는데 보시면 트렌딩 리서치 해가지고 최근 인기 있는 논문이 뭐가 있는지 이렇게 나옵니다

그래서 이제 보시면은 옴니젠 유니파이드 이미지 제너레이션에서 이미지 생성 모델의 어떤 논문이 있고요

여기 보시면 이거 파이토치로 구현되어 있다

이거 누르면 이 논문에서 사용된 모델의 코드를 다운받을 수 있다

이렇게 돼 있습니다

그리고 또 밑으로 내려 보면은 여기도 뭐 svd 퀀트 그래가지고 뭔가 노이즈 제거나 이런 거 하는 모델일 것 같은데 뭐 뭔지는 잘 모르겠고요 어쨌든 파이토치로 또 돼 있고 여기 가면 다운받을 수 있다

그다음에 또 어 이건 또 뭘까요 하여간 또 무슨 모델이 있는데 이것도 또 파이토치로 돼있습니다

그다음에 또 보면은 또 무슨 모델인데 이것도 파이토치로 돼 있네요

여러분들이 이제 파이토치를 쓰실 줄 알면은 이 논문을 읽으실 필요도 없이 그냥 아무 데나 하나 들어가

볼까요

들어가 보면은 이제 머시기 머시기 이제 최신 논문이 있는데 이 논문은 이렇게 이렇게 했고 중국에서 쓴 논문인데요 칭화대에서 칭화대 연구팀이 쓴 논문인데 보면은 이제 뭐 하는 논문인지는 모르겠지만 뭔가 좋은 걸 하는 논문이겠죠 뭔가 좋은 걸 하는 논문인데 이 내용을 쭉 볼 필요 없이 밑으로 내려가면은 이 함수를 어떻게 돌릴 수 있는지

그래서 그냥 파이썬 edit.py 하고 이렇게 돌리면 된다

이런 식으로 대부분 그냥 아무것도 몰라도 돌릴 수 있게 이게 이런 거군요

뭐 이렇게 사진을 올리면 이렇게 하이킹 하는 건데 막대기를 짚은 모양으로 바꾸라든가 말 타고 있는 건데 낙타를 타고 있는 걸로 바꾸라든가 이런 걸 해주는 모델입니다

그래서 이거를 이제 네가 가진 이미지로도 이렇게만 하면은 이 코드 다운받아서 이렇게만 하면 돌릴 수 있다

이렇게 제공을 해 주는 거죠

그러니까 남들이 만든 이런 코드를 그냥 가져다 쓰기만 해도 우리가 할 수 있는 것이 굉장히 많은 거죠

그래서 보시면은 지금 쭉 보면은 계속 파이토치로 돼 있고 처음 이제 작스로 된 게 하나 나왔는데 대부분 거의 파이토치로 돼 있습니다

학계에서 파이토치로 연구를 하고 그 코드까지 다 공개를 하니까 우리가 정말 딥러닝에 대해서 아무것도 몰라도 그냥 인터넷에서 코드 다운 받아서 파이썬으로 돌릴 줄만 알면은 그냥 다운 받아 돌리면은 뭔진 모르겠지만 하여간 잘 돌아가는 그런 거를 할 수 있어요

그래서 요즘에 보면 뭐 무슨 고등학생들도 딥러닝 하고 있거든요

그래서 참 저는 큰일이다

이런 생각이 드는데 그러니까 이제 우리가 기술에 대한 어떤 접근권이 신호진 거죠

회사들도 최신 논문을 따라 하고 싶은데 파이토치를 그냥 쓰면 그냥 파이토치로 공개된 코드 다운 받아 갖고 딱 돌릴 줄 아는 고수준까지만 하면 그 코드 한 줄도 무슨 말인지 이해를 못 해도 내가 최신 기법을 써 볼 수 있다는 거죠

그래서 이제 회사에서도 최근에는 파이토치를 점점 많이 쓰는 그런 추세고요 아까 보셨듯이 작스 라는 것도 있는데 요거는 뭔가 이제 좀 파이토치보다 더 발전된 그런 느낌이 있긴 한데 아직까지 요거는 신생툴이라서 신생입니다 나온 시점을 보면 나온 시점이 더 늦어요

2019년에 나왔거든요

그래서 더 신생이라 가지고 사실 이제 작스는 정말 학계 일부에서 밖에 안 씁니다

쓸 줄 아는 사람도 잘 없고 근데 이제 좀 아름아름 인기를 얻고 있긴 한데 뭐 어찌 될지는 잘 모르겠어요

그래서 사실 작스를 배우는 거는 좀 제 생각에는 아직 좀 이르다

이런 생각이 들고 파이토치를 제일 권할 만하고요 그 다음에 캐라스 라고 있는데 이거는 이제 뭐냐면 이제 이렇게 프레임워크가 여러 개가 있으니까 내가 이거를 사용법을 다 배우려면은 좀 힘들잖아요

왜냐면 이제 파이토치 쓰는 사람도 있고 작스 쓰는 사람도 있고 텐서플로 쓰는 사람도 있고 그러니까 내가 나는 파이토치 배웠는데 회사 왔더니 우리 회사는 텐서플로 쓰더라.

이러면 이제 곤란하죠

캐라스는 이 자체는 어떤 이런 기능들을 제공하지 않는데 이 세 가지를 모두 같은 방법으로 쓸 수 있게 해주는 라이브러리입니다

캐라스를 쓴 다음에 뒷단에다 작스를 붙이면 작스로 돌아가고요 뒷단에 파이토치를 붙이면 파이토치로 돌아가고 텐서플로를 붙이면 텐서플로로 돌아가고 내 코드는 캐라스인데 실제로 돌아가는 거는 다른 프레임워크를 쓸 수 있도록 그러면은 모두가 사이좋게 지낼 수 있는 거 아니냐

뭐 이런 거죠

그래서 캐라스 같은 경우는 약간 초보자들한테 권할 만하고요 사용법이 일단 쉽거든요

그 다음에 내가 뭐 프레임워크를 이거 썼다 저거 썼다 하고 싶다던가 이런 경우에 좀 권할 만한데 일단은 파이토치로 우리는 해 보도록 하겠습니다

근데 사실 써보시면 다 비슷해요

뭐 그게 그렇게 크게 사용법이 다르지는 않습니다 조금씩 달라요

약간 스마트폰 외에 요즘 LG는 스마트폰 안 만들지만 옛날에 LG 스마트폰 쓰면 삼성 스마트폰하고 사용법이 좀 다르긴 하지만 그렇다고 우리가 막 완전히 처음부터 새로 배워야 되고 이런 정도는 아니잖아요

좀 적응 시간이 필요한 거죠

그래서 이것들 사이에서도 사용법이 다르긴 하지만 서로 이제 자꾸 베끼기 때문에 사용법이 점점 비슷해지고 약간 좀 적응이 필요하긴 하지만 뭐 그렇게 차이가 나지는 않습니다

그래서 우리가 파이토치로 배우지만은 여러분들이 이제 딴 걸로 전환하시고자 한다면 하나의 툴을 익숙하게 하시면 금방 다른 도구로 익숙하게 하실 수 있습니다

그래서 이제 여기 Papers with Code 이렇게 있는데 파이토치 코드가 60%다

이렇게 써놨는데 이거는 아마 지금은 아마 60%가 아니라 한 90%쯤 될 거 같아요

제가 요 자료를 만들 때는 작년인가에 만든 거라서 그때는 그래도 텐서플로가 좀 있었는데 요즘 텐서플로 코드를 쓰는 사람이 거의 없더라고요

그래서 파이토치를 쓰시면 모델 가용성이 좋다

근데 텐서플로가 한 가지 더 좋은 점이 있는데 배포 인프라 우리가 모델을 만들었을 때 이제 코드를 이제 운용하는 것도 중요한데 텐서플로가 요점에서는 여전히 우위에 있습니다

보통 이제 기업에서는 코드도 중요한데 그 코드를 이제 제 규모로 이제 운용을 하는 것도 중요한데 그런 인프라 측면은 텐서플로가 좀 더 나아요

그래서 파이토치가 이런 측면은 조금 미진한 점이 있습니다

그래서 그냥 기업에서 그냥 우리가 새로운 모델도 필요 없고 그냥 있는 모델 잘 운용만 하고 싶다 이러면은 좀 텐서플로가 강점이 되죠
*/}
# 모형 선택


## 모형 선택
- 주요 개념:
    - 과대 적합
    - 수정 R제곱, AIC, BIC
    - 단계적 회귀분석: 전진 선택, 후진 선택


## 과대적합 overfitting
- 최소제곱법은 잔차분산이 가장 작은 계수를 추정
- 주어진 표본에 가장 맞는 계수를 찾게 됨
- 표집 오차가 존재하기 때문에, 주어진 표본에 지나치게 맞는 계수를 추정하면 모집단의 계수와 다를 수 있음
- (오른쪽 그림) 초록색 선이 실제 데이터 패턴
- 빨간 선은 사용한 모형으로 추정한 패턴
- 0차, 1차 함수는 과소적합(underfitting)
- 9차 함수는 과대적합(overfitting)
- 잔차 = 0이지만(모든 선이 점을 지남) 실제 데이터 패턴과는 거리가 멂


## 독립변수의 개수와 과적합
- 최소제곱법은 잔차분산이 작아지는 방향으로 계수를 추정
- 종속변수와 아무 관련이 없는 독립변수를 추가하더라도 잔차분산이 커지는 경우는 없음
- 모집단에서는 아무 관련이 없어도 표본에서는 약간의 관계라도 있을 수 있으므로 잔차분산은 작아지게 됨
- 독립변수가 많으면 많을 수록 잔차분산은 무조건 작아짐(R제곱은 높아짐)


## 무작위 데이터의 과적합 예시

```python
import numpy as np
np.random.seed(0)
random_data = pd.DataFrame({
    'x1': np.random.randn(5), # 모든 변수를 무작위로 생성
    'x2': np.random.randn(5),
    'x3': np.random.randn(5),
    'x4': np.random.randn(5),
    'y': np.random.randn(5)
})
# 회귀분석을 하면 R제곱이 100%
ols('y ~ x1 + x2 + x3 + x4', data=random_data).fit().summary()
```


## 수정 R제곱과 AIC, BIC
- 여러 모형을 비교할 때 R제곱을 사용하면 독립변수가 많은 모형에 편향
- 독립변수의 개수를 이론적으로 보정한 수정 R제곱, AIC, BIC 등의 지수가 있음
- 수정 R제곱: R제곱을 보정 → 클 수록 좋음
- AIC와 BIC: 잔차분산을 보정 → 작을 수록 좋음
    - 예측이 주 목적이라면 AIC를 선호
    - 모델의 간결성이나 변수들 간의 인과적 관계 설명에 더 중점을 둔다면 BIC를 선호BIC는 변수 개수에 더 큰 패널티 → 더 적은 수의 변수를 가진 모델을 선택할 가능성이 높음


## 단계적 회귀분석 stepwise regression
- 독립변수의 후보가 k개 있으면 가능한 독립변수의 조합은 2^k개
- 독립변수의 후보가 많으면 모든 조합으로 회귀분석을 실시하는 것은 현실적으로 불가능
- 단계적 회귀분석(stepwise regression): 독립변수를 하나씩 추가/제거 하여 종속변수를 잘 예측하는 변수들을 선택하는 기법
- 예측력이 (통계적으로) 유의한 예측변수들만을 골라줌
- 오직 자료만으로 변수를 선택하기 때문에 이상한 결과가 생길 수 있음
- 단계적 회귀분석은 탐색적으로 주요 변수를 파악하는 목적으로만 실시해야


## 전진 선택 forward selection
- 독립변수를 하나씩 추가
- 예) A, B, C, D를 가지고 Y를 예측하는 전진 방식의 단계적 회귀분석을 한다면,
    - A, B, C, D 중 설명력이 제일 큰 예측변수? A
    - A+B, A+C, A+D 중에 설명력이 가장 큰 조합은? A+B
    - A와 A+B의 설명력이 유의하게 차이가 나지 않으면 중단
    - 설명력이 유의하게 차이가 나면 A+B+C, A+B+D 중에 설명력이 가장 큰 조합을 찾음
    - 이상의 과정을 계속

```python
import varsel
m = varsel.forward_selection(
    'price ~ year + mileage + model + my_car_damage + other_car_damage', df)
m.summary()
```


## 후진 선택 backward selection
- 독립변수를 하나씩 제거
- 예) A, B, C, D를 가지고 Y를 예측하는 후진 방식의 단계적 회귀분석을 한다면,
    - A+B+C+D에서 설명력이 가장 적게 줄어드는 변수를 제거 (D라고 하자)
    - A+B+C와 A+B+C+D 설명력이 유의하게 차이가 나면 중단
    - 차이가 나지 않으면 A+B+C에서 설명이 가장 적게 줄어드는 변수를 제거
    - 이상의 과정을 반복

```python
m = varsel.backward_selection(
    'price ~ year + mileage + model + my_car_damage + other_car_damage', df)
m.summary()
```


## 단계적 회귀분석에서 주의할 점
- 변수를 순서대로 선택하기 때문에 검토하지 못하는 조합이 생김
    - A -> A+B -> A+B+C ... 순으로 탐색을 하면 B+C는 검토할 기회가 없음
- 전진 방식과 후진 방식의 결과가 항상 같은 건 아님
    - 대체로 전진 방식이 후진 방식보다 적은 변수를 선택하는 경향이 있음

## 퀴즈

<iframe src="https://tally.so/embed/npzgOb?alignLeft=1&hideTitle=1&transparentBackground=1&dynamicHeight=1" loading="lazy" width="100%" height="2200" frameborder="0" marginheight="0" marginwidth="0" title="[통계] 모형 선택"></iframe>


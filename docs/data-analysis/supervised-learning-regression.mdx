# 지도학습: 회귀


## 머신러닝의 주요 접근
- 지도 학습
- 비지도 학습
- 강화 학습


## 지도학습 supervised learning
- 라벨이 있는 데이터로부터 학습
- 입력(x)과 출력(y) 간의 관계 모형화
- 머신 러닝의 90% 이상을 차지하는 학습 형태
- 종류:
    - 회귀(regression): 연속적인 y를 예측하는 것
    - 분류(classification): 여러 종류의 값들을 구분하는 것. 범주형 y를 예측하는 것


## 지도학습 예시
- 스팸 메일 필터링: 이메일 내용을 분석하여 스팸 여부를 판단
- 이미지 분류: 이미지를 특정 카테고리로 자동 분류
- 질병 예측: 환자의 데이터를 기반으로 질병 발병 확률 예측
- 주가 예측: 과거 주식 데이터를 이용해 미래 주가를 예측


## 회귀 알고리즘
- Linear Regression
- Support Vector Regression
- Nearest Neighbors
- Decision Tree
- Naive Bayes
- Artificial Neural Network


## 중고차 가격 데이터
- 중고차 데이터
  ```python
  df = pd.read_excel('car.xlsx')
  ```
- X와 y
  ```python
  y = df['price']
  X = df.drop(columns='price') # price를 제외한 나머지
  X = pd.get_dummies(X, drop_first=True) # 범주형 변수 더미코딩
  ```
- 데이터 분할
  ```python
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  ```


## 선형 모델
- 선형 회귀분석과 동일
  ```python
  from sklearn.linear_model import LinearRegression
  linear_model = LinearRegression()
  linear_model.fit(X_train, y_train)
  ```
- 모델의 계수(statsmodels와 달리 해석에 필요한 정보들을 제공하지는 않음)
  ```python
  linear_model.coef_
  ```
- 예측
  ```python
  y_pred_linear = linear_model.predict(X_test)
  ```


## 선형 모델 성능 테스트
```python
from sklearn.metrics import *
```
- RMSE: 오차 제곱의 평균의 제곱근
    - 표준편차는 편차 제곱의 평균(분산)의 제곱근
  ```python
  root_mean_squared_error(y_test, y_pred_linear)
  ```
- 결정계수(R²)
  ```python
  r2_score(y_test, y_pred_linear)
  ```


## 지표의 직접 계산
- RMSE
  ```python
  import numpy as np
  np.sqrt(np.mean((y_test - y_pred_linear) ** 2))
  ```
- 결정계수(R²)
  ```python
  mse = np.mean((y_test - y_pred_linear) ** 2) # 예측 값과 차이
  y_mean = np.mean(y_test)
  var = np.mean((y_test - y_mean) ** 2) # 평균 값과 차이
  1 - mse / var
  ```


## Decision Tree
- 회귀 및 분류
- 트리 기반 알고리즘
- 내부 노드에서는 한 특징 값에 따라 분기
- 잎 노드는 최종 예측 결과를 제공
- 이해하기 쉽고 시각화가 가능
- 과적합(overfitting)이 발생하기 쉬운 단점
- 여러 개의 트리를 만드는 Random Forest, Boosting Tree 등의 방법이 있음


## 랜덤 포레스트 회귀
- 의사결정나무를 무작위로 100개 만들어서 각각의 가격 예측을 평균
  ```python
  from sklearn.ensemble import RandomForestRegressor
  rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
  rf_model.fit(X_train, y_train)
  ```
- 예측
  ```python
  y_pred_rf = rf_model.predict(X_test)
  ```


## 특징 중요도 feature importance
- 여러 예측의 평균이므로 각각의 특징이 어떻게 기여하는지 해석은 불가능
- 다만 각각의 예측에 자주/많이 사용되는 정도를 이용해서 상대적 중요도를 보일 수는 있음
  ```python
  import matplotlib.pyplot as plt
  import numpy as np
  importances = rf_model.feature_importances_
  feature_names = X.columns
  indices = np.argsort(importances)[::-1]
  plt.bar(range(X.shape[1]), importances[indices], align="center")
  plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90);
  ```


## 평가
- RMSE
  ```python
  root_mean_squared_error(y_test, y_pred_rf)
  ```
- 결정계수(R²)
  ```python
  r2_score(y_test, y_pred_rf)
  ```
- 선형 모형에 비해 설명가능성은 낮지만 대체로 예측 성능은 높음

## 퀴즈

<iframe src="https://tally.so/embed/3xzOWv?alignLeft=1&hideTitle=1&transparentBackground=1&dynamicHeight=1" loading="lazy" width="100%" height="2269" frameborder="0" marginheight="0" marginwidth="0" title="[통계] 지도학습 - 회귀"></iframe>

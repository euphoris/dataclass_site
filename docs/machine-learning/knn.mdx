# KNN

## K Nearest Neighbors

  * 가장 간단한 머신러닝 알고리즘 
  * 새로운 데이터 포인트를 예측하기 위해 가장 가까운 K개의 이웃을 참조 
  * 회귀(연속적인 값을 예측)의 경우 이웃 값들의 평균 
  * 분류(범주를 예측)의 경우 이웃 값들의 다수결 
  * 훈련 단계가 없고, 모든 계산이 예측 시에 이루어지는 게으른 학습(lazy learning) 방식 

## K에 따른 차이

  * K가 작으면 
      * 적은 사례만으로 예측하므로 노이즈에 민감 
  * K가 커지면, 
      * 많은 사례를 검색하야 하므로 계산 비용이 증가 
      * 거리가 먼 사례도 예측에 포함될 수 있어 너무 크면 성능 저하 

## 스케일링 Scaling

  * 데이터의 특성을 일정한 범위나 분포로 변환하는 과정 
  * 데이터셋의 각 특징(피처)들이 서로 다른 단위와 범위를 가질 경우 비교나 해석이 어려움 
  * 많은 머신러닝 알고리즘, 특히 KNN은 특징 간의 스케일 차이에 민감 
  * 한 특징의 값이 매우 크거나 작은 경우, 모형이 그 특징에 지나치게 의존하게 되어 과적합(overfitting) 이 발생할 수 있음 
  * 방법: 
      * 정규화(normalization) 
      * 표준화(standardization) 

## 정규화 Normalization

  * 데이터를 특정 범위(주로 [0, 1])로 변환하는 방법 
    $X^{\prime}=\frac{X-X_{min}}{X_{max}-X_{min}}$ 



```python
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
normalized = scaler.fit_transform(
df[['mileage', 'year', 'my_car_damage', 'other_car_damage']])
```

  * 문헌에 따라서는 정규화는 스케일링과 동의어로 사용하기도 함 
  * 이때는 위의 방법은 최소-최대 정규화로 구분 

## 표준화 Standardization

  * 평균이  , 표준편차가 10이 되도록 변환하는 방법 
    $X^{\prime}=\frac{X-X_{min}}{X_{max}-X_{min}}$ 



```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
standardized = scaler.fit_transform(
df[['mileage', 'year', 'my_car_damage', 'other_car_damage']])
```

## 원핫 인코딩 one-hot encoding

  * 범주형 변수 변환에 널리 사용되는 방법 
  * 범주의 개수만큼 새로운 특징(변수)를 만듦 
  * 범주의 번호에 해당하는 특징만 1(hot), 다른 특징 값은 0(cold)으로 
  * 차종은 2개이므로 2개의 컬럼이 만들어짐 
  * 사이킷런 사용 



```python
from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder(sparse_output=False)
one_hot = encoder.fit_transform(df[['model']])
```

  * pandas 사용 



```python
df['model'].str.get_dummies()
```

## 더미 코딩 dummy coding

- 원핫 인코딩에서 한 특성은 다른 특징의 조합으로 결정됨
- 앞에서 Avante = 1이면 반드시 K3 = 0 (역도 마찬가지)
- 모델에 따라서는 학습에 문제가 생길 수 있으므로 특징 중 한 개는 제외

```python
encoder = OneHotEncoder(sparse_output=False, drop='first')
encoded = encoder.fit_transform(df[['model']])
```

## 준비

  * X와 y 만들기 



```python
import numpy as np
X = np.hstack((normalized, encoded)) #준비된 데이터를 연결
y = df['price']
```

  * 데이터 분할(20%는 테스트 용으로) 



```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size = 0.2, random_state = 42)
```

## 학습

  * 훈련: 분류의 경우 KNeighborRegressor 대신 KNeighbor Classifier 사용 



```python
from sklearn.neighbors import KNeighborsRegressor
knn = KNeighborsRegressor(n_neighbors=5) # K=5, 즉 5가지 유사 사례로 예측
knn.fit(X_train, y_train) # 훈련
knn.score(X_train, y_train) # 성능 평가
```

  * 테스트 



```python
knn.score(X_test, y_test) # 테스트 데이터로 성능 평가
```

## 예측

  * 예측 

```python
y_pred = knn.predict(X_test)
```

  * 평균 제곱 오차(MSE) 



```python
from sklearn.metrics import mean_squared_error
mean_squared_error(y_test, y_pred)
```

  * R제곱: 1-MSE/분산 
  * 분산은 모든 값을 평균으로 예측했을 때의 MSE이므로, 이에 비해 MSE를 몇%나 줄였는지 평가 



```python
from sklearn.metrics import r2_score
r2_score(y_test, y_pred)
```

## 퀴즈

import { QuizComponent } from "@/components/QuizComponent";

<QuizComponent quizId="regularization" quizItems={
    [
    {
        "item_type": "radio",
        "question": "KNN 알고리즘에 대한 설명으로 가장 올바른 것은 무엇입니까?",
        "options": [
            "데이터의 패턴을 학습하여 복잡한 수학적 모델을 미리 만들어 둔다",
            "새로운 데이터가 들어오면, 가장 가까운 K개의 이웃 데이터를 참조하여 예측한다",
            "데이터를 여러 그룹으로 나누는 클러스터링 알고리즘의 한 종류이다",
            "데이터의 차원을 축소하여 시각화하는 데 주로 사용된다"
        ],
        "hint": "알고리즘의 이름 'K-Nearest Neighbors'에 핵심 원리가 담겨 있습니다. 예측 시점에 계산이 이뤄지는 '게으른 학습' 방식입니다.",
        "solution": "새로운 데이터가 들어오면, 가장 가까운 K개의 이웃 데이터를 참조하여 예측한다"
    },
    {
        "item_type": "radio",
        "question": "KNN에서 K값이 지나치게 클 경우 발생할 수 있는 문제점은 무엇입니까?",
        "options": [
            "모델이 학습 데이터의 노이즈에 매우 민감해진다",
            "예측 속도가 매우 빨라지지만 정확도가 떨어진다",
            "예측에 사용되는 데이터의 범위가 너무 넓어져 성능이 저하될 수 있다",
            "분류 문제에만 사용할 수 있고 회귀 문제에는 사용할 수 없게 된다"
        ],
        "hint": "너무 많은 이웃을 고려하면, 예측하려는 데이터와 관련이 적은 먼 데이터까지 포함될 수 있습니다.",
        "solution": "예측에 사용되는 데이터의 범위가 너무 넓어져 성능이 저하될 수 있다"
    },
    {
        "item_type": "radio",
        "question": "KNN과 같은 거리 기반 알고리즘에서 스케일링(Scaling)이 중요한 이유는 무엇입니까?",
        "options": [
            "데이터의 개수를 늘려 모델의 성능을 높이기 위해서",
            "모든 변수를 범주형 변수로 만들기 위해서",
            "특정 변수의 단위나 범위가 너무 커서 거리 계산에 과도한 영향을 미치는 것을 방지하기 위해서",
            "모델의 훈련 시간을 단축시키기 위해서"
        ],
        "hint": "서로 다른 단위(예: 주행거리 'km'와 연식 'year')를 가진 변수들의 거리를 계산할 때 어떤 문제가 발생할지 생각해보세요.",
        "solution": "특정 변수의 단위나 범위가 너무 커서 거리 계산에 과도한 영향을 미치는 것을 방지하기 위해서"
    },
    {
        "item_type": "radio",
        "question": "데이터를 평균 0, 표준편차 1이 되도록 변환하는 스케일링 방법은 무엇입니까?",
        "options": [
            "정규화 (Normalization)",
            "원핫 인코딩 (One-hot encoding)",
            "표준화 (Standardization)",
            "로그 변환 (Log transformation)"
        ],
        "hint": "데이터의 분포를 '표준'적인 형태로 만든다고 생각해보세요. Scikit-learn의 StandardScaler를 사용합니다.",
        "solution": "표준화 (Standardization)"
    },
    {
        "item_type": "radio",
        "question": "범주형 변수인 '차종'(['세단', 'SUV'])을 머신러닝 모델에 입력하기 위해 [1, 0], [0, 1]과 같은 형태로 변환하는 기법은 무엇입니까?",
        "options": [
            "표준화 (Standardization)",
            "정규화 (Normalization)",
            "라벨 인코딩 (Label Encoding)",
            "원핫 인코딩 (One-hot encoding)"
        ],
        "hint": "여러 범주 중 '하나만 뜨겁게(hot)' 만든다고 생각해보세요. Pandas의 `get_dummies` 함수로도 구현할 수 있습니다.",
        "solution": "원핫 인코딩 (One-hot encoding)"
    },
    {
        "item_type": "radio",
        "question": "scikit-learn을 사용하여 데이터를 학습용과 테스트용으로 분할할 때 사용하는 함수는 무엇입니까?",
        "options": [
            "StandardScaler",
            "KNeighborsRegressor",
            "train_test_split",
            "mean_squared_error"
        ],
        "hint": "'학습'과 '테스트'로 '분할'한다는 의미의 영어 단어 조합을 생각해보세요.",
        "solution": "train_test_split"
    },
    {
        "item_type": "radio",
        "question": "회귀 모델의 성능 평가 지표 중, 실제값과 예측값의 차이(오차)를 제곱하여 평균 낸 값은 무엇입니까?",
        "options": [
            "R-제곱 (R-squared)",
            "정확도 (Accuracy)",
            "평균 절대 오차 (Mean Absolute Error)",
            "평균 제곱 오차 (Mean Squared Error)"
        ],
        "hint": "이름 그대로 '제곱'한 '오차'의 '평균'을 의미합니다.",
        "solution": "평균 제곱 오차 (Mean Squared Error)"
    }
]
} />


## Q&A
<iframe src="https://tally.so/embed/wbOOKg?alignLeft=1&hideTitle=1&transparentBackground=1&dynamicHeight=0" loading="lazy" width="100%" height="274" frameborder="0" marginheight="0" marginwidth="0" title="Q&A"></iframe>
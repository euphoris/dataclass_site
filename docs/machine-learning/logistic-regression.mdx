# 로지스틱 회귀

## 준비

  * 데이터 불러오기



```python
cc = pd.read_excel('cancer.xlsx')
cc.head()
```

  * 준비



```python
X = cc.drop(columns=['diagnosis'])
y = cc['diagnosis'].map({'M':1, 'B':0})
```

  * 분할



```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size = 0.2, random_state = 42)
```



## 로지스틱 회귀분석 logistic regression

  * 0\~1 사이의 출력 
      * $z=wx+b$ 
      * $\sigma(z)=\frac{1}{1+exp(-z)}$ 
  * 출력은 확률로 해석 (예: 0.8→1일 확률이 80%) 



## 로지스틱 회귀분석 실습

  * 훈련 



```python
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter = 1000)
model.fit(X_train, y_train)
model.score(X_test, y_test)
```

  * 예측 



```python
from sklearn.metrics import accuracy_score
y_pred = model.predict(X_test)
accuracy_score(y_test, y_pred)
```



## 확률로 예측

  * 확률 예측 



```python
y_prob = model.predict_proba(X_test)[:, 1]
```

  * 정확도 



```python
import numpy as np
threshold = 0.5
y_pred_threshold = np.where(y_prob >= threshold, 1, 0)
accuracy_score(y_test, y_pred_threshold)
```



## 정칙화

  * penalty에는 라쏘(lasso), 릿지(ridge), 엘라스틱넷(elasticnet)이 가능 
  * C는 작을 수록, 강한 정칙화 



```python
model = LogisticRegression(penalty='elasticnet', l1_ratio=0.5, C=0.1,
                           solver='saga', max_iter = 10000)
model.fit(X_train, y_train)
model.score(X_test, y_test)
```



## Support Vector Machine

  * 분류의 경우 두 집단 간의 최대 마진을 찾는 초평면을 학습하여 데이터를 분류 



```python
from sklearn.svm import SVC
model = SVC(kernel='linear', C=1.0, probability=True, random_state = 42)
model.fit(X_train, y_train)
model.score(X_test, y_test)
```



## 커널 트릭 kernel trick

  * 저차원 공간에서 분류가 어려운 문제도 고차원 공간에서는 분류가 쉬움 
  * 실제 데이터를 고차원 공간으로 매핑하는 것은 계산이 많음 
  * 커널(쉽게 말하면 두 점의 거리를 측정하는 방식)만을 변경하여 마치 데이터가 고차원 공간에 매핑된 것처럼 계산하는 트릭을 사용할 수 있음 
  * SVM은 커널 트릭을 사용할 수 있는 모형 



## Support Vector Machine

  * RBF 커널 



```python
model = SVC(kernel='rbf', gamma='scale', C=1.0, probability=True, random_state = 42)
model.fit(X_train, y_train)
model.score(X_test, y_test)
```
## 퀴즈

import { QuizComponent } from "@/components/QuizComponent";

<QuizComponent quizId="regularization" quizItems={
    [
    {
        "item_type": "radio",
        "question": "로지스틱 회귀 모델이 선형 함수(z = wx + b)의 결과를 0과 1 사이의 값으로 변환하기 위해 사용하는 함수는 무엇입니까?",
        "options": [
            "선형 함수 (Linear Function)",
            "시그모이드 함수 (Sigmoid Function)",
            "최대값 함수 (Max Function)",
            "항등 함수 (Identity Function)"
        ],
        "hint": "이 함수의 공식은 1 / (1 + exp(-z)) 이며, S자 형태의 곡선을 그립니다.",
        "solution": "시그모이드 함수 (Sigmoid Function)"
    },
    {
        "item_type": "radio",
        "question": "scikit-learn의 로지스틱 회귀 모델에서 `predict_proba()` 메서드가 반환하는 값은 무엇입니까?",
        "options": [
            "최종 예측 클래스 (0 또는 1)",
            "각 클래스에 속할 확률",
            "모델의 정확도 점수",
            "모델 학습에 사용된 파라미터"
        ],
        "hint": "이름에 확률을 의미하는 'proba'가 포함되어 있습니다.",
        "solution": "각 클래스에 속할 확률"
    },
    {
        "item_type": "radio",
        "question": "로지스틱 회귀 모델의 정칙화(regularization)에서, 파라미터 `C`의 값이 작아질수록 정칙화의 강도는 어떻게 변합니까?",
        "options": [
            "강해진다",
            "약해진다",
            "변하지 않는다",
            "C값은 정칙화와 관련이 없다"
        ],
        "hint": "C는 정칙화 강도의 역수에 해당합니다. 즉, C가 작을수록 페널티는 커집니다.",
        "solution": "강해진다"
    },
    {
        "item_type": "radio",
        "question": "분류 문제에서 서포트 벡터 머신(SVM)의 주된 목표는 무엇입니까?",
        "options": [
            "데이터의 평균을 찾는 것",
            "두 데이터 집단 간의 거리가 가장 넓어지는(최대 마진) 경계선을 찾는 것",
            "모든 데이터 포인트를 통과하는 선을 찾는 것",
            "데이터의 분산을 최소화하는 것"
        ],
        "hint": "두 클래스를 가장 멀리 떨어뜨려 놓는 '최적의 선'을 찾는다고 생각할 수 있습니다.",
        "solution": "두 데이터 집단 간의 거리가 가장 넓어지는(최대 마진) 경계선을 찾는 것"
    },
    {
        "item_type": "radio",
        "question": "SVM에서 사용되는 '커널 트릭(kernel trick)'에 대한 설명으로 가장 올바른 것은 무엇입니까?",
        "options": [
            "데이터의 개수를 늘려주는 기술이다",
            "실제 데이터를 고차원으로 보내지 않고도, 고차원 공간에서 계산한 것과 같은 효과를 내는 기술이다",
            "모델의 학습 속도를 항상 빠르게 만들어주는 기술이다",
            "결측치를 자동으로 처리해주는 기술이다"
        ],
        "hint": "저차원에서 복잡하게 얽힌 데이터를 더 높은 차원에서 쉽게 분리할 수 있다는 아이디어에서 출발한 계산 기법입니다.",
        "solution": "실제 데이터를 고차원으로 보내지 않고도, 고차원 공간에서 계산한 것과 같은 효과를 내는 기술이다"
    },
    {
        "item_type": "radio",
        "question": "scikit-learn의 `SVC` 모델에서 비선형 분류를 위해 사용할 수 있는 커널(kernel)의 예시는 무엇입니까?",
        "options": [
            "linear",
            "rbf",
            "ols",
            "lasso"
        ],
        "hint": "Radial Basis Function의 약자입니다. 교안의 마지막 실습 코드에 나와 있습니다.",
        "solution": "rbf"
    }
]
} />


## Q&A
<iframe src="https://tally.so/embed/wbOOKg?alignLeft=1&hideTitle=1&transparentBackground=1&dynamicHeight=0" loading="lazy" width="100%" height="274" frameborder="0" marginheight="0" marginwidth="0" title="Q&A"></iframe>
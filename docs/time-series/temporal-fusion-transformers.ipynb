{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformers\n",
    "\n",
    "pytorch-forecasting 설치\n",
    "\n",
    "```\n",
    "!pip install pytorch-forecasting\n",
    "```\n",
    "\n",
    "임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stallion & Co.는 도매업체(agency)를 통해 소매업체에 유통되는 제품(sku)의 수요를 예측하기 위한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "data = get_stallion_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인덱스 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"time_idx\"] = data[\"date\"].dt.year * 12 + data[\"date\"].dt.month\n",
    "data[\"time_idx\"] -= data[\"time_idx\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 월\n",
    "data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\") \n",
    "# 로그 볼륨\n",
    "data[\"log_volume\"] = np.log(data.volume + 1e-8)\n",
    "# SKU별 평균 볼륨\n",
    "data[\"avg_volume_by_sku\"] = data.groupby([\"time_idx\", \"sku\"], observed=True).volume\\\n",
    "\t.transform(\"mean\")\n",
    "# 도매업체별 평균 볼륨\n",
    "data[\"avg_volume_by_agency\"] = data.groupby([\"time_idx\", \"agency\"], observed=True).volume\\\n",
    "\t.transform(\"mean\")\n",
    "# 공휴일 등 변환\n",
    "special_days = [\n",
    "    \"easter_day\", \"good_friday\", \"new_year\", \"christmas\", \"labor_day\", \n",
    "    \"independence_day\", \"revolution_day_memorial\", \"regional_games\", \"fifa_u_17_world_cup\",\n",
    "    \"football_gold_cup\", \"beer_capital\", \"music_fest\"]\n",
    "data[special_days] = data[special_days].apply(\n",
    "    lambda x: x.map({0: \"-\", 1: x.name})).astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 6  # 예측하려는 최대 시간 길이\n",
    "max_encoder_length = 24  # 인코더에 사용할 최대 시간 길이\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\t# 데이터를 훈련 및 검증 데이터로 나누기 위한 기준점\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],  # 기준점 이하만 훈련 데이터로 사용\n",
    "    time_idx=\"time_idx\",  # 시계열 인덱스\n",
    "    target=\"volume\",  # 예측하려는 값\n",
    "    group_ids=[\"agency\", \"sku\"],  # 데이터 그룹화에 사용할 열\n",
    "    min_encoder_length=max_encoder_length // 2,  # 인코더에 사용할 최소 길이(24/2==12)\n",
    "    max_encoder_length=max_encoder_length,  #\n",
    "    min_prediction_length=1,  # 예측할 최소 길이\n",
    "    max_prediction_length=max_prediction_length,  # 예측할 최대 길이\n",
    "    static_categoricals=[\"agency\", \"sku\"],  # 변하지 않는 범주형 변수\n",
    "    static_reals=[  # 변하지 않는 실수형 변수\n",
    "        \"avg_population_2017\",\"avg_yearly_household_income_2017\"], \n",
    "    time_varying_known_categoricals=[  # 시간에 따라 변하는 미래에 알려진 범주형 변수\n",
    "        \"special_days\", \"month\"],\n",
    "    variable_groups={\"special_days\": special_days},  # 특정 범주형 변수 그룹을 하나의 변수로 취급\n",
    "    time_varying_known_reals=[  # 시간에 따라 변하는 미래에 알려진 실수형 변수\n",
    "        \"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    time_varying_unknown_categoricals=[], # 시간에 따라 변하는 미래에 알 수 없는 범주형 변수\n",
    "    time_varying_unknown_reals=[  # 시간에 따라 변하는 미래에 알 수 없는 범주형 변수\n",
    "        \"volume\", \"log_volume\", \"industry_volume\", \"soda_volume\", \"avg_max_temp\",\n",
    "        \"avg_volume_by_agency\", \"avg_volume_by_sku\", ],\n",
    "    target_normalizer=GroupNormalizer(  # 그룹별로 정규화하고, softplus 변환\n",
    "            groups=[\"agency\", \"sku\"], transformation=\"softplus\"),\n",
    "        add_relative_time_idx=True,  # 상대적인 시간 인덱스를 추가\n",
    "        add_target_scales=True,  # 대상 값의 스케일을 추가\n",
    "        add_encoder_length=True,  # 인코더 길이를 추가\n",
    ")\n",
    "\n",
    "# 검증 데이터셋\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# 데이터 로더\n",
    "batch_size = 128  # 배치(한 번에 모델에 입력하여 학습시킬 데이터셋) 크기\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베이스라인 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predictions = Baseline().predict(val_dataloader, return_y=True)\n",
    "MAE()(baseline_predictions.output, baseline_predictions.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,  # 학습률\n",
    "    hidden_size=16,  # 은닉층 크기\n",
    "    attention_head_size=2, # attention heads의 수. 클 수록 복잡한 패턴\n",
    "    dropout=0.1,  # 과대적합 방지(0.1~0.3 사이)\n",
    "    hidden_continuous_size=8,  # 은닉층 크기보다 작거나 같게\n",
    "    loss=QuantileLoss(),  # TFT의 손실 함수\n",
    "    optimizer=\"Ranger\"  # 학습 알고리즘\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # 학습율 기록\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50, # 학습을 총 50회 반복\n",
    "    accelerator=\"gpu\", # cpu로 바꾸면 CPU로 학습\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1, # 경사 클리핑(폭발하는 경사 방지)\n",
    "    limit_train_batches=50, # 매 에포크 최대 50배치만 학습\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "predictions = best_tft.predict(val_dataloader, return_y=True,\n",
    "    trainer_kwargs=dict(accelerator=\"gpu\"))\n",
    "MAE()(predictions.output, predictions.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prediction = best_tft.predict(training.filter(lambda x: \n",
    "        (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"raw\", return_x=True)\n",
    "\n",
    "best_tft.plot_prediction(raw_prediction.x, raw_prediction.output, idx=0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

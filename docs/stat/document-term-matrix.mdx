

# 단어 통계



## 단어 통계

*   단어 사용의 패턴에는 여러 가지 정보가 포함
*   **개인**: "나"를 많이 쓰는가, "너"를 많이 쓰는가? (심리 상태, 성격)
*   **정치**: 대통령 연설문에 어떤 단어가 많이 나오는가? (정책 방향, 시대상)
*   **경제**: 기업의 실적보고에 어떤 단어가 많이 나오는가? (경영 상태, 시장 전망)
*   **제품**: 고객 리뷰에 어떤 단어가 많이 나오는가? (장단점, 개선점)
*   (이미지: 제임스 W. 페니베이커 '단어의 사생활' 책 표지 - 단어 사용과 심리 분석)
*   (그래프: 미국 대통령 연설문에서 'jobs' 단어 언급 빈도 변화, 경제 사이클과 관련성 시사)
*   (출처: NYT 인터랙티브 기사)



## 문서 단어 행렬 (Document Term Matrix, DTM)

*   문서별로 단어의 빈도를 정리한 표
*   **예시**:
    *   문서1: 오늘은 밥을 먹었다
    *   문서2: 어제도 밥, 오늘도 밥

|     | 오늘 | 어제 | 밥 | 먹다 |
| :--- | --- | --- | --- | --- |
| 문서1  |   1   |   0   |  1 |   1   |
| 문서2  |   1   |   1   |  2 |   0   |

*   비정형 데이터인 텍스트를 표 형태로 정형화
*   정형 데이터의 다양한 통계 기법을 적용 가능
*   처리가 단순 ↔ 어순과 맥락을 무시하는 것이 단점 (Bag-of-Words 가정)



## CountVectorizer 실습

*   pandas를 이용해 `yelp.xlsx` 파일을 연다.
    ```python
    import pandas as pd
    df = pd.read_excel('yelp.xlsx')
    ```
*   데이터 앞부분 확인
    ```python
    df.head()
    ```
*   데이터의 형태 확인 (예: 1000행, 2열)
    ```python
    df.shape
    ```



## 문서 단어 행렬 설정

```python
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=500, stop_words='english')
```

*   `max_features`: DTM에 포함시킬 최대(max) 단어(feature) 수 (빈도 순)
*   `stop_words`: 분석에서 제외할 불용어(stop words)를 설정
    *   `'english'`로 설정하면 영어의 내장 불용어 목록(a, an, the, is 등) 사용
    *   다른 언어는 리스트 등의 형태로 불용어 목록을 직접 전달해야 함



## 문서 단어 행렬 만들기

*   `df`의 `review` 컬럼을 바탕으로 문서 단어 행렬(DTM)을 만든다.
    ```python
    dtm = cv.fit_transform(df['review'])
    ```
*   만들어진 `dtm`의 형태 확인 (예: 1000행, 500열)
    ```python
    dtm.shape
    ```
*   DTM의 단어(feature) 목록 확인 (cv 객체에 저장됨)
    ```python
    cv.get_feature_names_out()
    ```



## 합계

*   **단어별 총 빈도 (axis=0: 열별 합계)**
    *   바이너리 인코딩(binary=True)된 경우, 문서 빈도 (Document Frequency, DF: 해당 단어가 출현하는 문서의 수)
    ```python
    dtm.sum(axis=0)
    ```
*   **문서별 총 단어 수 (axis=1: 행별 합계)**
    ```python
    dtm.sum(axis=1)
    ```
*   (다이어그램: 행렬에서 `axis=0` (열 방향)과 `axis=1` (행 방향) 합계 시각화)



## 단어 빈도 데이터 프레임

```python
word_count = pd.DataFrame({
    '단어': cv.get_feature_names_out(),
    '빈도': dtm.sum(axis=0).flat # .flat은 행렬을 1차원으로 펴줌
})
```

*   각 단어의 총 빈도를 Pandas 데이터 프레임으로 만들어 `word_count`라고 함
*   `dtm.sum(axis=0)`의 결과는 NumPy 행렬 형태이므로 `.flat`을 사용하여 시리즈 형태로 변환



## 빈도순 정렬

*   `.sort_values()`를 이용해 빈도 순으로 정렬한다.
    ```python
    word_count.sort_values('빈도', ascending=False).head()
    ```
*   `ascending=True`를 하면 오름차순으로 정렬.
*   생략하거나 `False`로 하면 내림차순 정렬.
*   엑셀 파일로 저장:
    ```python
    word_count.to_excel('word_count.xlsx')
    ```



## 단어 구름 (Word Cloud)

*   단어 빈도를 시각화하는 방법
*   자주 나오는 단어는 크게, 드물게 나오는 단어는 작게 시각화
*   단어의 배치를 통해 특정한 이미지 형태(마스크)가 되도록 하기도 함
*   (이미지: Word Cloud 예시)



## 설치와 임포트 (wordcloud)

*   pip 명령어로 설치
    ```bash
    pip install wordcloud
    ```
*   wordcloud 모듈에서 WordCloud 클래스를 임포트
    ```python
    from wordcloud import WordCloud
    ```



## 설정 (WordCloud)

```python
wc = WordCloud(
    font_path='NanumGothic.ttf', # 글꼴 파일 경로 (한글 사용시 필수)
    background_color='white',    # 배경색
    max_words=100,               # 표시할 최대 단어 수
    width=400,                   # 이미지 가로 크기 (px)
    height=300                   # 이미지 세로 크기 (px)
)
```

*   한글 단어 구름을 그릴 때는 한글 지원 글꼴 파일(`font_path`)이 반드시 있어야 함
*   상업적으로 사용할 수 있는 무료 글꼴은 눈누(noonnu.cc) 등에서 구할 수 있음



## 눈누

*   눈누: https://noonnu.cc
*   상업적으로 사용할 수 있는 무료 글꼴 모음 사이트
*   (이미지: 눈누 웹사이트 스크린샷, 다양한 무료 한글 폰트 예시)



## 그리기 (WordCloud)

*   단어 빈도 데이터 불러오기 (예: 엑셀 파일)
    ```python
    import pandas as pd
    word_count = pd.read_excel('word_count.xlsx', index_col=0) # index_col=0은 첫번째 열을 인덱스로 사용
    ```
*   `word_count` 데이터프레임을 단어:빈도 형태의 사전(dictionary)으로 변환
    ```python
    # zip 함수는 두 리스트를 묶어 튜플의 리스트로 만듬
    # dict 함수는 (키, 값) 튜플 리스트를 사전으로 만듬
    count_dic = dict(zip(word_count.단어, word_count.빈도))
    ```
*   사전 데이터를 이용해 단어 구름 생성
    ```python
    # fit_words 메서드는 단어 빈도 사전을 받아 워드클라우드 객체를 학습시킴
    cloud = wc.fit_words(count_dic)
    ```



## 보기 및 저장 (WordCloud)

*   생성된 단어 구름 보기 (이미지 객체 반환)
    ```python
    image = cloud.to_image()
    image.show() # PIL 라이브러리 필요 시
    # Jupyter Notebook 등에서는 cloud 객체만 입력해도 표시됨
    ```
*   글자 크기는 단어 빈도에 비례
*   글자 위치는 기본적으로 랜덤 배치
*   이미지 파일로 저장
    ```python
    cloud.to_file('cloud.png')
    ```
*   (이미지: 생성된 Word Cloud 예시 - 음식점 리뷰 관련 단어)



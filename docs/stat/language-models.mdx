
# 언어 모형과 생성형 인공지능



## 언어 모형 (Language Model, LM)

*   텍스트 데이터의 통계적 구조와 패턴을 모델링하여 단어, 문장, 문단 등의 등장 **확률 분포**를 추정하는 기술
*   다양한 자연어 처리(NLP) 작업의 기반이 됨
*   **주요 종류**:
    *   **Causal LM (Autoregressive LM)**: 이전 단어 시퀀스를 바탕으로 **다음 단어**를 예측 (예: GPT)
    *   **Masked LM**: 문장의 일부 단어를 마스크(mask) 처리하고, 앞뒤 문맥을 바탕으로 **마스크된 단어**를 예측 (예: BERT)
*   **프롬프트 (Prompt)**: 언어 모형에게 작업을 지시하거나 원하는 출력을 유도하기 위해 입력하는 텍스트
*   (이미지 1: Causal LM 예시 - "The best thing about AI is its ability to" 다음 단어 예측 확률)
*   (이미지 2: Masked LM 예시 - "대한민국의 수도는 [MASK] 입니다." 에서 [MASK] 예측 확률)



## n-gram 언어 모형

*   언어 모형을 만드는 가장 간단한 전통적 방법
*   텍스트에서 **연속된 n개의 단어** (n-gram) 시퀀스의 출현 빈도를 세어 확률을 계산
    $P(w_i | w_{i-n+1}, ..., w_{i-1}) \approx \frac{\text{count}(w_{i-n+1}, ..., w_{i-1}, w_i)}{\text{count}(w_{i-n+1}, ..., w_{i-1})}$
*   **단점**:
    *   **문맥 제한**: 최대 n-1개의 이전 단어만 고려 가능 (장기 의존성 파악 어려움)
    *   **희소성 문제 (Sparsity Problem)**: n이 커질수록 가능한 조합의 수가 폭발적으로 증가하여, 대부분의 n-gram은 학습 데이터에서 관찰되지 않아 확률이 0으로 추정될 수 있음 (Smoothing 기법 필요)
    *   **메모리 문제 (Storage Problem)**: 관찰된 모든 n-gram의 빈도를 저장해야 하므로 많은 저장 공간 필요



## GPT (Generative Pretrained Transformer)

*   OpenAI가 개발한 **Transformer** 아키텍처 기반의 대규모 언어 모형
*   **"Generative Pretrained Transformer"** 의 의미:
    *   **Generative (생성적)**: 학습된 확률 분포를 바탕으로 새로운 텍스트를 생성할 수 있는 언어 모형 (Causal LM 방식)
    *   **Pretrained (사전학습된)**: 대규모의 비정형 텍스트 데이터로 미리 학습시킨 후, 특정 과제(task)에 맞게 추가 학습(fine-tuning)하여 사용 가능
    *   **Transformer (트랜스포머)**: Google에서 2017년 발표한 Self-Attention 메커니즘 기반의 딥러닝 모델 구조. 병렬 처리와 장기 의존성 학습에 강점.
*   **발전 과정**:
    *   2018년 GPT-1 발표
    *   ...
    *   2023년 GPT-4 발표
*   **규모 (파라미터 수)**:
    *   GPT-3: 약 1,750억 개
    *   GPT-4: 약 1조 7,600억 개 (추정치)
*   (다이어그램: Transformer Decoder 구조 - Masked Multi-Head Self-Attention, Feed Forward, Layer Normalization 등)



## 언어 모형은 어떻게 텍스트를 생성하는가?

*   **1단계: 다음 토큰(Token) 예측**: 현재까지 생성된 텍스트 시퀀스를 바탕으로, 다음에 올 가능성이 있는 모든 토큰들과 그 확률을 예측
    *   토큰: 단어보다 작은 단위 (subword)를 사용하기도 함 (예: BPE, WordPiece). 자주 나오는 문자열은 하나의 토큰으로 묶음.
    *   예: `Al is` 다음 토큰 예측 → `a`(9.7%), `the`(5.6%), `not`(3.6%), `an`(2.5%), `also`(2.4%), ...
*   **2단계: 디코딩 (Decoding)**: 예측된 토큰 확률 분포에서 실제 사용할 다음 토큰을 **선택**하는 방법
    *   **결정론적 디코딩 (Deterministic Decoding)**:
        *   **Greedy Search**: 매 단계에서 가장 확률이 높은 토큰을 선택 (예: `Al is a ...`)
    *   **확률적 디코딩 (Stochastic Decoding)**: 예측된 확률 분포에 따라 무작위로 다음 토큰 선택 (다양하고 창의적인 생성 가능)
        *   **Temperature Sampling**: 확률 분포를 조절하여 다양성 제어 (낮으면 Greedy, 높으면 균등)
        *   **Top-k Sampling**: 확률 상위 k개 토큰 중에서만 샘플링
        *   **Top-p (Nucleus) Sampling**: 누적 확률이 p 이상이 되는 최소 개수의 토큰 중에서 샘플링
        *   (예: 0~1 난수 추출 → 0.099 추출 → $P(a)=0.097 < 0.099 \le P(a)+P(the)=0.153$ 이므로 'the' 선택 → `Al is the ...`)



## 튜링 테스트 (Turing Test)

*   기계(컴퓨터)가 **인간과 유사한 지능적인 행동**(생각)을 할 수 있는지 판별하기 위해 앨런 튜링이 1950년에 제안한 테스트
*   **방법**:
    1.  인간 평가자가 벽(스크린) 너머의 상대방과 텍스트(키보드, 화면)로 자유롭게 대화
    2.  상대방은 인간 또는 컴퓨터(AI)
    3.  평가자는 대화 후 상대방이 인간인지 컴퓨터인지 판정
*   **판정 기준**: 만약 평가자가 상당한 시간 동안 대화한 후에도 컴퓨터와 인간을 **구분할 수 없다면** (예: 5분 대화 후 70% 이상 속인다면 - 튜링의 기준), 그 컴퓨터는 생각을 할 수 있다고 간주할 수 있음
*   (이미지: 평가자, 인간 대화 상대, AI 대화 상대를 연결하는 튜링 테스트 개념도)
*   (이미지: 앨런 튜링 지폐 도안)



## GPT-4.5는 튜링 테스트를 통과 (연구 결과)

*   2023년 발표된 한 연구(Jones and Bergen, 2023)에서 GPT-4(모델 버전 표기 오타 가능성, 혹은 GPT-4.5가 비공개 모델일 수 있음)를 포함한 여러 언어 모델로 튜링 테스트 실험 진행
*   결과: GPT-4.5 모델은 인간 평가자를 상당히 높은 비율로 속여, 연구자들은 해당 모델이 튜링 테스트를 통과했다고 주장
*   (그래프: 다양한 AI 모델(ELIZA, LLAMA, GPT 등)과 인간의 튜링 테스트 승률(Win Rate) 및 평가자의 확신도(Confidence) 비교. GPT-4.5-PERSONA 모델이 높은 승률을 보임)



## 튜링 테스트의 문제점 및 한계

*   **"생각하는 능력" 자체를 측정하는 테스트로서는 문제점 지적**:
    *   생각은 하지만 언어 표현을 못하는 경우 (예: 영유아, 실어증 환자)는 테스트 불가
    *   언어적 표현은 잘하지만 실제로는 생각하지 않는 경우 (예: 중국어 방 논증, 정교한 챗봇)를 걸러내기 어려움
*   **"인간처럼 대화하는 능력" (자연어 생성 능력) 테스트로는 유효**: 현대 LLM의 성능 평가 지표 중 하나로 활용 가능
*   **튜링의 기준(5분 대화, 70% 정답률)은 현대 기준으로 너무 낮음**:
    *   짧은 시간의 대화에서는 피상적인 속임수가 통하기 쉬움
    *   1966년 개발된 초기의 간단한 규칙 기반 챗봇 **ELIZA**조차 단시간 대화에서는 일부 사람들에게 실제 사람과 대화하는 듯한 인상을 줌
    *   1991년 PC Therapist 챗봇은 50%의 평가자를 속임 (Loebner Prize)
*   즉, 튜링 테스트 통과가 반드시 진정한 의미의 '생각'이나 '이해'를 의미하지는 않음



## 벤치마크의 빠른 포화

*   인공지능 성능을 측정하기 위해 사용되는 다양한 **벤치마크(benchmark)** 데이터셋 및 과제들이 개발됨 (예: MNIST, ImageNet, SQuAD, GLUE, MMLU, MATH)
*   그래프는 여러 AI 벤치마크에서 시간이 지남에 따라 AI 모델의 성능(인간 수준 대비 정규화)이 빠르게 향상되어 **인간 수준에 도달하거나 넘어서는(포화되는)** 경향을 보여줌
*   이는 AI 기술, 특히 대규모 언어 모델(LLM)의 급속한 발전을 시사
*   벤치마크가 포화되면, 모델 간의 성능 차이를 변별하기 어려워지고 새로운, 더 어려운 벤치마크의 필요성이 대두됨
*   (그래프: 다양한 AI 벤치마크 이름과 해당 벤치마크에서 AI 성능이 인간 수준(0%)에 도달하는 시점을 보여주는 시계열 그래프)


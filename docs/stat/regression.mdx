# 회귀분석

## 통계에서 예측의 의미

*   **예측 (Prediction) 정의:** 특정 값(보통 종속변수)에 대한 **추론** 의미. 반드시 미래 시점 예측 의미 아님.
*   **지도학습 (Supervised Learning) 관점:** 변수 간 패턴 파악하여, 한 변수(독립변수)로 다른 변수(종속변수) **추론**하는 것.
*   **미래 예측:** 시계열 분석 등에서 미래 값 예측은 보통 **forecasting**이라 구분함.

## 회귀분석 기본

*   **목적:** **독립변수(들)** 이용하여 **연속형 종속변수** 예측/설명하는 분석.
*   **평가:** 예측값과 실제값 차이(잔차) 이용하여 정확성 계산.
*   **독립변수 (Independent Variable, x):** 예측의 바탕 정보, 원인, 입력값. 설명변수, 예측변수라고도 함.
*   **종속변수 (Dependent Variable, y):** 예측 대상, 결과, 출력값. 반응변수라고도 함.

## 선형 모형 (Linear Model)

*   가장 기본적인 회귀 모형. 독립변수와 종속변수 간 직선 관계 가정.
*   **수식:**
    $$ \hat{y} = wx + b $$
*   **구성:**
    *   $\hat{y}$: $y$의 **예측치**.
    *   $x$: **독립변수**.
    *   $w$: **가중치(weight)** 또는 **기울기(slope)**. $x$가 1단위 변할 때 $\hat{y}$의 변화량. 회귀계수(regression coefficient).
    *   $b$: **절편(intercept)**. $x = 0$ 일 때 $\hat{y}$의 예측치.

## 회귀분석 예시: 피부암 사망률

*   독립변수(x): 위도 (Latitude)
*   종속변수(y): 인구 천만명 당 피부암 사망자 수 (Mortality)
*   **분석 결과 (예시):** $\hat{y} = 389.2 - 5.98x$
    *   위도가 1단위 증가할수록 사망률 약 5.98 감소 예측.

## 잔차 (Residual)

*   **정의:** 실제값($y$) - 예측값($\hat{y}$). 예측 오차.
*   **잔차 분산 (Residual Variance / Mean Squared Error, MSE):** 잔차 제곱의 평균. 모형 예측 정확도 지표.
*   **cf. 분산 (Variance):** 편차(실제값 - 평균) 제곱의 평균. 데이터 퍼짐 정도.
*   **해석:**
    *   잔차 분산 크다 → 예측 잘 맞지 않음 (오차 큼).
    *   잔차 분산 작다 → 예측 잘 맞음 (오차 작음).

## 최소제곱법 (Ordinary Least Squares, OLS)

*   회귀 모형 계수($w, b$ 등) 추정하는 가장 표준적인 방법.
*   **원리:** **잔차 제곱합 (Sum of Squared Residuals, SSR)** 또는 **잔차 분산 (MSE)**을 **최소화**하는 계수 찾는 것.
*   "최소'제곱'법" 이유: 잔차(오차)의 '제곱'합을 최소화하기 때문.

## 관계식 (Formula) in Python (statsmodels)

*   회귀분석 모형 설정 위한 문법 (R 언어 스타일).
*   **형식:** `종속변수 ~ 독립변수1 + 독립변수2 + ...`
*   **주의:** **종속변수(y)**가 `~` 기호 **왼쪽(먼저)** 나옴.
*   `+` 기호: 해당 독립변수 모형에 **포함** 의미 (산술 덧셈 아님).

## Python 회귀분석 코드 (statsmodels)

```python
# 1. 모듈 가져오기
from statsmodels.formula.api import ols

# 2. 모형 설정 및 분석 수행
# 형식: ols("종속변수 ~ 독립변수", data=데이터프레임).fit()
m = ols("price ~ mileage", data=df).fit()

# 3. 결과 확인
print(m.summary())
```

## 회귀계수 추정 결과 해석

*   `m.summary()` 결과 표에서 **`coef` (계수 추정치)**, **`P>|t|` (p-value)**, **`[0.025 0.975]` (95% 신뢰구간)** 중요.
*   **Intercept 행:** 절편($b$)에 대한 정보.
    *   `coef`: 추정된 절편 값 (예: 1258.7668). x=0일 때 y 예측치.
*   **독립변수 행 (예: mileage):** 해당 독립변수 기울기($w$)에 대한 정보.
    *   `coef`: 추정된 기울기 값 (예: -0.0052). x가 1단위 증가할 때 y 예측 변화량.
*   **결과 식:** `price = -0.0052 * mileage + 1258.7668`
*   **기타:** `std err`(표준오차), `t`(t값)는 주로 p-value 계산 위한 중간 값. 직접 해석 필요성 낮음.

## 회귀계수의 가설 검정

*   **목적:** 추정된 회귀계수($w$)가 통계적으로 유의미한지(0과 다른지) 판단.
*   **귀무가설 (H₀):** 모집단에서 해당 회귀계수 = 0 (독립변수가 종속변수 설명 못 함).
*   **판단 (p-value 또는 신뢰구간):**

| 가설검정 (p-value)     | 신뢰구간          | 해석                                         |
| :--------------------- | :---------------- | :------------------------------------------- |
| `p ≥ 유의수준 (0.05)` | `- ~ +` (0 포함) | 귀무가설 기각 실패. 계수가 0일 가능성 배제 못 함. |
| `p < 유의수준 (0.05)` | `- ~ -` 또는 `+ ~ +` (0 미포함) | 귀무가설 기각. 계수가 0과 유의하게 다름. |

## Python 예측 수행

```python
import pandas as pd

# 1. 예측할 새로운 독립변수 데이터 만들기 (DataFrame 형태)
new_df = pd.DataFrame({'mileage': [10000, 20000]})

# 2. 학습된 모형(m)으로 예측 수행
predictions = m.predict(new_df)
print(predictions)
```

## R 제곱 (R-squared / 결정계수)

*   회귀 분석에서 모형의 **설명력(예측 정확성)** 나타내는 대표 지표 (0 ~ 1 범위).
*   **계산:**
$$ 
R^2 = 1 - \frac{\text{잔차 분산 (Residual Variance, RSS/n)}}{\text{종속변수 총 분산 (Total Variance, TSS/n)}} = 1 - \frac{SSR}{TSS} 
$$
    *   SSR (Sum of Squared Residuals): 잔차 제곱합. 모형으로 설명 안 되는 변동.
    *   TSS (Total Sum of Squares): 종속변수 총 변동 (평균 대비).
*   **해석:**
    *   $R^2 = 0$: 모형이 종속변수 예측/설명 도움 안 됨 (평균 예측과 동일).
    *   $R^2 = 1$: 모형이 종속변수 완벽하게 예측/설명함 (잔차 없음).
*   **단순회귀분석 (독립변수 1개):** $R^2$ = (피어슨 상관계수)² 와 같음.

## R 제곱 읽는 법

*   "모형이 종속변수($y$) 분산(총 변동)의 **약 R² %를 설명한다**" 라고 해석.
*   예: $R^2 = 0.3$ → "모형이 종속변수 분산의 30%를 설명한다".
*   **의미:** 모형 사용 통해 종속변수 예측 불확실성(분산)이 얼마나 줄었는지 나타냄. (분산 감소 = 불확실성 감소 = 설명됨).

## 퀴즈

<iframe src="https://tally.so/embed/3E62yl?alignLeft=1&hideTitle=1&transparentBackground=1&dynamicHeight=1" loading="lazy" width="100%" height="2800" frameborder="0" marginheight="0" marginwidth="0" title="[통계] 회귀분석"></iframe>

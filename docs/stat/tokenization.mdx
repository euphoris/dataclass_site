
# 형태소 분석



## 토큰화 (Tokenization)

*   문장을 의미있는 최소 단위인 토큰(token)으로 쪼개는 과정
*   **영어**의 경우 흔히 **단어** 단위로 토큰화 (공백, 구두점 기준)
    *   단어: 홀로 쓰일 수 있는 단위
    *   `The apple went bad` → `the`, `apple`, `went`, `bad`
*   **한국어**의 경우 조사가 발달하여 어절(띄어쓰기) 단위가 아닌 **형태소** 단위로 토큰화하는 것이 일반적
    *   형태소: 의미를 가지는 가장 작은 말의 단위
    *   `사과가 상했다` → `사과/NNG`, `가/JKS`, `상하/VV`, `었/EP`, `다/EF` (형태소/품사 태그)
*   **단어 분리 (word segmentation)**: 중국어, 일본어처럼 띄어쓰기가 없거나 모호한 언어에서 단어 경계를 찾는 과정



## 형태소 분석기 kiwi 사용법

*   빠르고 정확한 한국어 형태소 분석기 중 하나 (SWRC 개발)
*   설치
    ```bash
    !pip install kiwipiepy
    ```
*   불러오기 및 객체 생성
    ```python
    from kiwipiepy import Kiwi
    kiwi = Kiwi()
    ```



## kiwi 형태소 분석

*   `kiwi.tokenize()` 메서드를 사용한 형태소 분석
    ```python
    text = '오늘은 자연어 처리를 배우기 좋은 날이다.'
    result = kiwi.tokenize(text) # 토큰 리스트 반환
    # 각 토큰은 form(형태), tag(품사), start(시작위치), len(길이) 속성을 가짐
    print(result)
    ```



## kiwi 품사 태그 (주요 태그)

*   **체언(N)**: `NNG`(일반명사), `NNP`(고유명사), `NNB`(의존명사), `NR`(수사), `NP`(대명사)
*   **용언(V)**: `VV`(동사), `VA`(형용사), `VX`(보조용언), `VCP`(긍정지정사), `VCN`(부정지정사)
*   **관형사/부사(M)**: `MM`(관형사), `MAG`(일반부사), `MAJ`(접속부사)
*   **감탄사(I)**: `IC`
*   **조사(J)**: `JKS`(주격), `JKC`(보격), `JKG`(관형격), `JKO`(목적격), `JKB`(부사격), `JKV`(호격), `JKQ`(인용격), `JX`(보조사), `JC`(접속조사)
*   **어미(E)**: `EP`(선어말), `EF`(종결), `EC`(연결), `ETN`(명사형전성), `ETM`(관형형전성)
*   **접사(X)**: `XPN`(체언접두사), `XSN`(명사파생접미사), `XSV`(동사파생접미사), `XSA`(형용사파생접미사), `XR`(어근)
*   **부호(S)**: `SF`(마침표), `SP`(쉼표 등), `SS`(따옴표 등), `SE`(줄임표), `SO`(붙임표), `SW`(기타기호), `SL`(알파벳), `SH`(한자), `SN`(숫자)
*   **기타**: `UN`(분석불능), `W_*`(URL, EMAIL, HASHTAG, MENTION)

*※ 전체 태그 목록은 공식 문서 참조*



## kiwi 명사 추출 함수

```python
def extract_nouns(text):
    """kiwi 형태소 분석 결과에서 명사(NNG, NNP)만 추출하는 함수"""
    result = kiwi.tokenize(text)
    for token in result:
        # 일반 명사(NNG) 또는 고유 명사(NNP)인 경우 해당 형태(form)를 반환
        if token.tag in ['NNG', 'NNP']:
            yield token.form # yield는 제너레이터 함수를 만듬
```

*   사용 예시
    ```python
    text_example = '어제는 홍차를 마시고, 오늘은 커피를 마셨다.'
    nouns = list(extract_nouns(text_example)) # 제너레이터 결과를 리스트로 변환
    print(nouns) # ['어제', '홍차', '오늘', '커피']
    ```



## 한국어 문서 단어 행렬 만들기

```python
# 데이터 로드 (예시)
import pandas as pd
df = pd.read_csv('news_ai.csv')

# 사용자 사전 추가 (분석 전에 필요 시)
kiwi.add_user_word('인공지능', 'NNP') # '인공지능'을 고유명사로 등록

from sklearn.feature_extraction.text import CountVectorizer

# CountVectorizer의 tokenizer 인자에 명사 추출 함수(extract_nouns) 지정
cv = CountVectorizer(max_features=100, tokenizer=extract_nouns)

# df의 '본문' 컬럼에 대해 명사만 추출하여 DTM 생성
dtm = cv.fit_transform(df['본문'])
```

